The North American video game crash of 1983 (known as the Atari shock in Japan[1]) was a massive recession in the video game industry that occurred from 1983 to 1985. Revenues had peaked at around $3.2 billion in 1983,[2] then fell to around $100 million by 1985[citation needed][3] (a drop of almost 97 percent). The crash was a serious event that brought an abrupt end to what is retrospectively considered the second generation of console video gaming in North America.

The crash almost destroyed the then-booming industry, and led to the bankruptcy of several companies producing home computers and video game consoles in the region. It lasted about two years. Analysts of the time expressed doubts about the long-term viability of video game consoles and software.[4] The North American video game console industry recovered a few years later, mostly due to the widespread success of the Nintendo Entertainment System (NES), which was soft launched in New York City in late 1985 and had become extremely popular in North America by 1987.[5]

The crash had several causes, including the saturation of the market. The full effects of the industry crash would not be felt until 1985.[6]

The North American video game console crash of 1983 was caused by a combination of factors.

At the time of the North American crash, there were many consoles on the market, including the Atari 2600, Atari 5200, ColecoVision, Odyssey 2 and the Fairchild II. In addition to this, Mattel and Coleco created devices that allowed them to play 2600 games on their consoles, and others created Atari 2600/Intellivision clones such as the Coleco Gemini, the Sears Tele-Games systems (private-labeled versions of the Atari 2600 and Intellivision), and Tandyvision (an Intellivision clone for Radio Shack).

Each of these consoles had its own library of games produced by the console maker, and many had large libraries of games produced by third-party developers. In 1982, analysts noticed trends of saturation, mentioning that the amount of new software coming in will only allow a few big hits, that retailers had too much floor space for systems, along with price drops for home computers could result in an industry shakeup.[7]

The first microcomputers such as the Altair 8800 and Apple I were marketed to a niche of electronics hobbyists as most required assembly from a kit. In 1977, pre-assembled machines with BASIC in ROM became available, including the "Trio of '77": the Apple II, Commodore PET, and TRS-80 Model I. The latter two retailed for under $1,000, but lacked game joysticks and high-resolution color video.[8] Third-party developers created games for all of these platforms. The TRS-80 benefited from Radio Shack's retail stores, which displayed computers and accessories locally in an era where many personal computers were mail-ordered from manufacturers.

In 1979, Atari unveiled the Atari 400 and 800 computers, built around a chipset originally meant for use in a game console, and which retailed for the same price as their respective names. In 1981, IBM introduced the IBM 5150 PC with a $1,565 base price[9] (equivalent to $4,123 in 2016), while Sinclair Research introduced its low-end ZX81 microcomputer for £70 (equivalent to £242 in 2015). By 1982, new desktop computer designs were commonly providing better color graphics and sound than game consoles and personal computer sales were booming. The TI 99/4A and the Atari 400 were both at $349 (equivalent to $866 in 2016), Radio Shack's Color Computer sold at $379 (equivalent to $941 in 2016), and Commodore International had just reduced the price of the VIC-20 to $199 (equivalent to $494 in 2016) and the 64 to $499 (equivalent to $1,238 in 2016).[10][11]

By 1983 consumers found that most predicted uses of home computers were unrealistic, except for games. Children used most home computers[12]—Coleco planned to market its Adam home computer to "boys age 8 to 16 and their fathers ... the two groups that really fuel computer purchases"[13]—so games dominated home computers' software libraries. A 1984 compendium of reviews of Atari 8-bit software used 198 pages for games compared to 167 for all other software types.[14] Because computers generally had more memory and faster processors than a console, they permitted more sophisticated games. They could also be used for tasks such as word processing and home accounting. Games were easier to duplicate, since they could be packaged as floppy disks or cassette tapes instead of ROM modules (though some cassette-based systems retained ROM modules as an "instant-on" option). This opened the field to a cottage industry of third-party software developers. Writeable storage media allowed players to save games in progress, a useful feature for increasingly complex games which was not available on the consoles of the era.

In 1982 a price war began between Commodore and Texas Instruments, and home computers became as inexpensive as video-game consoles;[15] after Commodore cut the retail price of the 64 to $300 in June 1983 some stores began selling it for as little as $199.[12] Dan Gutman, founder in 1982 of Video Games Player magazine, recalled in 1987 that "As the first wave of the personal computer boom started, the video games market began to taper off. People asked themselves, 'Why should I buy a video game system when I can buy a computer that will play games and do so much more?'"[16] The Boston Phoenix stated in September 1983 about the cancellation of the Intellivision III, "Who was going to pay $200-plus for a machine that could only play games?"[12] Commodore explicitly targeted video game players. Spokesman William Shatner asked in VIC-20 commercials "Why buy just a video game from Atari or Intellivision?", stating that "unlike games, it has a real computer keyboard" yet "plays great games too".[17] The company offered competitive upgrades, where rival systems could be traded for a discount toward the purchase of a Commodore 64. Commodore's ownership of chip fabricator MOS Technology allowed manufacture of integrated circuits in-house, so the VIC-20 and C64 sold for much lower prices than competing home computers.

By September 1983 the price war was so severe that Coleco CEO Arnold Greenberg welcomed rumors of an IBM 'Peanut' home computer because "IBM is a company that knows how to make money". "I look back a year or two in the videogame field, or the home-computer field", Greenberg added, "how much better everyone was, when most people were making money, rather than very few".[18] By that year, Gutman wrote, "Video games were officially dead and computers were hot". He renamed his magazine to Computer Games in October 1983, but "I noticed that the word games became a dirty word in the press. We started replacing it with simulations as often as possible". Soon "The computer slump began ... Suddenly, everyone was saying that the home computer was a fad, just another hula hoop". Computer Games published its last issue in late 1984.[16] In 1988, Computer Gaming World founder Russell Sipe noted that "the arcade game crash of 1984 took down the majority of the computer game magazines with it." He stated that, by "the winter of 1984, only a few computer game magazines remained," and by the summer of 1985, Computer Gaming World "was the only 4-color computer game magazine left."[19]

The American game industry lobbied in Washington, D.C. for a smaller $1 coin, closer to the size of a quarter, arguing that inflation (which had reduced the quarter's spending power by a third in the early 1980s) was making it difficult to prosper.[20] During the 1970s, the dollar coin in use was the Eisenhower Dollar, a large coin impractical for vending machines. The Susan B. Anthony Dollar was introduced in 1979, and its size fit the video game manufacturers' demands, but it was a failure with the general public. Ironically, the new coin's similarity to the quarter was one of the most common complaints. In Canada, existing dollar bills were removed from circulation and replaced with coins in 1987.

Arcade machines in Japan had standardized the use of ¥100 coins, worth roughly $1, which industry veteran Mark Cerny proposed as a reason for Japan's game industry stability of the time.[20]

In 1979, Activision became the industry's first third-party developer.[21] It was founded by Atari programmers who left the company because Atari did not allow credits to appear on their games and did not pay employees a royalty based on sales. At the time, Atari was owned by Warner Communications, and the developers felt that they should receive the same recognition that musicians, directors, and actors got from Warner's other divisions. After Activision went into business, Atari quickly sued to block sales of Activision's products, but failed to secure a restraining order and ultimately settled the case in 1982.[22] This court case legitimized third-party development, encouraging companies such as Quaker Oats (with their US Games division) to rush to open video-game divisions, hoping to impress both stockholders and consumers.

Popular games from developers such as Activision, Imagic, and Parker Brothers reduced Atari's share of the cartridge-game market from 75% in 1981 to less than 40% in 1982.[23] David Crane, one of the founders of Activision after leaving Atari, recalled that during the six months between two consecutive Consumer Electronic Shows, the number of third-party developers jumped from 3 to 30. Attempting to imitate Activision, the new companies attempted to use programmers unfamiliar with game development to produce, Crane said, "the worst games you can imagine".[24] Companies lured away each other's programmers or used reverse engineering to learn how to make games for proprietary systems. Atari even hired several programmers from Mattel's Intellivision development studio, prompting a lawsuit by Mattel against Atari that included charges of industrial espionage.

Despite the lessons learned by Atari in the loss of its programmers to Activision, Mattel continued to try to avoid crediting game designers. Rather than reveal the names of Intellivision game designers, in a 1981 TV Guide interview, Mattel instead required that they change their names to protect their collective identities. ColecoVision designers worked in similar obscurity, feeding more departures to upstart competitors.

In the second half of 1982 the number of cartridges grew from 100 in June to more than 400 in December. Experts predicted a glut in 1983, with 10% of games producing 75% of sales.[21] BYTE stated in December that "in 1982 few games broke new ground in either design or format ... If the public really likes an idea, it is milked for all it's worth, and numerous clones of a different color soon crowd the shelves. That is, until the public stops buying or something better comes along. Companies who believe that microcomputer games are the hula hoop of the 1980s only want to play Quick Profit."[25] Bill Kunkel said in January 1983 that companies had "licensed everything that moves, walks, crawls, or tunnels beneath the earth. You have to wonder how tenuous the connection will be between the game and the movie 'Marathon Man'. What are you going to do, present a video game root canal?"[26]

By September 1983 the Phoenix stated that 2600 cartridges "is no longer a growth industry".[12] Unlike Nintendo, Sega, Sony, or Microsoft in later decades, the hardware manufacturers in this era lost exclusive control of their platforms' supply of games. With it, they also lost the ability to ensure stores were never overloaded with products. Activision, Atari, and Mattel all had experienced programmers, but many of the new companies rushing to join the market did not have the expertise or talent to create quality games. Titles such as Chase the Chuck Wagon (about dogs eating food, funded by the dog food company Purina), Skeet Shoot, and Lost Luggage were examples of games made in the hopes of taking advantage of the video-game boom. While heavily advertised and marketed, these games were perceived to be of poor quality and did not catch on as hoped, further damaging the industry.

In addition, to recoup revenue, companies like Coleco and Atari would publish their own games on each other's systems; this greatly increased saturation and spurred companies like Sears and CBS to publish the same games on their own cartridges, sometimes with different names.

The release of so many new games in 1982 flooded the market. Most stores had insufficient space to carry new games and consoles. As stores tried to return the surplus games to the new publishers, the publishers had neither new products nor cash to issue refunds to the retailers. Many publishers, including Games by Apollo and US Games, quickly folded. Unable to return the unsold games to defunct publishers, stores marked down the titles and placed them in discount bins and sale tables. Recently released games which initially sold for USD$35 were in bins for $5.[27] Crane said that "those awful games flooded the market at huge discounts, and ruined the video game business".[24] By June 1983, the market for the more expensive games had shrunk dramatically and was replaced by a new market of rushed-to-market, low-budget games.

A massive industry shakeout resulted. Magnavox abandoned the video game business entirely. Imagic withdrew its IPO the day before its stock was to go public; the company later collapsed.

As a result, while some stores sold new games and machines, most retailers stopped selling video game consoles or reduced their stock significantly, reserving floor or shelf space for other products. This was the most formidable barrier that confronted Nintendo, as it tried to market its Famicom system in the United States. Retailer opposition to video games was directly responsible for causing Nintendo to brand its product an "Entertainment System" rather than a "console", using terms such as "control deck" and "Game Pak", as well as producing a toy robot called R.O.B. to convince toy retailers to allow it in their stores.[28][29]

Despite Atari's claim of 1 million in sales of its 2600 game system in 1985,[30] recovery was slow. The sales of home video games had dropped considerably during this period, from $3 billion in 1982 to as low as $100 million in 1985[citation needed]. Following the release of the Nintendo Entertainment System, the industry began recovering, with annual sales exceeding $2.3 billion by 1988, with 70% of the market dominated by Nintendo.[31] In 1986, Nintendo president Hiroshi Yamauchi noted that "Atari collapsed because they gave too much freedom to third-party developers and the market was swamped with rubbish games". In response, Nintendo limited the number of titles that third-party developers could release for their system each year, and promoted its "Seal of Quality", which it allowed to be used on games and peripherals by publishers that met Nintendo's quality standards.[32]

The end of the crash allowed Commodore to raise the price of the C64 for the first time upon the June 1986 introduction of the Commodore 64c—a Commodore 64 redesigned for lower cost of manufacture—which Compute! cited as the end of the home-computer price war,[33][34] one of the primary causes of the crash.[35]

The North American video game crash had two long-lasting results. The first result was that dominance in the home console market shifted from the United States to Japan. By 1986, three years after its introduction, 6.5 million Japanese homes—19% of the population—owned a Family Computer, and Nintendo began exporting it to the U.S.[32] When the U.S. video game market recovered in the late 1980s the NES was by far the dominant console, leaving only a fraction of the market to a resurgent Atari. By 1989, home video game sales in the United States had reached $5 billion, surpassing the 1982 peak of $3 billion during the previous generation. A large majority of the market was controlled by Nintendo; it sold more than 35 million units in the United States, exceeding the sales of other consoles and personal computers by a considerable margin.[36] Other Japanese companies also rivaled Nintendo's success in the United States, with Sega's Mega Drive/Genesis in 1989 and NEC's PC Engine/TurboGrafx 16 released the same year.

A second, highly visible result of the crash was the institution of measures to control third-party development of software. Using secrecy to combat industrial espionage had failed to stop rival companies from reverse engineering the Mattel and Atari systems and hiring away their trained game programmers. While Mattel and Coleco implemented lockout measures to control third-party development (the ColecoVision BIOS checked for a copyright string on power-up), the Atari 2600 was completely unprotected and once information on its hardware became available, little prevented anyone from making games for it. Nintendo thus instituted a strict licensing policy for the NES that included equipping the cartridge and console with lockout chips, which were region-specific and had to match in order for a game to work. In addition to preventing the use of unlicensed games, it also was designed to combat piracy, rarely a problem in the United States or Europe, but rampant in East Asia.

Accolade achieved a technical victory in one court case against Sega, challenging this control, even though it ultimately yielded and signed the Sega licensing agreement. Several publishers, notably Tengen (Atari), Color Dreams, and Camerica, challenged Nintendo's control system during the 8-bit era by producing unlicensed NES games. The concepts of such a control system remain in use on every major video game console produced today, even with fewer "cartridge-based" consoles on the market than in the 8/16-bit era. Replacing the security chips in most modern consoles are specially encoded optical discs that cannot be copied by most users and can only be read by a particular console under normal circumstances.

Nintendo reserved a large part of NES game revenue for itself by limiting most third-party publishers to only five games per year on its systems (some companies tried to get around this by creating additional company labels like Konami's Ultra Games label). It also required all cartridges to be manufactured by Nintendo, and to be paid for in full before they were manufactured. Cartridges could not be returned to Nintendo, so publishers assumed all the risk. As a result, some publishers lost more money due to distress sales of remaining inventory at the end of the NES era than they ever earned in profits from sales of the games.

Nintendo portrayed these measures as intended to protect the public against poor-quality games, and placed a golden seal of approval on all licensed games released for the system. These strict licensing measures backfired somewhat after Nintendo was accused of trust behavior.[37] In the longer run, however, many third-party publishers such as Electronic Arts actively supported competing consoles such as the Sega Genesis. Most of the Nintendo platform-control measures were adopted by later console manufacturers such as Sega, Sony, and Microsoft, although not as stringently.|||

