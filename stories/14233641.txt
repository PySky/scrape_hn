On Thursday, Google announced that MIT math professor and computational number theorist Andrew V. Sutherland had set a record for the largest Google Compute Engine (GCE) job. Sutherland ran the massive mathematics workload on 220,000 GCE cores using preemptible virtual machine instances. This is the largest known high-performance computing cluster to run in the public cloud, according to Google’s Alex Barrett and Michael Basilyan.

Sutherland used Google’s cloud to explore generalizations of the Sato-Tate Conjecture and the conjecture of Birch and Swinnerton-Dyer to curves of higher genus, write Barrett and Basilyan on the Google Cloud Platform blog. “In his latest run, he explored 1017 hyperelliptic curves of genus 3 in an effort to find curves whose L-functions can be easily computed, and which have potentially interesting Sato-Tate distributions. This yielded about 70,000 curves of interest, each of which will eventually have its own entry in the L-functions and Modular Forms Database (LMFDB),” they explain.

Sutherland compared the quest to find suitable genus 3 curves to “searching for a needle in a fifteen-dimensional haystack.” It’s highly compute-intensive research that can require evaluating a 50 million term polynomial in 15 variables.

Before moving to the public cloud platform, Sutherland conducted his research locally on a 64-core machine but runs would take months. Using MIT clusters was another option, but there were sometimes access and software limitations. With Compute Engine, Sutherland can create a cluster with his preferred operating system, libraries and applications, the Google blog authors note.

According to Google, the preemtible VMs that Sutherland used are “full-featured instances that are priced up to 80 percent less than regular equivalents, but can be interrupted by Compute Engine.”

Since the computations are embarrassingly parallel, interruptions have limited impact and the workload can also grab available instances across Google Cloud Regions. Google reports that in a given hour, about 2-3 percent of jobs are interrupted and automatically restarted.

Coordinating instances was done with a combination of Cloud Storage and Datastore, which assigns tasks to instances based on requests from the Python client API. “Instances periodically checkpoint their progress on their local disks from which they can recover if preempted, and they store their final output data in a Cloud Storage bucket, where it may undergo further post-processing once the job has finished,” write the blog authors. Pricing for the 220,000-core cluster was not shared.

Sutherland is already planning an even larger run of 400,000 cores, noting that when you “can ask a question and get an answer in hours rather than months, you ask different questions.”

There have been several other notably large cloud runs conducted by HPC cloud specialist Cycle Computing over the years. In late 2013, Cycle spun up a 156,000-core AWS cluster for Schrödinger and the University of Southern California to power a quantum chemistry application. The year prior, Cycle Computing created a 50,000 core virtual supercomputer on AWS to facilitate Schrödinger’s search for novel drug compounds for cancer research. In November 2014, Cycle customer HGST ran a 1 million simulation job in eight hours to help identify an optimal advanced drive head design. At peak, the cluster incorporated 70,908 Ivy Bridge cores with a max theoretical performance of 729 teraflops.

Cycle has also leveraged the Google Compute Engine (GCE). In 2015, Cycle ran a 50,000-core cancer gene analysis workload for the Broad Institute using preemptible virtual machine instances.

Amazon Web Services has benchmarked several self-made clusters for the Top500 list. The most recent, a 26,496 core Intel Xeon cluster, entered the list in November 2013 at position 64 with 484 Linpack teraflops. As of November 2016, the cluster was in 334th position.|||

On Thursday, Google announced that MIT math professor and computational number theorist Andrew V. Sutherland had set a record for the largest Google Compute Engine (GCE) job. Sutherland ran the massive mathematics workload on 220,000 GCE cores using preemptible virtual machine instances.