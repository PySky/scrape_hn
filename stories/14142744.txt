Landauer's principle is a physical principle pertaining to the lower theoretical limit of energy consumption of computation. It holds that "any logically irreversible manipulation of information, such as the erasure of a bit or the merging of two computation paths, must be accompanied by a corresponding entropy increase in non-information-bearing degrees of freedom of the information-processing apparatus or its environment".[1]

Another way of phrasing Landauer's principle is that if an observer loses information about a physical system, the observer loses the ability to extract work from that system.[why?]

If no information is erased, computation may in principle be achieved which is thermodynamically reversible, and require no release of heat. This has led to considerable interest in the study of reversible computing.

At 20 °C (room temperature, or 293.15 K), the Landauer limit represents an energy of approximately 0.0172 eV, or 2.75 zJ. Theoretically, room‑temperature computer memory operating at the Landauer limit could be changed at a rate of one billion bits per second with energy being converted to heat in the memory media at the rate of only 2.85 trillionths of a watt (that is, at a rate of only 2.85 pJ/s). Modern computers use millions of times as much energy.[2][3][4]

Rolf Landauer first proposed the principle in 1961 while working at IBM.[5] He rigorously justified and stated important limits to an earlier conjecture by John von Neumann. For this reason, it is sometimes referred to as being simply the Landauer bound or Landauer limit.

In 2011 the principle was generalized to show that while information erasure requires an increase in entropy, that increase could theoretically occur at no energy cost[6] (instead, the cost can be taken in another conserved quantity like angular momentum).

In a 2012 article published in Nature, a team of physicists from the Ecole Normale Supérieure de Lyon, University of Augsburg and the University of Kaiserslautern described that for the first time they have measured the tiny amount of heat released when an individual bit of data is erased.[7]

In 2014 physical experiments tested Landauer's principle and confirmed its predictions.[7][8]

In 2016 researchers used a laser probe to measure the amount of energy dissipation that resulted when a nanomagnetic bit flipped from off to on. Flipping the bit required 15 millielectron volts (3 zeptojoules).[9]

Landauer's principle can be understood to be a simple logical consequence of the second law of thermodynamics—which states that the entropy of an isolated system cannot decrease—together with the definition of thermodynamic temperature. For, if the number of possible logical states of a computation were to decrease as the computation proceeded forward (logical irreversibility), this would constitute a forbidden decrease of entropy, unless the number of possible physical states corresponding to each logical state were to simultaneously increase by at least a compensating amount, so that the total number of possible physical states was no smaller than originally (total entropy has not decreased).

Yet, an increase in the number of physical states corresponding to each logical state means that, for an observer who is keeping track of the logical state of the system but not the physical state (for example an "observer" consisting of the computer itself), the number of possible physical states has increased; in other words, entropy has increased from the point of view of this observer.

The maximum entropy of a bounded physical system is finite. (If the holographic principle is correct, then physical systems with finite surface area have a finite maximum entropy; but regardless of the truth of the holographic principle, quantum field theory dictates that the entropy of systems with finite radius and energy is finite due to the Bekenstein bound.) To avoid reaching this maximum over the course of an extended computation, entropy must eventually be expelled to an outside environment.

Landauer's principle asserts that there is a minimum possible amount of energy required to erase one bit of information, known as the Landauer limit:

where k is the Boltzmann constant (approximately 1.38×10−23 J/K), T is the temperature of the circuit in kelvins, and ln 2 is the natural logarithm of 2 (approximately 0.69315).

For an environment at temperature T, energy E = ST must be emitted into that environment if the amount of added entropy is S. For a computational operation in which 1 bit of logical information is lost, the amount of entropy generated is at least k ln 2, and so, the energy that must eventually be emitted to the environment is E ≥ kT ln 2.

The principle is widely accepted as physical law; but in recent years it has been challenged[how?], notably in Earman and Norton (1998), and subsequently in Shenker (2000)[10] and Norton (2004,[11] 2011[12]), and defended by Bennett (2003)[1] and Ladyman et al. (2007).[13]|||

