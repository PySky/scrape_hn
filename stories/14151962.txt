Now that we’ve got the pieces working, it’s time to build our masterpiece.

We do want to check and make sure that consumption of PubNub’s Twitter stream is working, so let’s get to it!

Twitter does have their own API, but PubNub has made consuming it easy by providing us with a public subscription key. As I noted in Part 2, PubNub’s Twitter stream only pulls in 50 messages a second, but we’re throttling the number of messages sent to IBM Watson’s sentiment analysis to just 1,000/day anyways.

If you’re interested in sifting through all of the tweets every second because you have a less popular keyword, or if you’re paying for IBM’s services, checkout the last section: BONUS — Part 7: The Ultimate Stream

I initially wrote this project in Python because that’s the language I’m most familiar in, but I’ve gone ahead and added Node JS versions of all the scripts too! These could easily be adapted into another language thanks to PubNub’s many SDKs.

To use PubNub on your own machine (or perhaps a Raspberry Pi?), you need to install it using the command line:

You can see other installation methods here.

To see if the Twitter feed will work, just run the twitterTest.py script! You can copy it to your computer by saving it to a folder you usually run code from or by creating a file with and pasting it.

Give it a second or two to actually find a tweet that matches our criteria on line 32 ([‘Trump’,’trump’,’POTUS’,’potus’]), and you should start seeing messages print out:

If that works, we can move on to the master script!

To use PubNub on your own machine, you need to install it using the command line:

You can see other installation methods here.

To see if the Twitter feed will work, just run the twitterTest.js script! You can copy it to your computer by saving it to a folder you usually run code from or by creating a file with and pasting it.

Give it a second or two to actually find a tweet that matches our criteria on line 16 (Trump, trump, or any capitalization of POTUS), and you should start seeing messages print out:

If that works, we can move on to the master script!

The most important thing you need to do before you try to run this script is add your PubNub keys:

Lines 1–5 import all of our modules.

Lines 7–20 are where we configure PubNub with both the public Twitter key and the private keys associated with our account.

Lines 23–33 handle the results of any publish call and will tell us if a publish was successful.

Lines 36–71 handle the subscription to the Twitter stream. If you want to change what keywords are looked for, you can do so on line 40 (‘Donald’ was omitted because I kept picking up tweets about McDonald’s). Starting at line 64, we actually handle the tweets — first searching for any of the keywords and then publishing the message to our sentiment-analysis channel (which is associated with the IBM Watson block).

Lines 74–134 handle the subscription to the sentiment analysis output. On line 78 we specify our Initial State bucket key (“pubnubtrump”). We will need this to create our bucket in Initial State! Lines 99–134 handle the sentiment analysis response. We build the payload to send to our Initial State block here (using the merge function on lines 137–145) and then publish it.

Lines 149–155 are where we configure our PubNub channel subscriptions and tell them which callback class to use.

You should see the payload start printing out and output in your PubNub block debug console!

The most important thing you need to do before you try to run this script is add your PubNub keys:

Lines 3–12 are where we configure PubNub with both the public Twitter key and the private keys associated with our account.

Lines 17–40 handle the subscription to the Twitter stream. If you want to change what keywords are looked for, you can do so on line 25 (‘Donald’ was omitted because I kept picking up tweets about McDonald’s). Starting at line 25, we actually handle the tweets — first searching for any of the keywords and then publishing the message to our sentiment-analysis channel (which is associated with the IBM Watson block).

Lines 42–88 handle the subscription to the sentiment analysis output. On line 48 we specify our Initial State bucket key (“pubnubtrump”). We will need this to create our bucket in Initial State! Lines 51–85 handle the sentiment analysis response. We build the payload to send to our Initial State block here and then publish it.

Lines 91–99 are where we configure our PubNub channel subscriptions.

You should see the payload start printing out and output in your PubNub block debug console!

Time to check the tweets out in a dashboard.

Time to look at our dashboard! We need to create a bucket with the bucket key from our script like we did in Part 3.

So click the +cloud icon at the top of your bucket shelf to create a new streaming bucket. Name your bucket and check the “Configure Endpoint Keys” box to specify the bucket key.

This must match the key you just sent through PubNub so enter “pubnubtrump”. I named my bucket “Trump Twitter 🐦”.

Click the “Create” button at the bottom and the new bucket should be listed at the top of your shelf.

Click on that bucket and you should see Tiles pop up for Tweet, Positive Level, Neutral Level, Negative Level, and Score.

If you want to make your dashboard both more informative and attractive, keep reading!

You can find support articles on what you can do in Tiles, but I’m going to walk through the main things I changed with links to the relevant support article:

And now you have a beautiful dashboard that updates in realtime! It’s also interactive — mouse over the different tiles to see signal names and values:|||

How to build a live dashboard that analyzes and publishes the sentiment of Tweets related to a keyword in realtime with IBM Watson, Bluemix, PubNub, and Initial State.