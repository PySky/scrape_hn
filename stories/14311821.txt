Spin up Kubernetes and gain a perspective on your deployments.

[Guest blog post by Matt Baldwin , CEO of Stack Point Cloud — the Universal Control Plane for Kubernetes Anywhere]

Kubernetes is the king of container orchestration and scheduling, beating out rivals like Docker Swarm and Apache Mesos to open up a future where microservices can self-heal, can autoscale, can federate across zones, regions, even cloud providers. With this new era in Cloud Native applications it is increasingly important to be able to peer into how our services are interoperating with one and the other in a simple way — that doesn’t feel like searching the figurative hay for that needle causing your performance problems.

We spent some time sitting with Netsil and packaging their solution as a native Kubernetes Deployment. Netsil’s application, Application Operations Center (AOC), helps you observe and collect analytics for the microservice application(s) running across your Kubernetes cluster. It is agnostic about the services as it taps the network to determine what’s exactly going on. Over time, and in real-time, it learns and discovers your environment, enabling you to begin to set up SLA indicators, alerts, and so forth.

You’ll first need a Kubernetes cluster. I used Stackpoint.io to quickly create a cluster. Spin one up at any of the leading providers, such as AWS, GCE, or Azure. You’ll want to ensure you choose a larger size for your master node — it’s where all collectors will be sending their data and can become chatty on net, processor, and memory. Your worker nodes can be whatever size your microservice application along with anything else require. In my examples I’m using larger instance sizes as I’m pushing a variety of services into the environment.

For our example, we built out a handy cluster on GCE using three N1 Standard 4 instances exposed via an HAProxy Ingress Controller, which will self-discover and register the AOC services once we deploy them. We’ll be able to hit the AOC dashboard using the cluster’s public VIP.

To give ourselves something to look at besides an empty cluster running only the Kubernetes services, we will use Sock Shop, a microservice reference application developed by Weaveworks. This will help us simulate a real world environment; Sock Shop uses 14 different services, a level of complexity you might find with many organizations and their applications. With this in mind, let’s jump into adding AOC to our environment.

You can read about Sock Shop here. Pushing it into the environment is as easy as running the following command once you’ve cloned the repo:

Then check to see if your Pods have come online:

Now that we have a running Kubernetes 1.4 cluster online with our Sock Shop installed it’s time for us to begin to learn what’s what in our environment. Do we have any issues we’re not aware of causing problems for buyers of socks?

You’ll want to run the following command on all your hosts before deploying the AOC. This will help you work around a known race condition with Flannel and kube-proxy.

Replace host-private-ip with the private IP of each host. Once done, clone the Netsil manifests repo:

Go into the kubernetes folder and apply the Netsil Kubernetes manifest with a single command.

Let’s make sure our Pods and Services have come online. It might take a few minutes for the AOC container to pull down, but the collectors will be up and queueing data to be pushed in as they already begin to discovery your environment.

The AOC topology has two principle components. The first is a Pod running as part of a Replication Controller with a single replica. This runs the AOC dashboard and platform for data collection. The second component is a DaemonSet for the AOC collector. This tells Kubernetes to run a Pod with the collector container on all nodes in the environment. These collectors are configured to send traffic to the AOC Pod.

We’re going to use some more tools from the Sock Shop to simulate a bit of shopping on the site. This will allow us to watch as the AOC learns the traffic patterns and our general topology.

You’ll want to take the frontend IP address and port your Sock Shop is listening on and run:

As the load-test runs, you should start to see the AOC light up with data:

Since AOC deploys as a DaemonSet if any of your Pods die and get rescheduled elsewhere the AOC continues to observe your topology, shifting as Kubernetes shifts.

One of the neat things I like about the AOC is my deployments are grouped by service and I can watch my environment in real-time and begin to dig into different metrics, setting up service level alerts for things that could impact my customers. So, when my environment goes red like the below screenshot I can be alerted when one of my services is operating in a critical state, such as the cards and addresses endpoints in my Sock Shop.

I can even dig into the dashboards to get a view of what my top Pods and containers might be. In this case, my flannel Pod is the top container for network out as I’d expect. This gives me insight into where the most chatty services live, maybe prompting me to re-think my sizing or how I distribute deployments within Kubernetes.

Netsil’s AOC is a wonderful tool that helps you observe your environment in real-time, updating as usage patterns change. You can dig into historical data and noodle around with adding alerts. The application automatically scales as you add more nodes, spinning up a collector on the new node once it comes online so you don’t lose any metrics from the birth of a machine to its death.

If you want to work with the Application Operations Center in your own Kubernetes environment, pull down the manifests here and enjoy. You can learn more about Netsil and the Application Operations Center and get started for free at Netsil|||

Monitor kubernetes pods and containerized applications without any code instrumentation with the NETSIL Application Operations Center (AOC)