In my initial implementation of our lightmapping technology I simply stored lightmap textures in RGBA16F format. This produced excellent results, but at a very high memory cost. I later switched to the R10G10B10A2 fixed point format to reduce the memory footprint of our lightmaps, but that introduced some quantization artifacts. At first glance it seemed that we would need more than 10 bits per component in order to have smooth gradients! At the time the RGBM color transform seemed to be a popular way to encode lightmaps. I gave that a try and the results weren't perfect, but it was a clear improvement and I could already think of several ways of improving the encoder. Over time I tested some of these ideas and managed to improve the quality significantly and also reduce the size of the lightmap data. In this post I'll describe some of these ideas and support them with examples showing my results. I believe the RGBM transform was first proposed by Capcom in these CEDEC 2006 slides . While Capcom employs it for diffuse textures, it has become a popular way to encode lightmaps. RGBM or some of its variations are used in Unity Bioshock Infinite , and the Unreal Engine, among others. Its use for standard color textures is not as widespread, but Shane Calimlim found it to be a good fit for the stylized artwork of Duck Tales and suggests it could be a good format in general. However, with so many precedents, I was surprised it had not been analyzed in more detail. The main challenge of compressing lightmaps is that often they have a wider range than regular diffuse textures. This range is not as large as in typical HDR textures, but it's large enough that using regular LDR formats results in obvious quantization artifacts. Lightmaps don't usually have high frequency details, they are often close to greyscale, and only have smooth variations in the chrominance. In our case, most our lightmap values are within the [0, 16] range, and in the rare occasions when they are outside of that range, we constrain them clamping the colors while preserving the hue to avoid saturation artifacts. Brian Karis also suggests tone mapping the upper section of the range to avoid sharp discontinuities, but I only found this to be a problem when light sources had unreasonably high intensity values. The shape of the lightmap color distribution varies considerably. Interior lightmaps are predominantly dark with a long tail of brighter highlights:while outdoor lightmaps have a more Gaussian distribution with a bell-like shape. This particular lightmap is under the shade of some colored fall trees, which give it an orange tone:Not all lightmaps use all the available range, so after tone mapping the next thing we do is to scale the range to [0, 1]. So, why is RGBM a good choice for data like this? The distribution of distinct values that can be represented with RGBM looks as follows:It provides much more precision toward 0 than toward 1. This is beneficial for images that are intended to be visualized at multiple exposures. We want to obtain smooth lightmaps without quantization artifacts independently of the camera exposure. However, as we will see later, this provides much more precision around 0 than is actually necessary.In my initial implementation I simply used RGBA8 textures, squaring the colors to perform gamma correction in the shader. The standardtransform is as follows:A simple improvement I did early on is to divide the quantization interval in two. This is a variation of the idea presented in Microsoft's LUVW HDR texture paper , but instead of using an extra texture, I simply rely on the RGB and alpha (M) channels. A similar observation is done by Shane Calimlim But in our case grey is not really an edge case! Lightmaps are mostly grey with slight smooth color variations. The way I implemented this is by choosing a certain threshold. For values ofthat are lower thanthe color is fully encoded using only the RGB components as follows:and for values ofgreater than the threshold, the normalized color is encoded in the RGB components, and the normalization factoris biased and scaled to store it at a higher precision:That's equivalent to just doing:This is useful for several reasons. As Shane notes, splitting the burden of representing the luminance between the RGB and M maps we can obtain more precision and reduce the size of the quantization interval. It's important to note that this actually reduces precision around zero, where we don't actually need so much, because the game camera never has long enough exposures. If we look at the distribution of grey levels that biased RGBM can represent it now looks as follows:Picking different values ofallows us to use different quantization intervals for different parts of the color range. The optimal choice ofdepends on the distribution of colors in the lightmap and the number of bits used to represent each of the components. We chose this value experimentally. For our lightmaps values around 0.3 seemed to work best when encoding them in RGBA8 format.With these improvements RGBM was already producing very good results. Visually I could not see any difference between the RGBM lightmaps and the raw half floating point lightmaps. However, I had not reduced the size of the lightmaps by much and ideally I wanted to compress them further. The next thing that I tried to do was to choosein a way that minimizes the quantization error. I did that by brute force, trying all possible values of, computing the correspondingvalues for that choice of, and selecting the one that minimized the MSE:This improved the error substantially, but it introduced interpolation artifacts. The RGBM encoding is not linear, so interpolation of RGBM colors is not correct. With the naive method this was not a big deal, because adjacent texels usually had similar values of, but thevalues resulting from this optimization procedure were not necessarily similar anymore. However, it was easy to solve this problem by constraining the search to a small range around thevalue selected with the naive method:This constrain did not reduce the quality noticeably, but eliminated the interpolation artifacts entirely. While this idea showed that there's a significant optimization potential over the naive approach, it did not get us any closer to our stated goal: to reduce the size of the lightmaps. I tried to use a packed pixel format such as RGBA4, but even with the optimized encoding, it did not produce sufficiently high quality results. To reduce the size further we would have to use DXT block compression.Simply compressing the RGBM data produced poor results and compressing the optimized RGBM data did not help, but instead only degraded the results even more. A brute force compressor is not practical in this case, because when processing blocks of 4x4 colors simultaneously the search space is much larger. A better approach is to first compress thevalues obtained through the naive procedure using a standard DXT1 compressor and then choosing thevalues to compensate for the quantization and compression errors of the DXT1 component. That is, we want to computeso that:This gives us three equations that we can minimize in the least squares sense. Thethat minimizes the error is:In my tests, the resulting's compress very well in the alpha map and reduced the error significantly. I also tried to encodeagain with the newly obtained, and compress them afterward, but in most cases that did not improve the error. Something that worked well was to simply weight theerror byin the initial compression step. The number of bits allocated for theandcomponents is very different than in our initial RGBA8 texture, so the choice ofhad to be reviewed. In this case values ofaround 0.15 produced best results. I attribute this to the reduced number of bits per pixel used to encode thechannels.In addition to the described formats I also compared the proposed method against BC6. BC6 is specifically designed to encode HDR textures, but it's not available in all hardware. Our optimized RGBM-DXT5 scheme provides nearly the same quality as BC6:The above chart is displaying RMSE values of the final images after color space conversion and range rescaling. To study the effectiveness of the encoders it's more useful to look at the errors before rescaling. These look a lot more uniform, but cannot be compared against BC6 anymore, since in that case adjusting the range of the input values does not usually reduce the compression error.Finally, I thought it would be interesting to use RGBM-DXT5 to compress standard images and compare it against YCoCg-DXT5. The following chart shows the results for the first 8 images of the kodim image set:YCoCg-DXT5 is clearly a much better choice for LDR color textures.Our proposed RGBM encoder was good enough for our lightmaps, but I'm convinced there's more room for improvement. One idea would be to pick a different thresholdfor each texture. Finding the bestfor a given texture to be encoded using the plain RGBM linear format would be easy, but it's not so obvious when using block compression. The RGB components are encoded with a standard weighted DXT1 compressor. It would be interesting to use a specialized compressor that favoredvalues with errors that thecomponent could correct. For example, thevalues resulting from the least squares minimization are sometimes above 1, but need to be clamped to therange, it should be possible to constrain theendpoints to prevent that. It may also be possible to chooseendpoints such that the error of the least squares fittedare as small as possible. Finally, DXT5 is not available on most mobile GPUs. I haven't tried this yet, but it seems the ETC2 EAC_RGBA8 format is widely available and would be a good fit for the techniques presented here. It would also be interesting to compare our method against packed floating point formats such as (R11G11B10_FLOAT R9G9B9E5_SHAREDEXP) and ASTC's HDR mode.In all cases I measured the error using the RMSE metric, which is the same metric used to guide the block compressors. It may make more sense to use a metric that takes into account how the lightmaps are visualized in the game. I did exactly that, tone map the lightmaps at different exposures and compute the error in post-tone-mapping space. The tables below show the resulting values and they roughly correlate with the plain RMSE metric.|||

