If you build a web-service around content, then it is a matter of time when you need to introduce a search functionality.

Depending on the shape of your data you may go the easiest way: search using a regular expression against some field (title, name, etc.). But what if you have more than one field? What if the data is spread across several collections? You would probably also want to have a ‘search rank,’ i.e. to know how close the match is.

This way the simple solution will not work anymore. Or it won’t be simple.

‘Classic’ solution for this problem is to pick something like Elastic Search or Apache Lucene. But if you are running on MongoDB, then there is no need to introduce another dependency into your stack. You can use the MongoDB Full-Text Search and MongoDB Aggregation Framework to build powerful search functionality.

I highly recommend to create a database locally, import sample data and follow my actions step by step. I crafted small data set. The data is normalized on purpose. I chose the “worst” case to show a real-world application.

Just connect to some sandbox database locally (you can pick any other name):

Now we are ready to go further.

Given this dataset, we already can look for books based on a dumb simple regular expression. The ‘i’ at the end means that we want the search to be case-insensitive.

The same works just perfect if we are interested in fantasy in general.

However, this approach might be slow, especially if we add few more fields. Also, it probably makes sense to order results based on some criteria. E.g., matches by title go first, then go matches by genres.

This way we would need to do few searches, for each field, and then combine results manually.

Fortunately, there is a much better approach.

MongoDB supports text indexes that enable Full Text Search. The great thing about text indexes: they provide , which is controlled via . Here is an example:

Please, notice the entry. Numbers there are pretty random, just to show that the is more relevant than genres and languages.

Now we can use powerful operator. The result will have some ‘hidden’ metadata attached, from which we can get the .

We can sort results based on the :

We will get the following:

It looks awesome and definitely much better than naive regex-based search. But, there is another problem:

Here the Aggregation Framework comes into play.

To search through authors, we can craft another collection, which will serve us a very accurate search index. It will have the following form:

To create this collection, we will use aggregation pipeline. The algorithm is the following:

It can be expressed using ‘aggregation language’:

Let’s look at each stage in the pipeline.

joins two collections using and as a connection. results in an array. In our case, the array always contains one element.

To get rid of the array we use , which creates a copy of a document for each entry.

Then we use to shape the data.

At the very end of the pipeline, we use operator who puts all results into another collection. overrides all existing records.

Now, given the new collection, we can create a text index on it as we did initially with .

Again, the weights are random. Let’s check out previous results.

Awesome. Though, we are getting back documents from , not from . We can easily fix this using aggregation framework:

To make it work correctly, we would just need to keep up to date. The update can be easily triggered via a Cron task. Or after each change in the database.

Full-Text Search is very common requirement in software development. The implementation itself is not straightforward, but nowadays one could easily integrate working solution in a couple of hours.|||

This article shows how to build a real-world full text search using MongoDB Aggregation Framework