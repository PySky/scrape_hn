In The Bicentennial Man by science fiction writer Isaac Asimov, a robot named Andrew Martin campaigns to be treated as a human. Unlike most robots of his day, Andrew exhibits extremely human qualities, such as creativity and emotions, and begins to dress like a man and modify his body to look more like a man. The novelette raises the question of what it means to be human, whether a robot might be regarded as a human being if it has enough qualities in common with humans, and what rights it ought to have if that is so.

Similar questions arise when we consider a sufficiently advanced computer simulation of humanity.

If it is the case that we live in a computer simulation run by far more advanced humans, as Tesla and SpaceX chief Elon Musk famously claimed at the 2016 Code Conference, then a natural question arises: What is the moral status of those of us in the simulation?

I can only speak for myself, but it sure seems like the emotions I experience are genuine. I feel pain, happiness, disappointment, distress, and desire. I am capable of introspection. I have a sense of an interior self. And I am a moral creature; I have a conscience that troubles me when I do bad and is satisfied when I do good.

Even if I am, as Andrew Martin is, something other than a natural-born human, and even if my life exists only in a futuristic data center’s supercomputers, rather than in base reality, do I not possess enough human qualities that I should be regarded, in a moral sense, as human, and endowed with certain rights?

In various fields of clinical research, human trials are a special case, guided by codes of ethics and regulations that recognize that human subjects deserve protections that are not afforded to animal subjects. These codes of ethics prohibit scientists from, for instance, intentionally cause a spinal cord injury to a human subject for research purposes, though it can be done in rats for sufficient reason.

It would seem that the creators of any computer program that simulates humans who are capable of self-awareness would need to confront these ethical considerations. If it is unethical to subject a human to excruciating pain for research purposes, is it not similarly unethical to subject a simulated human to excruciating pain, if that simulated human is indistinguishable from a real human except in its existence in base reality?

The fact that we do experience pain, misery, and injustice in a way that feels awfully real to us is a powerful argument against the idea that we are living in a computer simulation.

If we were the product of a simulation, it would mean that the creators of such a simulation are willing to subject us to unspeakable atrocities, all in the name of what? Historical research? Video games? What purpose would be noble enough to permit us to experience torture, malnourishment, or suffocation?

We can therefore conclude that unless the creators of such a simulation were utterly depraved, they would not actually run it.

This is not, of course, a proof that we are not in a computer simulation. It merely points out that this other horrific thing — a total disregard for human suffering by the creator* of the simulation — must also be true for the simulation argument to be correct.

* You might be wondering whether the same logic can be used to argue not only that we have no creators in the sense of a computer simulation, but that we have no Creator, even if we live in base reality.

Yes, the argument can be used — it’s a spin on the classic problem of evil — but it should be pointed out that there are various defenses that may apply to theism, depending on how it is defined, that don’t apply to human creators of a simulation. For instance, Augustine argued that God does not permit any type of evil unless he is able to bring good out of it, either during our earthly life or in the afterlife. But both human creators and any simulation they create are fundamentally finite, while God is classically defined as being infinite and omnipotent. It might be argued that human creators lack the omnipotence and the simulation lacks the infinite capacity that would be required to bring about a final justice commensurate with the level of suffering that occurs within the simulation, whereas an omnipotent creator is not so constrained.|||

In The Bicentennial Man by science fiction writer Isaac Asimov, a robot named Andrew Martin campaigns to be treated as a human. Unlike most robots of his day, Andrew exhibits extremely human…