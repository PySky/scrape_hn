nteract: Building on top of Jupyter (from a rich REPL toolkit to interactive notebooks)

This post originally appeared on the nteract blog.

nteract builds upon the very successful foundations of Jupyter. I think of Jupyter as a brilliantly rich REPL toolkit. A typical REPL (Read-Eval-Print-Loop) is an interpreter that takes input from the user and prints results (on stdout and stderr).

 ​

 Here’s the standard Python interpreter; a REPL many of us know and love.

The standard terminal’s spartan user interface, while useful, leaves something to be desired. IPython was created in 2001 to refine the interpreter, primarily by extending display hooks in Python. Iterative improvement on the interpreter was a big boon for interactive computing experiences, especially in the sciences.

As the team behind IPython evolved, so did their ambitions to create richer consoles and notebooks. Core to this was crafting the building blocks of the protocol that were established on top of ZeroMQ , leading to the creation of the IPython notebook. It decoupled the REPL from a closed loop in one system to multiple components communicating together.

It’s an establishment of well-defined protocols and formats. It’s a community of people who come together to build interactive computing experiences. We share our knowledge across the sciences, academia, and industry — there’s a lot of overlap in vision, goals, and priorities. That being said, one project alone may not meet with everyone’s specific needs and workflows. Luckily, with strong support by Jupyter’s solid foundation of protocols to communicate with the interpreters (Jupyter kernels) and document formats (e.g. .ipynb), you too can build your ideal interactive computing environment. In pursuit of this, members of the Jupyter community created nteract, a Jupyter notebook desktop application as well as an ecosystem of JavaScript packages to support it and more.

To explore this, I will describe the Jupyter protocol with a lightweight (non-compliant) version of the protocol that hopefully helps explain how this works under the hood.

Also a lightweight Hello WorldWhen a user runs this code, a message is formed:

We send that message and receive replies as JSON:

As multiple outputs come in, they get appended to the display area below the code editor.

Let’s send that code over to see

The power and simplicity of the protocol emerges when using the execute_result and display_data message types. They both have a data field with multiple media types for the frontend to choose how to represent. Pandas provides text/plain and text/html for tabular data

When the front-end receives the HTML payload, it embeds it directly in the outputs so you get a nice table:

We’ve witnessed how our code gets sent across to the runtime and what we receive on the notebook side. How do we form a notebook? How do we associate messages to the cells they originated from?

 ​

 We need an ID to identify where an execute_request comes from. Let’s bring in the concept of a message ID and form the cell state over time

We send the execute_request as message 0001

Each message afterward lists the originating msg_id as parent_id 0001. Responses start flowing in, starting with

Which we can store as part of the state of our cell

Here comes the plain text output in

Which we fold into an outputs structure of our cell

Finally, we receive a status to inform us the kernel is no longer busy

Resulting in the final state of the cell

That’s just one cell though —what would an entire notebook structure look like? One way of thinking about a notebook is that it’s a rolling work log of computations. A linear list of cells. Using the same format we’ve constructed above, here’s a lightweight notebook:

​As well as the rendered version:

As Jupyter messages are sent back and forth, a notebook is formed. We use message IDs to route outputs to cells. Users run code, get results, and view representations of their data:|||

