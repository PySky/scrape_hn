This guide is intended to link to the best resources for people learning Machine Learning and Deep Learning.

Machine Learning at its most basic is the practice of using algorithms to parse data, learn from it, and then make a determination or prediction about something in the world. So rather than hand-coding software routines with a specific set of instructions to accomplish a particular task, the machine is “trained” using large amounts of data and algorithms that give it the ability to learn how to perform the task.

Deep learning is a class of machine learning algorithms that:

Andrew Ng's ML-Class at coursera: Focused on application of techniques. Easy to understand, but mathematically very shallow. This is good resource for beginners. Yaser Abu-Mostafa's Learning From Data: Focuses a lot more on theory, but also doable for beginners. Geoff Hinton's Neural Nets for Machine Learning: this resource is almost exclusively about Neural Networks. Daphne Koller's Probabilistic Graphical Models is a very challenging class, but has a lot of good material that few of the other MOOCs will cover. It covers two basic PGM(Probabilistic graphical models) representations: Bayesian Networks, which rely on a directed graph; and Markov networks, which use an undirected graph. The course discusses both the theoretical properties of these representations as well as their use in practice. AI: A Modern Approach by Stuart Russell and Peter Norvig offers a comprehensive introduction to the theory and practice of artificial intelligence. This is a highly acclaimed book and is approachable for beginners.

Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. Written by leading researchers, this is an approachable book for beginners. Fast.ai course on Deep Learning is a practical deep learning course for anyone who has at least a year's worth of programming experience. It's a hands on course and uses AWS for teaching. Stanford CS231n: Convolutional Neural Networks for Visual Recognition is another great resource to understand RNNs. The lecture notes can be found here. UC Berkeley Stat212b: Topics Course on Deep Learning aims to present the mathematical, statistical and computational challenges of building stable representations for high-dimensional data, such as images, text and audio. It delves into selected topics of Deep Learning, discussing recent models from both supervised and unsupervised learning. Special emphasis is on convolutional architectures, invariance learning, unsupervised learning and non-convex optimization.

An Introduction to Statistical Learning : his book provides an introduction to statistical learning methods. It is aimed for upper level undergraduate students, masters students and Ph.D. students in the non-mathematical sciences. The book also contains a number of R labs with detailed explanations on how to implement the various methods in real life settings, and should be a valuable resource for a practicing data scientist. Probabilistic Programming and Bayesian Methods for Hackers is designed as an introduction to Bayesian inference from a computational/understanding-first, and mathematics-second, point of view. For the mathematically trained, they may cure the curiosity this text generates with other texts designed with mathematical analysis in mind. For the enthusiast with less mathematical-background, or one who is not interested in the mathematics but simply the practice of Bayesian methods, this text should be sufficient and entertaining. Linear Algebra by MIT : This is a basic subject on matrix theory and linear algebra. Emphasis is on systems of equations, vector spaces, determinants, eigenvalues, similarity, and positive definite matrices. Introduction to Probability by edx. This course is an introduction to probabilistic models, including random processes and the basic elements of statistical inference.|||

