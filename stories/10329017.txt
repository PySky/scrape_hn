In aesthetics, the uncanny valley is the hypothesis that human replicas which appear almost, but not exactly, like real human beings elicit feelings of eeriness and revulsion among some observers.[2] Valley denotes a dip in the human observer's affinity for the replica, a relation that otherwise increases with the replica's human likeness.[3] Examples can be found in robotics, 3D computer animations, and lifelike dolls among others. With the increasing prevalence of virtual reality, augmented reality, and photorealistic computer animation, the 'valley' has been cited in the popular press in reaction to the versimilitude of the creation as it approaches indistinguishability from reality. For example, Telus's attempt to replace real animals in advertisements with animations like this wound up firmly in the 'uncanny valley' and had negative, not positive, impact on those viewing the spots. Similar reactions can occur with special effects where care is not taken to either break away from the audience's expectation of reality completely or honor it (People and objects noticably not traveling in proper parabolic arcs when knocked flying, or real human bodies clearly being subject to loads that would not be survivable in reality—the flight of Tom Cruise from helicopter to train at the end of Mission Impossible failed both of these tests.) The 'uncanny valley' has therefore moved from its origin about reactions to human simulacra, to reactions about photorealistic simulacra in general.

The concept was identified by the robotics professor Masahiro Mori as Bukimi no Tani Genshō (不気味の谷現象) in 1970.[4] The term was first translated as uncanny valley in the 1978 book Robots: Fact, Fiction, and Prediction, written by Jasia Reichardt,[5] thus forging an unintended link to Ernst Jentsch's concept of the uncanny,[6] introduced in a 1906 essay "On the Psychology of the Uncanny."[7][8][9] Jentsch's conception was elaborated by Sigmund Freud in a 1919 essay entitled "The Uncanny" ("Das Unheimliche").[10]

Mori's original hypothesis states that as the appearance of a robot is made more human, some observers' emotional response to the robot become increasingly positive and empathic, until it reaches a point beyond which the response quickly becomes strong revulsion. However, as the robot's appearance continues to become less distinguishable from a human being, the emotional response becomes positive once again and approaches human-to-human empathy levels.[12]

This area of repulsive response aroused by a robot with appearance and motion between a "barely human" and "fully human" entity is the uncanny valley. The name captures the idea that an almost human-looking robot seems overly "strange" to some human beings, produces a feeling of uncanniness, and thus fail to evoke the empathic response required for productive human–robot interaction.[12]

A number of theories have been proposed to explain the cognitive mechanism underlying the phenomenon:

A series of studies experimentally investigated whether Uncanny Valley effects exist for static images of robot faces. Mathur MB & Reichling DB[27] used two complementary sets of stimuli spanning the range from very mechanical to very human-like: first, a sample of 80 objectively chosen robot face images from Internet searches, and second, a morphometrically and graphically controlled 6-face series set of faces. They asked subjects to explicitly rate the likability of each face. To measure trust toward each face, subjects completed a one-shot investment game to indirectly measure how much money they were willing to "wager" on a robot's trustworthiness. Both stimulus sets showed a robust Uncanny Valley effect on explicitly-rated likability and a more context-dependent Uncanny Valley on implicitly-rated trust. Their exploratory analysis of one proposed mechanism for the Uncanny Valley, perceptual confusion at a category boundary, found that category confusion occurs in the Uncanny Valley but does not mediate the effect on social and emotional responses.

One study conducted in 2009 examined the evolutionary mechanism behind the aversion associated with the uncanny valley. A group of five monkeys were shown three images: two different 3D monkey faces (realistic, unrealistic), and a real photo of a monkey's face. The monkeys' eye-gaze was used as a proxy for preference or aversion. Since the realistic 3D monkey face was looked at less than either the real photo, or the unrealistic 3D monkey face, this was interpreted as an indication that the monkey participants found the realistic 3D face aversive, or otherwise preferred the other two images. As one would expect with the uncanny valley, more realism can lead to less positive reactions, and this study demonstrated that neither human-specific cognitive processes, nor human culture explain the uncanny valley. In other words, this aversive reaction to realism can be said to be evolutionary in origin.[39]

As of 2011, researchers at University of California, San Diego and California Institute for Telecommunications and Information Technology are measuring human brain activations related to the uncanny valley.[40][41] In one study using fMRI, a group of cognitive scientists and roboticists found the biggest differences in brain responses for uncanny robots in parietal cortex, on both sides of the brain, specifically in the areas that connect the part of the brain’s visual cortex that processes bodily movements with the section of the motor cortex thought to contain mirror neurons. The researchers say they saw, in essence, evidence of mismatch or perceptual conflict.[20] The brain "lit up" when the human-like appearance of the android and its robotic motion "didn’t compute". Ayşe Pınar Saygın, an assistant professor from UCSD, says "The brain doesn’t seem selectively tuned to either biological appearance or biological motion per se. What it seems to be doing is looking for its expectations to be met – for appearance and motion to be congruent."[42][43][44]

Viewer perception of facial expression and speech and the uncanny valley in realistic, human-like characters intended for video games and film is being investigated by Tinwell et al., 2011.[45] Consideration is also given by Tinwell et al. (2010) as to how the uncanny may be exaggerated for antipathetic characters in survival horror games.[46] Building on the body of work already undertaken in android science, this research intends to build a conceptual framework of the uncanny valley using 3D characters generated in a real-time gaming engine. The goal is to analyze how cross-modal factors of facial expression and speech can exaggerate the uncanny. Tinwell et al., 2011[47] have also introduced the notion of an unscalable uncanny wall that suggests that a viewer’s discernment for detecting imperfections in realism will keep pace with new technologies in simulating realism. A summary of Dr Angela Tinwell's research on the Uncanny Valley, psychological reasons behind the Uncanny Valley and how designers may overcome the uncanny in human-like virtual characters is provided in her book, The Uncanny Valley in Games and Animation by CRC Press.[48]

A number of design principles have been proposed for avoiding the uncanny valley:

A number of criticisms have been raised concerning whether the uncanny valley exists as a unified phenomenon amenable to scientific scrutiny:

An effect similar to the uncanny valley was noted by Charles Darwin in 1839:

A similar "uncanny valley" effect could, according to the ethical-futurist writer Jamais Cascio, show up when humans begin modifying themselves with transhuman enhancements (cf. body modification), which aim to improve the abilities of the human body beyond what would normally be possible, be it eyesight, muscle strength, or cognition.[66] So long as these enhancements remain within a perceived norm of human behavior, a negative reaction is unlikely, but once individuals supplant normal human variety, revulsion can be expected. However, according to this theory, once such technologies gain further distance from human norms, "transhuman" individuals would cease to be judged on human levels and instead be regarded as separate entities altogether (this point is what has been dubbed "posthuman"), and it is here that acceptance would rise once again out of the uncanny valley.[66] Another example comes from "pageant retouching" photos, especially of children, which some find disturbingly doll-like.[67]

A number of films that use computer-generated imagery to show characters have been described by reviewers as giving a feeling of revulsion or "creepiness" as a result of the characters looking too realistic. Examples include the following:

The fear, arising at contemplation of the "person" having small aberrations, and strengthening of impression because of its movement were noticed in 1818 by the writer Mary Shelley in the novel Frankenstein; or, The Modern Prometheus:

How to describe my feelings at this awful show, how to represent unfortunate, created by me with such incredible work? And meanwhile its members were proportional, and I picked up for it beautiful lines. Beautiful — My God great! Yellow skin too hardly fitted his muscles and veins; hair were black, shiny and long, and teeth white as pearls; but that their contrast with the watery eyes almost indistinguishable on color from eye-sockets, with dry skin and a narrow cut of a black mouth was more terrible. <…> It was impossible to look at it without shudder. No mummy restored to life could be more awful than this monster. I saw the creation unfinished; it was ugly even then; but when his joints and muscles started moving, something turned out more terrible, than all fictions of Dante.

The 1977 Doctor Who serial "The Robots of Death" describes a mental illness called "Grimwade's Syndrome" or "robophobia": a condition where the lack of body language from humanoid robots provokes in certain people the feeling that they are "surrounded by walking, talking dead men."

In the 2008 30 Rock episode "Succession", Frank Rossitano explains the uncanny valley concept, using a graph and Star Wars examples, to try to convince Tracy Jordan that his dream of creating a pornographic video game is impossible. He also references the computer-animated film The Polar Express.[100]

In the 2010 Criminal Minds episode "The Uncanny Valley", a woman turns women into living dolls to try to reclaim the porcelain dolls she had owned when she was younger.

In the 2014 The Leftovers season 1 finale "The Prodigal Son Returns," the Guilty Remnant places dozens of lifesize humanoid replicas of departed loved ones into the homes of their family members who are still alive. This action unnerves so many people that it sparks a riot in the town.|||

