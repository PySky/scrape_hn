In school, we are first taught the arithmetic mean, then later the geometric mean, and maybe one or two others like the harmonic/contraharmonic mean.

But most teachers do not teach the logic or derivation behind these means. They merely provide the formulas and perhaps provide some scenarios where each mean would be more useful than the others.

I’d like to illustrate the definition of a mean, in the most abstract sense, from a programmer’s perspective, an algorithmic point of view.

Suppose we have a list of N numbers, and a binary operation

If we apply that binary operation to one number from the list, we must apply its inverse operation to another number from the list.

We can continue applying to one element then to another element as many times as we need to, until every number in the list is equal. That number that all elements are equal to…is the mean!

** I am aware we haven’t specified the most optimized way to perform this algorithm to ensure it halts.

let our list be and our

then we apply the operation and its inverse to two elements respectively:

So our mean is 4. We just performed the arithmetic mean!

Well, given ANY invertible symmetric binary function, we can define a mean and derive its “shortcut” formula!

Here are the functions that define the means we usually come across:

arithmetic mean: 

 geometric mean: 

 geometric mean (alternative definition): 

 harmonic mean:

Now, most of us learn that geometric mean tends to favor smaller numbers.

For example, the arithmetic mean of 1 and 100 is . But the geometric mean of 1 and 100 is 10.

Knowing what we do now, can we create a mean that favors smaller numbers even more?

I don’t know if these already exist in the formal mathematics universe, ie. books or published papers. So let me know if you find a previous name for them!

You might ask if we can skew our mean toward smaller numbers even more than our above exponential mean. We sure can. Using something called Tetration, simply put – it is iterated exponentiation. There are even operations that encompass iterated tetration and so on…these kind of operations are called hyperoperations. So we can make a mean skewed toward lows or highs as much as we want, and it’s beautiful isn’t it? Before different means are taught, the theory of what defines a mean should really be taught.

But before I forget, you must be saying: “Where’s my shortcut formulas?!!”

Let’s derive the arithmetic mean first. Assume we have a list of 4 elements,

Given the binary symmetric function that defines the arithmetic mean ,

Our formula for the mean of the 4 numbers in our list will be:

We know , so

That means our mean is , which is what we expected from the arithmetic mean

Above was just a demonstration for a fixed size list of 4 elements. The concept is the same for any sized list. We can use induction to extrapolate what the formula will be for a list of n elements,

I had to use 2 variables for the above, because Mathematica’s symbolic inverses aren’t strong enough.

 Franken Mean v2 does not even compute with symbolics or even numbers.

 I will eventually work on this to hopefully get at least numerics to work nomatter what.

This is an alternative implementation which seems to yield better results in some cases:

Enjoy creating your own means! Number theoretic means on lists of primes and that sort of stuff should be very interesting to explore, cheers!

Kolmogorov actually did something similar and came up with what’s called the Generalized f-mean

But he restricted his construct to only functions of the form , where g is the function that determines the mean and is to be specified.|||

