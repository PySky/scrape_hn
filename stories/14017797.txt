We could talk at great length about what it philosophically means to know something. I propose a quick dirty shortcut: an entity knows what it honestly says it knows. Thus, a machine knows that it is a machine, precisely if it says that it knows it is a machine. My PC does not know its a machine, because it has never announced its machinehood: it wasnt programmed to. You could easily modify Hello World in any programming language into Hello World, I know Im a machine! And yet, this is unsatisfying. Such a simple Hello World program cannot do anything with its knowledge: it cannot reason, it cannot do logic. It doesnt even know that 1+1=2. We would like to revise the question, and ask whether it is possible for a machine to know it is a machine, and for that machines knowledge to actually have potency somehow. How can we do this?

The answer is to impose axioms on our machine. First, we must pick an appropriate language. Its not overly important which language we use, so long as were consistent. Lets use the language of Epistemic Arithmetic, cultivated in the 80s by Stewart Shapiro and William Reinhardt independently. This language is simply Peano Arithmetic extended by a modal operator K, for know. All the formulas of PA, such as 1+1=2, carry over directly, but additionally there are formulas of knowledge: for instance, K(1+1=2) is meant to express that 1+1=2 is known.

We can use axiom schemas to constrain a knower. By my quick dirty shortcut, a priori, there is no restriction on a knower: he can know any combination of things, just as a 2-place multiplication function can have any properties whatsoever if not constrained by axioms like associativity or commutativity. What sort of axioms would be reasonable to impose to make our knowers behave?

We should first of all ignore any knower who knows a falsehood. Such a knower is useless: we cannot trust him. Thus, the Axiom Schema of Factivity:

In this Axiom Schema, φ ranges over all formulas. For example, taking φ to be 1+1=3, we get K(1+1=3)→1+1=3. Since 1+1 does NOT equal 3, in particular, Factivity forbids the knower from knowing 1+1=3.

If it is raining, I will go outside. It is raining. Therefore, I will go outside. You might have heard something inane like this in Philosophy 101. Its called Modus Ponens, and however silly and obvious it may seem, it is a very important property of knowledge. If you know that if it is raining, I will go outside, and you know that it is raining, well, then youd better well know I will go outside. MP formalizes the ability to do the most basic steps of logical reasoning. It is a very reasonable axiom schema to impose on our machines.

Tautologies are formulas which hold in every structure. Examples are so trivial, it almost feels silly to type them: If φ, then φ. If φ and ψ, then φ. φ or not φ. If ∀x φ(x), then φ(100) (where φ is a formula of pure arithmetic). And so on. It is possible to program a computer to list all the tautologies (this is by Gödels famous Completeness Theorem). It is reasonable to require that a knower knows every tautology. After all, if a knower doesnt even know that If φ then φ, well, thats a pretty weak knower.

Axiomatizing arithmetic is nontrivial; were very fortunate that all the works been done for us. Arithmetic is axiomatized by the axioms of Peano Arithmetic. All we have to do, to constrain our knowers to know arithmetic, is to require that they know Peanos axioms.

To illustrate the power of the axioms so far, I claim that if a knower satisfies just the axioms defined thus far, then that knower knows every theorem of PA. For instance, such a knower knows that 1+1=2 and knows that there are infinitely many prime numbers.

The axioms Ive listed so far are a very bare-bones set of axioms of knowledge. There are many other axioms which could be added, but these are enough for the purpose of this blog article. Finally, we can ask a more substantial question, one which doesnt have a trivial, dirty, cheating answer:

The answer is YES!at least for reasonable formalizations of what it means to know that it is a machine. You see, our axioms came with a heavy price. By switching from the English language into the language of Epistemic Arithmetic, we lost the ability to casually express I am a machine: there are no such words in the language. I will show two different and independent ways to formalize I am a machine, but we will need some tools from Computability Theory.

You can skip this section if you already know computability theory.

By a machine, I mean a Turing Machine which accepts one input. It is possible to encode such machines as numbers. The number of a machine is called its Gödel number. There are various different ways to do this. For example, you could systematically write the machines instructions into a .txt file, save it to your hard drive, tear open your hard drive, look where the .txt file is stored, read off all the 1s and 0s, and interpret them as binary to obtain a number. Its possible to define Gödel numbers in a way independent of hard drives or .txt files, by using unique prime decomposition creatively the details are solely of interest to logicians.

The point is, we may speak of Turing Machines by number: rather than spelling out a TM explicitly, we may simply refer to Machine number 1000 or Machine number 764823134. It is useful to speak of the range of a TM, that is, the set of outputs it can produce (depending on its input). Computability theorists use the following notation: for any number e, W stands for the range of the Turing Machine with number e. This will be important shortly.

Similarly, formulas of Epistemic Arithmetic can also be numbered. I will write #(φ) (pronounced: sharp phi) for the Gödel number of φ.

Arithmetic is strong enough that you can write out formulas, purely in arithmetic, which express facts like x is in W or even #(φ) is in W . In practice, these formulas would be terribly messy, a crime against humanity. No human writes them out in real life, but a machine would have no trouble with them. Well use abbreviations instead: when I write xεW , it is understood that I mean a formula of pure arithmetic which expresses that x is an output of the eth Turing Machine.

The first formalization of I am a machine is a schema due to William Reinhardt:

In English: There exists a number e such that for every x, I know φ(x) if and only if x is in the range of the eth Turing Machine.

Strictly speaking, the SMT is really a formalization of I am locally a machine: for every formula, the set of x such that I know that formula, is enumerated by some machine. However, it is possible that different machines are required for different formulas φ, and that no single machine works for all φ.

The second formalization of I am a machine is due to this author:

Here, e is a term representing a single fixed number. Thus, it is actually a family of schemas: one for every e. For example, if e=1000, the schema becomes: K(φ)↔#(φ)εW .

The second formalization, in English: I know φ if and only if (the Gödel number of) φ is output by the eth Turing Machine. If we allow quantification over formulas, this formalization becomes: The formulas which I know are exactly the formulas listed by the eth TM, or abusing language, I am the eth TM.

So now the Question which we are concerned with, Can a machine know that it is a machine (and satisfy some nice axioms)? can be further refined:

The answer to both questions is a resounding YES! However, proving this is nontrivial. (At least, the first question is nontrivial. Its impossible for me to judge the second, since Im the one who discovered it, and anything one discovers is trivial to oneself) The proofs that the answers are YES are contained in two papers:

Now, it might seem deceptively easy to prove these affirmative answers: we can easily program a machine to enumerate the consequences of PA (getting it to run quickly enough to be useful is another matter), and we should be able to throw in the I am a machine formalizations using some sort of Quine construction. After all, people have been writing programs which output their own source-code since before the dawn of time (at least as measured by the C time_t structure). Sure, you can make a program enumerate formulas in such a way as to satisfy all the axioms except maybe for Factivity. How do you know your program wont eventually output 1=0? To get a sense of the subtle difficulty, remember that Gödel showed that Peano Arithmetic cannot even prove its own consistency (unless its inconsistent); so, since your machine will certainly list the consequences of PA, you cannot prove in PA that your machine satisfies Factivity! And thats without even considering the additional things your machine must know about its own knowledge, in addition to arithmetic.

One way to see the non-triviality of positive results is to see how, by attempting to strengthen them, we obtain negative results.

A somewhat discredited axiom schema candidate from epistemology is the following:

Can we add S5 to our list of axioms, and still have a machine which satisfies those axioms (or, even better, a machine which satisfies those axioms and knows itself to be a machine)? The answer is no, because if such a machine existed, we could solve the Halting Problem.

The following axiom schema is deceptively harmless-looking:

Can we add Knowledge of Factivity to our axioms and still get a machine which satisfies all the axioms, knows its own Gödel number, and knows its own factivity? The answer is NO.

Where did I use Knowledge of Factivity in the above proof? I didnt explicitly invoke it. But I did invoke Factivity, while reasoning through Ms perspective. If M didnt have Knowledge of Factivity, then Factivity itself would not be available to M and I couldnt use it while working in Ms perspective.

Timothy Carlson: Knowledge, machines, and the consistency of Reinhardts strong mechanistic thesis (PDF)

 A dichotomy in machine knowledge (PDF)

 Turing Machines

 Fitchs Paradox of Knowability|||

