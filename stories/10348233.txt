How to build in DevOps metrics without interfering with speed

Nothing should throttle the move to modern software delivery—that would be a contradiction. However, the problem with a self-service, just-go mentality is that starting is so easy that you might not know where you were, where you are, or where you're going. Teams are doing themselves injustice if they don't utilize strong metrics to keep DevOps up and running for an extended amount of time.

For DevOps to extend and expand it needs a path. And that path can only be established when it's measurable, analyzed, and actionable. Teams need to consider metrics for their entire development practice and to develop best practices for building metrics in without interfering with DevOps speed.

We're addicted to data—especially in the tech world—and we want to log everything and then visualize it. But for some reason, in software development, there are large blind spots. You can tell a person everything about a running application but very little about how it got there. This is mostly the result of teams thinking only in terms of releases and not the process of releasing.

In a DevOps environment, there's information everywhere. We log application data with application performance monitoring/management (APM) tools and system data with log analysis platforms; we even log data about application components with component monitoring tools. But there are some gaps. For example, pipeline-release frequency and failures are't commonly logged. In DevOps, it isn't just one piece of information that's most important, it's the continuity between them all. Just as the releases should be continuous, so should the data associated with them at each step of the way.

But data isn't the same for everyone. Even something as simple as your role will determine what data is important to you. For the most part, you won't consider your peers' measurement goals. For example, if you use the word "logging" with a developer, they're going to reference APM, which helps them react to user behavior. They're aware of system monitoring, but they'd rather have IT ops think about it. The inverse is true as well.

Because of the difference in POV, what each person measures is different, and thus the entire population of data is disconnected. One way to reconcile this discrepancy is to create a shared objective. If the entire organization is shooting for the same goal, there will be a large incentive to share data and be on the same page. But this also requires that teams start monitoring their pipeline as well.

Organizations need to reconsider their pipeline as its own entity. Why do we consider logging the data in the applications we release but not the processes that release them? This usually stems from the fact that everyone owns a portion of the process, but rarely is one person or group watching all of it. Seeing the big picture of the entire development process requires a holistic point of view.

If teams consider their pipeline the meta-application, it can be transformative, and it quickly becomes clear how beneficial this can be to proving success over time. At the end of the year, the entire team can claim success for the modernization of their delivery process.

But adding the pipeline data is just one more data source in a mountain of data. For example, at a minimum, organizations need to log data from these examples of data elements:

Below is an example reference architecture for setup, data sources, and their relationship to pipeline stages.

Each data point doesn't represent a new tool, but there certainly is an ecosystem of one or more tools that make it happen.

This is a lot of arrows and a lot of data points. So let's quantify why it's worth doing the data origami:

Remember, you aren't only justifying analytics from a business perspective—you have to convince individual stakeholders why they should care about more than just their slice of the data pie.

As stated above, there are lots of moving parts. It isn't easy, but the expectation isn't to get the analysis down in one fell swoop—that's waterfall—it's that you enable the data visibility required to accomplish these types of analyses in the future.

Here are the top challenges to providing all this data. Don't worry—they're all manageable.

The best and only way to start is to identify who the data facilitators are and to give them the autonomy to understand what's available, who needs it, and what's missing. Being data-driven is a mentality, and doing it effectively requires strategy, not just a project. Focus on simply identifying data elements and having a vision for how they're going to be used. When you do this right, the speed of modern development won't be its ultimate destruction.|||

When you move at the speed of DevOps, it can be hard to know what you should be measuring. Read about how to work metrics into your DevOps pipeline.