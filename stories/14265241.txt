As the first benchmark we will use aiohttp web framework. Aiohttp is one of the first asynchronous (asyncio library in particular) web servers for Python. Pure python code, no cheats, no tricks.

Additionally, we are going to test the performance of different versions of Python (3.5.3. and 3.6.1).

Let’s see what Tarantool can offer us. tarantool.org.

There are Msgpack tuples, Lua application server, memory allocation mechanism and write ahead log inside Tarantool. All data is stored in memory and runs incredibly fast.

Msgpack is JSON’s competitor format that is faster and smaller than JSON. Msgpack stores messages in a byte-code. You cannot read them like JSON messages.

When you create a new record in Tarantool, it allocates slots of memory for this tuple and provides an access to it. All tuples (they might be called as rows) are stored at spaces (they might be called as table), the spaces are divided with fields. Spaces have primary or secondary keys. Each field can be a simple data like integer or text or it can be a compound as tuple or address link to another table. Every tuple may be extended with new data, but you have to enter mandatory data (fields) into primary or secondary keys. Keys support TREE, RTREE, BITSET, and HASH indexing algorithms.

Each operation (with data in database) is a built-in Lua function. For example, to run join query you have to implement you own Lua-function to perform join of these tables. Within this function you need to iterate one record in a space and add data from the records of another space, then you return consolidated dataset.

The configuration of Tarantool is simple. In fact, configuration file is a big lua-script, within which you declare spaces, fields, indexes, create users and can declare custom data transformation functions. Moreover, you can run a web server and all other features provided by Lua.

The performance of Lua can be compared to Java. Lua is much faster than Python but a little slower than Java. In our case, we have to take into consideration that Tarantool calculates data faster than the main application with Python would.

Snapshot provides storage in-memory data on the disk. This snapshot loads to Tarantool at the start and then additionally loads data from WAL for unsaved transactions. You can safely stop and run Tarantool server without losing your data.

Replication (master-slave, master-master) and sharding mode provides a possibility to build very sophisticated architectures. Built-in Lua language makes it possible to handle all database architecture specific aspects within Tarantool, so you don’t need to overload your application code.

What’s about stability? First of all, Tarantool is stable. I have no problems with or bugs in it. If you have reserved 128 MB of memory and used all this memory, you will get “could not allocate memory” on insert operation, but you still will be able to connect to DB and read data and in some cases upsert records. There’re no crashes and lags. But you have to consider that this is all about memory space. You cannot run three 256MB Tarantool instances at same time on a server of 512MB RAM. Actually, you can do this, though when more data is storing in Tarantools, then more memory will be used for them and at some moment the OS will start killing some instances out of system memory.

PostgreSQL has new type and provides the possibility to work with it as with native JSON storage. I repeated data architecture with this JSONb feature. This was painful.

Another way was to do features of PostgreSQL, but when I found this feature, it was too late to rewrite the whole code. Although, below there is an example of how to work with tuples in Python as part of jsonb data in Postgres.

Upsert with PostgreSQL and JSONb was hard to code and to test. You can find an example in the source code. There’s some statement like that:

For database driver we have , that is the fastest asynchronous python driver at the present.

First, I received a weak result. There were about 64 RPS on and 100 RPS on pages.

Rewriting selected statement, taking one sticker from 16k records table and rechecking code to remove fetch function (replace it with simple execute) on , gave me result of 190 RPS on and ... 110 RPS on  ... Well, this is strange.

Searching, investigating and giving a chance to statements made 650 RPS on with my dev machine. But I could not reproduce it with the aws.nano. The code was crashing and producing errors: 'cannot perform operation: another operation is in progress'. The main supposition is that statement with asyncpg cannot not work on one CPU server. I leave this moment beyond the article.

The next try was to explain myself the 100 RPS problem and run for the SQL statement. As a result I found that indexing was not working in the right order. It is fixed as follows:

Tarantool shows results ~7 times faster in intensive DB scenario and ~3 time faster on rare intensive scenario than PostgreSQL in our example.

In all scenarios Uvloop is faster than standard Asyncio loop and Python 3.6 is faster than 3.5.|||

Python and Tarantool benchmarks with demo and source code