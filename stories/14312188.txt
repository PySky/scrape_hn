The AI revolution sweeping the globe just got faster.

NVIDIA CEO Jensen Huang Wednesday launched Volta, a new GPU architecture that delivers 5x the performance of its predecessor before a record crowd of more than 7,000 scientists, engineers, entrepreneurs and global press at our GPU Technology Conference.

Over the course of two hours, Huang introduced a lineup of new Volta-based AI supercomputers including a powerful new version of our DGX-1 deep learning appliance;  announced the Isaac robot-training simulator; unveiled the NVIDIA GPU Cloud platform, giving developers access to the latest, optimized deep learning frameworks; and unveiled a partnership with Toyota to help build a new generation of autonomous vehicles.

The announcements come as, every day, hundreds of millions rely on AI-powered search, language translation and speech recognition services. Investment in AI startups rocketed to $5 billion last year, Huang said. The number of students in AI programs at Udacity has grown 100x to 20,000 in two years.

It’s all fueling demand for more AI computing power. Two years ago, cutting-edge image recognition systems needed seven exaflops of computing power, Huang said. Now, researchers tackling real-time language translation need more than 100 exaflops of power, he explained. By comparison, the cumulative peak performance of the world’s 500 fastest supercomputers is under one exaflop.

This demand comes as Moore’s law has stalled out. The single-threaded performance of traditional CPUs is now growing just 1.1x per year. By contrast the GPU performance — powered by improvements in the performance of everything from silicon to software — is still growing by 1.5x per year.

“Some people have described this progress as Moore’s law squared,” Huang said. “That’s the reason for our existence, recognizing we have to find a path forward, life after Moore’s law.”

The latest leap comes thanks to a slate of powerful new products led by our new Tesla V100 accelerator.

Built with 21 billion transistors, the Volta V100 delivers deep learning performance equal to 100 CPUs. Representing an investment by NVIDIA of more than $3 billion, the processor is built “at the limits of photolithography,” Huang told the crowd.

Volta will be supported by new releases of deep learning frameworks Caffe 2, Microsoft Cognitive Toolkit, MXNet, and TensorFlow, letting users quickly get the most out of Volta’s power.

“We’re on our second generation of GPUs in the cloud,” said Jason Zander, corporate vice president of Microsoft Azure. “We just announced P40s and P100s, but we really love Volta. My job is to ensure people use the Azure Cloud, and people want to use what’s available immediately, without waiting. We want data scientists and developers to focus on models and less on the plumbing.”

Another powerful endorsement came from Matt Wood, general manager for deep learning and AI at Amazon Web Services, who joined Huang on stage. “We couldn’t be more excited, we’ve seen amazing performance improvements for both training and inference, and we’re really excited to be a launch partner,” he said.

In addition to the new DGX-1 equipped with eight Volta GPUs, which sells for $149,000, Huang introduced a new whisper-quiet workstation, NVIDIA DGX Station. Powered by four V100 GPUs, it will slip 480 teraflops of Tensor computing power under the desks of anyone working on AI and sell for $69,000.

One of many applications of AI that Huang presented was the new Isaac robot-training simulator, which will allow robots to be trained in the virtual world before they move into action in  the real world. While he demo’d efforts to teach robots to golf and play hockey, he noted that it will make training safer, faster and cheaper for manufacturing, medicine and construction.

“We need to create an alternative universe,” Huang said. It needs to obey the laws of physics and gravity if you chose, it needs to be visually photorealistic, it needs to have the ability to learn inside this universe — the one gap with the real world is it needs to operate at warp speed, it needs to move faster.”

Huang announced Toyota will take advantage of the power of our upcoming Xavier SOC for autonomous vehicles, which boasts a 512-core Volta GPU generating 30 teraflops of AI deep-learning computing power while using just 30 watts of power.

“This is a company that is legend in so many ways…so many modern management systems were invented by this company,” Huang said. “Our two engineering teams are working to create their autonomous car and put it on the road in the next few years.”

Huang also touched on our burgeoning partnership with SAP. The partnership has already helped SAP create applications that can better track brand exposure, automate the extraction of classification of data from corporate accounts payable systems, and analyze the unstructured information in customer complaints, so they can be routed to people inside a company who can resolve them.

Huang presented a new tool for collaborating in a VR environment on high-fidelity photorealistic models. He demonstrated  Project Holodeck by collaborating with the founder of Koenigsegg, Christian von Koenigsegg , who was based in Sweden, checking out the interior of his new $1.9 million Regera supercar.|||

