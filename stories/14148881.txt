If you use Amazon CloudWatch Logs, you’ll love this.

I’ve written a tiny tool called . It’s very simple. It consumes standard input, and copies it to a CloudWatch Logs stream:

If you specify the (tee) option, it’ll also copy the stream to standard output.

You can find it at our GitHub repository. It’s Apache 2.0-licensed.

We’re big fans of the so-called “12 Factor” approach to logging, in which programs dispatch their logs exclusively to a single stream (i.e., standard output). The reasons are detailed at the linked site, but I’d like to discuss a few points that aren’t mentioned there.

One benefit of logging to standard output is that the application will be able to issue logs even when there’s no logging service available.

In traditional Linux environments, there’s typically a syslog daemon (or one of its many cousins, like rsyslogd and syslog-ng) running on the host to collect logs; and traditionally, UNIX software uses the C call to send messages to the syslog daemon. The daemon is then configured to filter and write logs to various local files based on attributes such as log facility (of which there are about 20) and urgency level (of which there are 8). Most syslog daemons also have the ability to forward logs to other servers, but some will drop logs or block (and worse, cause your application to stall) if the remote server is jammed or unavailable. And syslog servers’ configuration files can be quite complex.

As we move our applications into the cloud, we’re finding that the execution environments for our software don’t provide access to a traditional syslog service. Instead, these Platforms-As-A-Service (PaaSes) typically collect the application’s standard output and forward it to the cloud provider’s log collection and aggregation systems. So as a practical matter, our software increasingly has to log to standard output anyway.

Suppose your software currently logs messages via , and you have a rule in your syslogd configuration to forward those messages to a centralized log collector. Let’s also suppose you’re ready to prepare your software for a PaaS transition, but still want to run it on your legacy servers in the interim.

You can update your software right away to log to standard output. Until you’re ready to move it to the PaaS, you can simply connect the application to syslogd as follows:

is a tool that ships with every Linux distribution. It consumes lines from standard input and writes them to syslog, using the tag specified via the option.

Setting this up can be tricky in a standard init script, since traditional SysV init expects the processes it runs to background themselves. Using a process manager such as daemontools, runit, or s6 can simplify matters. Just configure your application’s script to:

Notwithstanding the above, we’ve learned that it’s not a good practice to connect applications that produce logs directly to consumer applications like syslogd, logstash, or Kafka.

Log-consuming applications can crash or hang. Network partitions happen. Without some sort of buffer, you have two options when this happens: either drop logs, or block until the consumer has been restored.

Dropping logs may not be acceptable if your business demands accurate reporting capabilities. And blocking makes your application stop handling requests, causing a denial of service (read: outage).

So we now combine both logging to standard output, but instead of connecting the output directly to a log consumer, we record it to a buffer: a file on disk with a bounded size. A separate program then reads the logs from the buffer and copies them to the ultimate consumer (remote syslog, message bus, etc.)

Here’s a simple implementation of such a system, composed as a set of runit services. First, :

Now, let’s send those buffered logs off to CloudWatch Logs!

For most sites, logs are important. Logging to stdio is the current best practice. CloudWatch Logs is just one place to store them for safe keeping — but no matter how you generate and collect them, be sure to buffer them so they don’t bring you down.|||

I’ve written a tiny tool called cloudwatch-logger. It’s very simple. It consumes standard input, and copies it to a CloudWatch Logs stream: We’re big fans of the so-called “12 Factor” approach to…