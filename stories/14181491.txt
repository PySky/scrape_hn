This article covers one of the secrets of high scalability and performance. A blog post about Flickr Architecture that has more than 5 billions photos brings us the following: Caching and RAM are the answer to everything. A Website could store data for the purpose of speed up future requests on three different layers and environments: 1) Client, 2) Network, 3) Server, and 4) Application.

Different pages of a Website commonly share the same assets. The user should reuse assets during navigation. Images, scripts, and styles could be cached for months and also the document page itself could be cached for minutes on the Client Browser. HTTP headers have the responsibility to define if a response could be cached and for how long. The following header example indicates that the response might be cached for 7 days. The Browser is going to request it again only if the cache expires or if the user force refreshes the page:

A response could also include a header or a header. These headers are used to verify if an expired response could be reused. The response status 304 indicates that the content didn't change and doesn't need to be downloaded again. Pay attention to the and the header pairs and the dates bellow:

The header is used with in a similar way to exchange codes to identify if a content changed or not. A Website with the HTTP headers wisely defined will provide a better experience for the users. The Browser could save time and Network Bandwidth based on it.

Wikipedia defines a Content Delivery Network (CDN) as a globally distributed network of proxy servers. CDNs are about caching — shared caching. The HTTP header directive allows different parts of the Network to cache a response. It is common to find assets with meaning that it last a year anywhere. You might know that there are others header cache directives. There is also a powerful header to handle authenticated and other kinds of dynamic responses.

Finally, the control is all on your hand, developer! Aside setting the right response headers and handle the request headers correctly, there are many things you could improve on server and application side. The first approach to faster responses and save resources is setting up a cache server between the application and the client.

Tools like Varnish, Squid, and nginx might cache images, scripts and other contents that are shared by users. The following setup up a nginx server proxy that caches content relying only on the application HTTP headers: There is also a directive called that allows the proxy server to delegate only the first of similar client requests at a time for the application. If it is set on, the clients are going to receive the response when the first request returns.

It is a simple but powerful mechanism that avoids chaos on the application side when a content expires, and many clients are requesting for it. The server proxy could also deliver expired content for the subsequent similar requests using the directive . This faster the response time and reduces the number of clients waiting for a server response. Last but not least, the proxy could improve the fault tolerance of the application. There are flags for the directive to deliver expired content when the application returns error statuses or when the communication between the server proxy and the application is not working as expected. The article A Guide to Caching with NGINX and NGINX Plus have more details and configuration options.

Application Caching reduces the time of specific operations. Complex computations, data requests to other services or common data shared across request are some examples. The Ruby code above uses the simple memoization caching technique. It stores the product price to avoid future calculations. In that case, it will store the data on an object instance, and it will only save resources during a request. This technique could be applied anywhere in the code. But the use of it brings some concerns. It is important to mind that your data will not expire for example. A global code memoization is going to last in-memory during all the application execution cycle. The code above uses the Rails Caching API to store and reuse the category tax during one minute across requests. The cache key definition uses the to identify the data. This technique is used there to reduce the amount of request to the external Category Tax Service saving resources and time. There are many libraries that provide this pattern. But it is important to mention that the application memory is a finite resource. The node-cache module, for example, doesn't manage the amount of memory consumed. It could be a problem if your application massively caches data consuming all the available memory. The Rails Memory Caching wisely prunes the cached data when it exceeds the allotted memory size by removing the least recently used entries. It allows to cache immutable data without defining expiration. Handle a growing amount of users and requests is an important subject of Web development. One of the ways to scale an application is through adding more application instances (scale horizontally). And as you might imagine, the simple in-memory cache can't be shared between instances.|||

This article covers one of the secrets of high scalability and performance. A blog post about Flickr Architecture that has more than 5 billions photos brings us the following: Caching and RAM are the…