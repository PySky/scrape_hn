Through all my “failed” project ideas, I ended up with a decent understanding of Flink’s model and internals. One of my Program Directors, Ronak Nathani, recommended I actually play around with the tool (as I hadn’t yet) and see if anything inspires me. I took interest in the streaming graph library, gelly-streaming, and learned it had an algorithm that could find connected components incrementally from the beginning of time, but for instance, couldn’t show you the connected components that had developed in just the past 2 hours. I didn’t have a great application in mind, but intuitively, it seemed there must be value in isolating a view of the graph that captures change in the network over time with respect to disjoint sets.

To get more concrete, take Github for example. You make pull requests to people’s repos, comment on others’ issues, and fork someone’s project to work on it yourself. If you treat these interactions as connections in a network (and squint a bit), you can see a developing social network, right? Flink’s gelly-streaming could tell you if there’s ever been a connection in your extended network of Github interactions to someone like Brendan Gregg, but it couldn’t tell you if such a connection happened recently, or if it happens periodically. It couldn’t show the ephemeral nature of groups as novel repos come and go, or identify the people that are most likely to bridge disparate groups as they are growing and changing.

I decided to implement this feature in the gelly-streaming framework. The concept isn’t too heavy-duty. My Insight project and demo consisted of a pipeline that identified groups (connected components) in the Github event stream, within a sliding window. At ~20,000 events per second, this pipeline could chew through 5 years of Github data in about 8 hours. I titled the project Network Pulse, but Github offered the repo name “literate-garbanzo”, and I just couldn’t bring myself to change it.

Lamentably, my contribution wasn’t in line with gelly-streaming’s goals. I also bumbled the implementation at first, and I didn’t make a good case for its inclusion since this sort of algorithm deviates a bit from the rest. Either way, my work is Open Source but not immediately consumable, so if you think you have a use for this, let me know and I’ll see if I can help!

And throughout it all, my workhorse was a $150 Acer C710 Chromebook. In my late-night stupor, I even spent hours building JARs locally, swapping memory to a USB2.0 flash drive when my SSD ran out of space, before I realized it’d take mere minutes to build the same things on any of the AWS EC2 nodes I had up and running. It was a hard lesson on the false economy of neglecting adequate rest. Live and learn.|||

A story about an Insight Data Engineering project that nearly wasn’t, and the beginning of an unexpected new career. I vaguely recall my first encounter with a trampoline — the physical, acrobatic…