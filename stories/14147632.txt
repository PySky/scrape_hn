When jq hits invalid JSON, it completely stops processing the stream.

 That’s not always great.

People will be quick to “fix” your problem:

If you can do this, that’s the cleanest way out of this.

But… real life is messy. You don’t always control the JSON you have to process.

 I ran into this recently: I extracted JSON logs from a system that decided to truncate some lines, some of the time.

Yes – you could do some minimal regex-based checks, possibly with AWK or grep.

 But you know what’s already great at handling JSON? jq.

That’s what you’ll find if you keep searching. The documentation says:

but an example might be clearer:

Just put (ASCII character 0x1e) in front of each record. See below for an example.

 (or check the internet draft for more details)

When a JSON parser finds a problem, what’s the best solution?

I don’t think there is one.

If the JSON is invalid … how much of it needs to be thrown out?

The answer is probably application-specific. And wouldn’t it be worse if jq silently skipped invalid JSON? How long would it take to debug that?!

With delimiters, you’re explicitly boxing failures: on a parse error, it skips the current record and forwards to the next .

Catch lines beginning with and insert a there.

DISCLAIMER again: the broken “green” entry is skipped… in this case it’s silent, but I’ve seen other broken cases where a message is shown on STDERR. Use responsibly.|||

Jonathan Palardy's blog about technology