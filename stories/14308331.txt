This post is the first in a two-part series on recursion schemes. Here, I want to build intuiton and understanding of what recursion schemes are and how to write them yourself. In the second part we will explore Ed Kmett’s recursion-schemes library, to show you, how to use recursion schemes in real-life Haskell code. Examples in the following text are intentionally kept as simple as possible, to aid in understanding of underlying ideas more than the examples themselves. Let us jump right in.

We usually write recursive data types like

This is a common way of writing a syntax tree, but it is not without downsides. Consider the following function that pretty-prints a tree made from this datatype.

This is the usual way of defining recursion we are used to everywhere — we define it explicitly. What if instead of pretty printing the syntax tree we wanted to calculate a numeric value of an operation it describes? We would have to write a function just like , manually recursing into individual elements. While there is a little chance of making an error in this simple example, mistakes while writing recursive functions are not unheard of. There is also a possible performance penalty, as GHC is way better in optimizing non-recursive then recursive code.

Can we do better? Possibly. Consider the following data type, where we are using a type parameter for encoding recursion.

The idea here is that we will use something called a ‘fixed point’ of a functor to encode recursive behavior inside somehow. Before we get to that, let us prove our type is, indeed, a functor. To do that, we have to implement that abides by the functor laws. I propose the following

So by applying with we unpack a level out of a functor, apart from the case, where we return the thing itself. The reason for passing through is that has type , but the type of is always , so we cannot match the types in general.

Our good old functor laws are

To check that the first law is fulfilled, insert for the function and the proof will flow from definition above. The second case for

will look as follows. It is the same for , since they have the same structure.

so it is fulfilled as well. Of course, we can skip this bit in GHC thanks to extension that allows us to derive automatically. We will reference this implementation later though, so it’s best if it is written down explicitly.

We have a type , which we know is a functor. This data type looks a bit useless, given that the type itself depends on the amount of levels of nesting

And so on. Even worse, the type demands that all branches have the same depth, so it looks effectively unusable. But I’ve mentioned fixed point as something that can help encoding arbitrary recursive behaviour in , what is it?

In mathematics, a fixed point is an argument of a function that is mapped to itself by that function. If we expand one layer from , the inner application, we get

and we can do it forever. So is an infinite chain of applications, and infinite chains do not care about one more application. If we apply to , we get again and that is what is meant by a fixed point in this context.

Let us define a simple syntax tree in terms of the initial

We should be able to represent the same thing with our . Let us start with the innermost

We do not have to write an infinite chain because does not have any s in its type definition. To get the whole thing, we have to wrap inside on each level

The types check out again. I bet this was easier than it looked like at the beginning of this story.

An algebra is an ‘unwrapping’ function.

So for our type, applying it to will give us an algebra

Wait, but it cannot be of any use, I can hear you say. We do not have any way of applying that function unwrapping strings into strings to our . Fear not!

Calling gives . WOW! The first time I got this I got so excited, this is amazing. Awesome. How does it work? unwraps one level from then which we wrote some time ago recurses inside. When it gets to leafs which are , it converts each to a string. Then s level up are called, but they already have their arguments as strings. We have eliminated recursion from our functions altogether! The only thing we had to define was what happens to a single element of . This is an essence of functional programming, to compose a program from multiple parts, each focused on doing it’s own thing well.

We have achieved so much so easily, can we get an integer value for the operation defined by same tree? We just need a simple new algebra:

Notice how, again, we just have to describe what happens to a single element, and all the internal types are s. This keeps our code concise and fast. There is only one place where recursion happens, in the definition of . Once we’re sure it is without errors, the possibility of making a mistake writing recursion disappears.

We can abstract away folds, but can we unfold from a single value using a similar scheme? Sure we can. For that we need an opposite of algebra, a coalgebra

Anamorphism is a kind of opposite of a catamorphism, so let us see what we get if we just flip functions around in the catamorphism. We have to remember to wrap where cata unwraps:

Oh, there is no automatic way of printing , which may be infinite. But we know how to print it, just use our catamorphism:

Notice that neither of these functions has access to the original structure. Stages higher up in a catamorphism (fold) only see the pretty-printed versions of elements down the tree, if we are creating a string-based representation. In many real-world tasks, this is not enough, and we need access to the original values along with their output representations. It would be a bit silly to parse output strings when folding, and it would negate any possible advantages of recursion schemes.

Algebras that carry that information are called R-Algebras

So instead of just accepting an element inside a functor, we get a tuple with the original entry and the pretty-printed element. A recursion scheme accepting this type is called a paramorphism

Notice how types perfectly match up — so much so that we can almost write these schemes by intuition. If you’re typing this in ghci, enable . It is needed for types and in to be interpreted by ghc as the same as and as in the definition of . Explicit just signals that both and should be available as the same types in .

A cool example of a paramorphism would be to sum the additions together, if it turns we want to shorten the output for some important reason

Here, we have used both — catamorphism for wrapping up the sums and paramorphism for neatly doing everything in one step.

Notice how behaves differently then and . We can see why it is so from the definition of above. equals by definition, so it allows us to populate leaves in the tree without calling and to have a neat starting point for providing two arguments to and

We have learnt how to abstract recursion away to transform recursive code into one that exploits recursion inherently present in the datatype itself. We now know what a fixed point of a functor is and can write five different algebras before morning coffee. If you have a minute, please let me know how this tutorial worked for you. I would love to use your feedback when writing part 2.

In part 2, we will explore the recursion-schemes library to move our understanding into the real world Haskell. The ideas will be broadly the same, with some magic sauce to make these functions even more generic. You can still use what you have learned here in your code as is, though, so feel free to play with it.

In researching this post I have mainly used the following resources:|||

