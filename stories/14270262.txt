A Test Is As Good As Its Ability To Fail When It Needs To Sometimes just writing tests is not enough

There's a pattern for organizing the internal code of tests called Arrange Act Assert (AAA). The structure is:

Let's say we want to test that a component. The implementation can be something like this, assuming that we are using a Test-Driven approach and a component-based architecture:

The modal will be open by default because this test is just to be sure we create something and append to the DOM. Now let's create the test that will drive us to create the functionality of closing it:

This failing test forces us to create the functionality of closing the modal. Let's build it using an  class that uses the to show/hide the content (see the function):

But we can only open the modal when an event happens, it should not open by default to the user. Let's edit the existing test so that the modal is not open by default (see the changes on the test the modal is NOT open by default ):

Now here's the problem: at some point when developing the modal, it's very likely that we commit a mistake and remove the button to close the modal from the DOM. That will break the functionality and we would expect at least one test to fail (see the function, the button has been removed):

However, no tests have failed.

The reason that happened is because the jQuery API, by default, doesn't throw anything for an element that doesn't exist. It fails silently and does not add the target element to the jQuery collection. Since we're checking the modal is closed and it is closed by default, then the test will never fail, even if the code is broken.

If we had an API that fails if the element doesn't exist, then there would be no false positive in the tests:

However, the error for a non-existent element when we use is not descriptive enough:

We can make it fail with a clearer message by wrapping the operation in a custom function:

The problem with passing a test when it shouldn't is that the developer won't know which tests to investigate when that specific bug happens. A passing test is very likely to be ignored, mostly if the modal test is more complex and it's in the middle of several other tests.

This is a problem of the same category of when Mocking Can Lead To False Positives. The difference is that, instead of mocking, we're using the incorrect DOM API for testing.

As a formal problem statement, we can say that a group of tests can lead to a false positive result when

In this circumstance, we can't guarantee the functionality is really covered. Even if there are tests written for that, changing the component code can make the test still pass.

There are a few options to prevent this from happening:

Just writing tests is not enough to ensure the application works. You need to write them correctly so that false positives like this one don't happen. That means using proper APIs for what you want to achieve.

jQuery alone is not suitable for this category of testing.

And you. Have you ever stomped in something similar? What's your suggestion to prevent this problem from happening when testing the default state of an object or component?|||

When you create a test for an initial state that is negative and later create another test for an action to trigger to the initial state, you might have just created a false positive