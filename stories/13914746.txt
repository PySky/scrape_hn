TLDR: Export BigQuery tables and queries to csv, ndjson, Excel and Google Sheets (!), supporting Excel/Google Sheet files with multiple sheets for a mix of full tables and ad-hoc queries. If you provide a filename starting with it will upload the file to the provided GCP Storage bucket.

It also supports build your own "whatever" using the code. The CLI is just composed of the functions and components contained in the package. In does some of the same things as bq, and some more.

It also supports use cases such as getting data from biguqery and adding columns, and then uploading it to another table. This can be useful in cases where you need to perform a lookup based on some data in a table, such as adding a country code based on latitude / longitude fields.

So, you know the feeling when the sales people ask you to "just grab some data"? Or, many times I have simple wanted to grab a set of data to play around with in a frontend / visualisation or some other analytics tool like a graph database.

Assuming your company is using BigQuery for yo' data and analytics needs, this is an easy task. Just launch the web UI and do the query. You can then download it as csv / ndjson file as well as exporting it to a Google sheet. Or you can use the bq command line tool from

There are however, some limitations to this. Let's say, for instance that the query result is too big to save or download. Then the query must be saved (or you can use the temporary table) and exported to a GCS bucket, after which you must download and upload it to a sheet.... You get it. Also, What if somebody wants an excel file with multiple sheets?

What if I told you that you that there is a tool that allows you to do run a query / scan a table and dump it to your local file system. You can even run multiple queries / table scans and have them appear in different sheets in an excel file. I present: , a package for working with ad-hoc biguquery data in a friendlier way.

is a CLI as well as a set of functions that allow you to do stuff with bigquery such as

In some cases, we might have complex queries that would be bad to write out in the CLI. Currently I haven't bothered to support anything here, it can be solved pretty easily like this:

When exporting to Excel, remember to include the sheet name (even though you only have one sheet)

Exporting to google sheets is a bit more work. you need to follow the guide in step 1 here and then, you need to teel bq-utils where to find the credentials by exposing it as the environment variable . You can also run it like this

When exporting to Google sheets, remember to include the sheet name (even though you only have one sheet). NB NB if the total number of cells (across sheets) exceeds 2000000 (2 million), Exporting to google sheets will not work. The code tries to minimize the use of columns * rows per sheet, but this is a hard limit from Google's side. Sorry maaan!|||

bq-utils - Utitilties for BigQuery such as downloading table / query to csv/ndjson/excel/gsheet or new table using iterators for a low memory footprint.