YALV helps you avoid the pain of manually tracing requests through logs. It requires an entering and exiting log entry based on which it calculates the time required for execution and matches against the server metrics like server memory used, memory free, load average.

YALV has two main components on the server side. A udp server listens for logs being sent and stores it in mongodb. A bash script tails logs and sends it to the udp server.

Deploy the following on each server thats generating logs.

In the first scenario it looks for app.log in the current working directory. It tails app.log and if it finds a string with pid in the log file it pushes to the udp server on port 5201.

The second option lets you give the location of the log file, custom string to look for in each log entry and the udp port.

This reads each line and matches the entry/exit for a particular request. It also adds server snapshot at that moment in time, giving you the corresponding server load, RAM used, RAM free.

It takes the same arguments as tail.sh. One disadvantage of using loading historical logs is you dont get server memory/load snapshot at the time of log generation. The memory/server load snapshots would be the server information at the time of file reading.

This will generate logs in app.log in your current working directory. It uses bunyan and node cron jobs to generate logs. Each log entry will look like

The service looks for type=entering,type=exiting and respective timestamps to match requests on same request,web server and func values.

If your application doesn't generate json logs, you can modify either bash script or udp server to change your log string to json formatted string in the above format.

Looped calls to a function are all captured. Individual looped request are shown under all requests while the averaged out response times are shown in the other graphs.

To check out the graphical representation of your logs check out YALV-UI|||

