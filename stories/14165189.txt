In the previous article about Microservices with Python, I was talking about how to create a basic API with some simple steps. You can run that directly with Python, but let’s say we have to integrate it with other systems, such as a Database, ElasticSearch or RabbitMQ.

As I mentioned in the previous article, you can find all the code I am generating on those articles in this GitHub repo: https://github.com/ssola/python-flask-microservice

Third part is available in this link.

Docker allow us to have different container for each one of our dependencies. In this example we are going to include two dependencies in our project:

But before starting, I need to explain some concepts:

From this step onwards I am assuming you have Docker installed on your machine. In case you do not have it installed, just follow this link.

It is a common practice to put the and in the root of your project. With this approach, you can share your development environment with anyone cloning the project.

Docker Compose allow you to create many containers needed for your service. For instance, in the Docker Compose we can define that we need a MySQL instance and an Elasticsearch up-and-running. We can set both on the same file, then with a single command, we can bring up or down those services.

Dockerfile allow you to create the recipe for a new container. In this case, let’s imagine we need to create a new container to run our application. With Dockerfile we can define to:

The Dockerfile allow you to define a recipe to build your image. Based on a given one, like alpine, you can set a list of commands to be executed to achieve some state, for instance, running a python app.

This is the definition of our recipe:

It basically get an alpine image with a python 3.5 already installed. This is nice because we can save some time, we only need to create a directory where to put our files, install the dependencies of our application and that is it.

This is a simple example, but for a production ready image we need to think about:

Open the file. Now, we are going to define the dependencies I stated above, Elasticsearch and RabbitMQ.

Most of the time you do not need to create your images. Fortunately, we have many of them publicly available in DockerHub.

Let’s start with the Elasticsearch one. Be careful, when looking for an image in DockerHub check the version of the applications you want to install. I found so many Elasticsearch 1.7 images when the current version is 5.2.0.

In this case, I chose the official image from Elastic  .

Probably your first question is, what that Alpine is? Alpine is a base image based on Alpine Linux. It is a super minimal distribution that allows us to create super small containers. It is a good idea to search for images built on top of that base image.

In our we are going to add these lines:

And the RabbitMQ dependency too, after the elasticsearch one:

With these few lines we have a composition of two containers. We can build up or down both services at the same time. But before building and running our services we should understand what we just did.

Now we can execute the command this will bring up two containers, one with the Elasticsearch and the other one with RabbitMQ. The means it will detach the process from your session.

If you want to stop your container, you can do , or to know the status of each container.|||

In this second article, I am going to explain how to create your development environment for your Python Microservice. With Docker we are going to include some services like Elasticsearch and RabbitMQ