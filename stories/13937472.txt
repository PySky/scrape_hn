Since the dawn of the 21st Century, innovations in internet technology have moved the world to what used to be unimaginable heights of connectivity. But have we the product directors, designers, and developers inadvertently opened the door to our monsters?

This dialog is from a pivotal scene in the 1956 MGM science fiction classic film, Forbidden Planet. The film, set in a future time of space exploration, tells the story of humans who have encountered a planet once populated by peaceful beings of high intellect, called “the Krell.” They had created a society of incredible technology. There was a great mystery. Why had the technology survived intact when every Krell had suddenly died? In their quest for instantaneous connection without instrumentalities, they had opened the door to long forgotten monsters from their past.

In the modern jurisprudence system, jurors are charged by the presiding judge to base their judgment only on admissible evidence, including direct and circumstantial evidence. They are charged with considering the credibility of witnesses, including expert witnesses. They are admonished never to let personal biases interfere with their judgments, including anecdotal experience. Indeed, they should not even be on the jury if the possibility of a bias exists.

We have seen (or read) this scene over and over in courtroom dramas in popular media and books. The ethical imperative to avoid a rash judgment is underscored and understood. Yet outside of the courtroom, many people make snap judgments about each other based on stereotypes, incomplete or non-existent evidence and personal biases.

Have people in past been quick to judge and condemn? Yes, of course. But now, thanks to the internet and social media, never before have snap judgments been so easily and widely disseminated. Not long after its creation, the internet was lauded as the great innovation that would bring about a new Utopia of free access to information and interpersonal communication. Everyone would have a voice. Communication barriers of distance would be banished. The truth would be pulled out from under the shadows of institutionalized suppression. To an extent, these things have happened, but not without an unintended effect. The “monsters from the id” gained access to this same awesome power.

For people who use the internet, the path to releasing monsters is very short indeed. It started with “trolling.” I doubt that product directors and designers intended to give trolls a platform for competitive insults when they gave viewers or readers the opportunity to comment on posts, articles and videos. Yet, that is what happened. In recent years, some publications have completely removed the feature because comments have become too mean. Even proud parents’ YouTube videos of their kids playing an instrument can be met with vicious, hurtful remarks from trolls. No consideration, no compassion, just…

Then social media gave the monsters even more power. What started out as a platform for social fluff quickly moved into the arena of personal causes and political viewpoints. Facebook’s interaction design makes it extremely easy to share anything online, including sites you happen upon that strike your fancy or boil your blood. In recent years, authors have responded in kind with a proliferation of websites with clickbait headlines, invalid content, and seemingly incriminating photos, specifically designed to illicit a visceral sharing reaction. People succumb to their shadow sides and respond with force.

Take, for example, the recent phenomenon of internet shaming. Some public “campaigns” have targeted people who have committed a cruelty, like the high-profile case of Walter Palmer, the hunter who killed Cecil the Lion. Whether or not he deserved the full extent of the vitriol against him can be debated and it can be argued that the online reaction will have an effect on curtailing the needless slaughter of big game. Nonetheless, judgment with punishment was exacted on Mr. Palmer without granting him access to his 6th Amendment rights for a trial by jury. For some people, it may be an argument for the end justifying the means. But the id doesn’t draw ethical lines in the sand.

Sigmund Freud described the id as “…a chaos, a cauldron full of seething excitations. …The id, of course, knows no judgments of value, no good and evil, no morality. The economic or, if you prefer, the quantitative factor, which is intimately linked to the pleasure principle, dominates all its processes. Instinctual cathexes seeking discharge–that, in our view, is all there is in the id.”

All people need to do is to allow clickbait to open the door to the instinctual cathexes seeking discharge, and the monsters will emerge seeking “justice.” No judgments of value, just…

In 2005, psychologist Justin Kruger and colleague Nicholas Epley of the University of Chicago published a study in the Journal of Personality and Social Psychology on the limitations of text-only communication in the form of email. Their research revealed that recipients often “hear” text communication differently than the writer of the message at the time of its creation. They found that people overestimate their ability to convey and hear the intended tone, including the distinction between sarcastic and serious messages.

This phenomenon played out in another shaming “campaign” brought to light by Jon Ronson, writer and documentary filmmaker, in his TED talk on internet shaming. Ronson describes how a young woman was targeted after having made what she thought was a self-ridiculing tweet using a poor choice of words that could easily be misconstrued. Her tweet was taken at face value and the Twitter world responded with a mind-boggling spiral of hate and viciousness. Her life was essentially destroyed.

The idea of internet shaming has been extrapolated to its logical next step in Charlie Brooker’s recent television series, Black Mirror. The episode Hated in the Nation portrays a modern world in which internet shaming combine with technological advances and hacking to create an unimaginable consequence to snap judgment condemnations.

Black Mirror is ostensibly science fiction. Yet, the most shocking aspect of this episode, and indeed the entire series, is that the stories are plausible with no suspension of disbelief required. This is the stuff of nightmares that could easily be a deadly reality of…

A hot topic after the American 2016 presidential election is the proliferation of “fake news” passed off as journalism. These stories are, at best, invalidated information and, at worst, blatant lies. There is good reason to believe that fake news had an impact on the results of the election. Yet, it should be noted that the line between lies and truth of online information is often blurry. There are plenty of publishing sources that, while not being untruthful per se, create a biased reality by choosing what they publish and how they present the story. Portrait photographer Enzo dal Verme presents a chilling testimonial of how even the mainstream media squelched his stories by forcing him to change or hide the truth because they feared repercussions from their advertisers. As long as people feel that they are entitled to have access to news for free, the media of necessity is forced to rely on advertisers for revenue.

Advertisers’ influence on publication bias is not new. What is new (again) is how quickly and widely lies can be disseminated around the world before they are even challenged and disproven. Couple this with an impatient public addicted to sound bites and unwilling to take the necessary time to read the details that would uncover lies, and you have conditions for a perfect storm of propaganda. As Oscar Wilde famously wrote, “The truth is rarely pure and never simple.” People have become so impatient that they can’t handle anything beyond simple. They move on to the next hot story to share it to get their rush of endorphins from “likes” in the bubbles that social media algorithms ensconce them in.

On whom does the responsibility for this situation fall? If you believe in the virtue of taking responsibility for one’s own actions, much of the blame falls on the public for irresponsibly sharing invalidated information that confirms their own biases. But after spending 17 years in technology, I argue that the makers of technological applications and devices share culpability for this uncivil “post truth” world. It is they who have rushed products to market in pursuit of accolades for creating the next “killer app” or to feed the cult of innovation that has reached evangelical status before considering how to address the inevitable unintended consequences.

Don’t get me wrong. I am a firm believer in the value of pursuing technological innovation. But I also believe in the necessity of due diligence to uncover the foreseeable implications of implementation. In Diffusion of Innovations, Everett M. Rogers concludes “The undesirable, indirect, and unanticipated consequences of an innovation usually go together, as do the desirable, direct, and anticipated consequences.” He goes on to cite the known example of what happened when missionaries gave the Yir Yoront Aborigines steel axes to replace the stone axes they already had. Axes were not simply tools in the Yir Yoront culture. They embodied great social significance and the action of missionaries, while made with the best of intentions to help the people, had the unintended consequence of unraveling the social structure of the tribe. Rogers warns that anticipating the form and function of an innovation’s consequences without anticipating its meaning for potential adopters is the path to disastrous unintended consequences.

We now see such consequences play out daily. Twitter has given people access to a world audience for “one liners” that can reveal the truth about events as they happen. But, did the creators of the application ever envision world leaders trading 140 character barbs on their platform as “shoot from the hip” diplomacy? Such communication dangerously circumvents the necessary subtle dialog that allows the diplomats to prevent war.

With astonishing speed, startups have leapt to connect an everyday object to the internet using wireless technology, creating what is known now as the “Internet of Things” (IoT). Many IoT startups have rushed their products to market (sometimes through “crowd funding”) without investigating the consequences for adopters. Now it has been revealed that these devices are particularly prone to becoming easy access gateways for hackers to reach personal data. The BBC reported that the German Federal Network Agency (Bundesnetzagentur) issued a warning to parents that the popular “Cayla” doll is giving hackers access to personal data through their children! The independent organization who defends all consumers in Norway, Forbrukerrådet (“The Consumer Council”), also published a video that shows how easily the doll’s security can be compromised.

Even Facebook, the social media giant, is scrambling to do damage control after realizing that their application’s algorithm driven interaction design has contributed to a viral proliferation of fake news. It is with great (and sobering) irony that Mark Zuckerberg’s statement about combatting fake news appeared right alongside two advertisements of fake news stories.

Some people will slog through his statement. Others will hit on the clickbait next to it and then…

I have spent my career engaged with understanding patterns, beginning 55 years ago with patterns in art, leading to patterns in visual design and then interaction design. In the last 15 years, I have come to understand and appreciate how patterns of human cognition underlie the foundations of User Experience. They are powerful subconscious motivators that move people to act, often without being aware of their own actions. They can be used to create clarity and transparency or, just as easily, deception and obfuscation of the truth (known as “dark patterns”). I now see patterns that provide pathways to release the monsters from the id. I hope more people will step back and refrain from engaging their monsters. But the technology industry must revise its approach to innovation with a new strategy of mindfulness, especially with regards to artificial intelligence. Many notable scientists, researchers, and entrepreneurs (e.g. Stephen Hawking, Sherry Turkle, Bill gates, Don Norman, just to name a few) have called for the same thing.

I ask my colleagues in the industry to consider that some of the most important contributors to innovation are people who assure its quality in testing and challenge it for its implications for adopters. Let us not allow the awesome power of technology to tempt people into making snap judgments and condemnations, lest we follow in the path of the Krell who gave their own monsters from the id the power to destroy them. ❖

Jim is a UX Designer with more than 15 years of experience in interaction design, IA, design patterns, heuristic evaluation, and accessibility evaluation.|||

Since the dawn of the 21st Century, innovations in internet technology have moved the world to what used to be unimaginable heights of connectivity. But have we the product directors, designers, and…