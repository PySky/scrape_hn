The connectivity, the world has achieved due to social media has a flip-side to it. It has been extensively reported that incidences of spamming by bots and fake accounts on Twitter have been increasing. Such accounts can help trend and spread Fake News and opinions, creating confusions and potentially, spreading rumors. Also, using bots and fake accounts to trend a topic on twitter or generate artificial likes is becoming commonplace. Twitter, in particular, is one of the worst sufferers of this “tragedy of commons” due to its openness. The talented engineers at Twitter respond with regular product and policy changes in order to curb this menace but the problem still persists. While the arms race between spammers and Twitter wages on, we tried to determine whether AI can help an information seeker stay on top of this game.

To bust fake accounts using AI, we first need to define what constitutes a fake account. We had two hypothesis about the type of fake accounts that could exist. When we tried to bust these accounts using AI algorithms, it turned out both of these hypothesis could indeed help us define accounts as “Fake” with certain probability. At Karna Analytics, our Machine Learning research team ran multiple experiments to track these type of accounts and categorised them in to two types — “Spammy Users” and “Bot Users” based on their activity and content of their post.

In this blog post, we talk about our approach that we use to detect “Spammy Users” (or “Spammers”) and how our approach can be used to improve the quality of research performed using data from social media. We have run our analysis based on data we tracked for two trending hashtags: #Presidentielle (For French Presidential elections 2017, which we predicted correctly using AI) and #Jio (A popular telecom company in India).

We observe that getting fake accounts to tweet and increase mentions about a #hashtag and make it trending topic is one of the most common spamming trick (google for “twitter hashtag trending services” and you would know what we mean). From spammers perspective, posting tweets from lots of fake accounts and that too in a quick succession is a challenging task. Ideally, a spammer should be posting tweets which are relevant yet different from each other so as to make the trend look genuine. Our key hypothesis is that achieving this within the constraints of time and money is challenging and potential spammers end up doing little to edit their tweets. As seen below, even celebrities that tweeted about Jio (probably as part of influencer marketing strategy) ended up posting the same tweets.

Based on this idea, we have found that spammers can be effectively identified if we look at all the tweets about a topic and figure out the tweets that are contextually very close to each other, made in a very short span of time (~15 minutes). For this, we use our proprietary text analytics algorithm called Semantic Similarity for clustering contextually similar tweets. To take an analogy from real world, we intend to use AI to closely examine answer sheets of students to identify who has cheated during the exam. For those looking to get some intuition on how this works, we have added below a visualization of how we cluster tweets that are contextually similar.

We analysed more than 50,000 tweets for #Presidentialle and #Jio and used Semantic Similarity technique to identify clusters of users that post very similar tweets multiple times. We produced the below list of potential spammers based on the contextual similarity and frequency of their tweets. If you search these users on Twitter, you would notice some users accounts have already been deleted or don’t appear in search results as they were classified as spammers by Twitter as well.|||

The connectivity, the world has achieved due to social media has a flip-side to it. It has been extensively reported that incidences of spamming by bots and fake accounts on Twitter have been…