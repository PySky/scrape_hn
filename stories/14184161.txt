Imagine you have an array of booleans (or an array of ‘conditions’), and you want to pack it - so you use only one bit per boolean. How to do it? Let’s do some experiments!

Read the second part here and also one update.

I started writing this post because I came across a similar problem during my work some time ago. The code in one area of our system packed boolean results of a condition into bits. I wondered if I could optimize that process. This ‘algorithm’ is not a rocket science, but as usually, it opened a whole box of details and interesting solutions. So I decided to share it with my readers.

To illustrate the problem, we might think about an image in greyscale. We want to generate another image that has only two colors: white or black; we use a threshold value to distinguish between white and black color from the input image.

The input has some integer range (like 0…255), but the output is boolean: true/false.

Then we want to pack those boolean values into bits so that we save a lot of memory. If is implemented as 8bit unsigned char, then we can save 7/8 of memory!

For example, instead of using 128kb for 256x512 greyscale image, we can now use 16kb only.

Should be simple to code… right?

Alternatively, we might remove the threshold value and just take input array of booleans (so there won’t be any need to make comparisons).

Please note that I only focused on the ‘packing’ part. With the packed format you save memory, but there are more instructions to unpack a value. Sometimes this additional processing might cause the slow-down of the whole process! Always measure measure measure because each case might be different!

This problem is similar to compression algorithms, although packing is usually much faster process. As always, there’s a conflict between the storage and the computation power (Space–time tradeoff).

I want to compare several implementations:

Plus, the next time we’ll also add parallel options…

For the benchmarking library, I decided to use Celero. You can find more details about using it in my post about Benchmarking Libs for C++.

With Celero there’s an easy way to express different options for the benchmark. So for example, I’d like to run my code against different sizes of the input array: like 100k, 200k, … Also, there’s a clean way to provide / methods that will be invoked before each run.

Originally I used the version as a baseline, but that could be misleading. Thanks to the comments I’ve updated the benchmarks. It’s much better to see the ‘no packing’ version as the baseline, so that we can see if we gain something or not.

It might happen than versions with packing will perform slower than the simple approach.

The code is as follows:

is an array of .

OK, this version will be really simple, take a look:

The only drawback of using bitset is that it requires compile time N constant. Also, bitset is implementation specific, so we’re not sure how the memory is laid out internally. I would reject this version from the final production code, but might be good for comparisons.

For example, here’s the fixture for this baseline benchmark:

In we check our generated values with the reference - just checks the values and prints if something is not equal.

Another simple code. But this time vector is more useful, as it’s dynamic and the code is still super simple.

This time, we generate the vector dynamically using (N - the size of the array).

Remember that is a special implementation of the vector. It doesn’t contain array of bools, but it holds just bits (in an unspecified way). In terms of memory it should use much less space than unpacked version.

Still, might not be a good choice for the production code; see 17.1.1 Do not use std::vector | High Integrity C++ Coding Standard.

The first two versions (and the baseline) were just to start with something, let’s now create some ‘real’ manual code :)

I mean ‘manual’ since all the memory management will be done but that code. Also, there won’t be any abstraction layer to set/get bits.

The setup looks like this:

is just a to array of . We have full bytes and also there’s one at the end that might be partially filled.

The first case will use just one variable to build the byte. When this byte is complete (8 bits are stored), we can save it in the output array:

The first manual version has a little drawback. As you see, there’s only one value used when doing all the computation. This is quite inefficient as there’s little use of instruction pipelining.

So I came up with the following idea:

Instead of working on one variable I used eight different variables where we store the result of the condition. However, there’s still a problem when doing that large . For now, I don’t know how to improve it. Maybe you know some tricks? (without using SIMD instructions…)

Was I right with this approach of using more variables? Let’s see some evidence!

The optimized version (using separate variables) is roughly 5x faster that and almost 3.5x faster than the first manual version!

As it appeared, there’s also at least one more reason why the optimized version is faster. You can read more in another post: Curious case of branch performance. Basically the first version has branches while the optimized can use conditional move instructions - and in this case that improves perf.

Even such simple sounding problem caused me some problems when implementing (hopefully) correct benchmark! Initially I’ve chosen as the baseline, but it’s much better to see version. Now you can see that packing actually can slow things down (when using wrong data structures). My manual version seems to be a bit better - you can potentially save 7/8 of the required memory space, at pack data almost 20…30% faster than no packing version.

Without looking at the traces, profiles I optimized my first version by using more variables to compute the conditions. That way there was less data dependency and CPU could perform better.

Next time I’ll try to parallelize the code. How about using more threads or vector instructions? For example, I’ve found a really interesting instruction called: … See you next week.

I would be grateful if you could run the samples and provide me with your results! Let me know, so I can even provide you with the binaries for Windows.|||

How to pack booleans into bits? I compared several options and measured performance.