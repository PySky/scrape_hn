You were an early employee at Cloudera, and then co-founded a Hadoop-based company called WibiData. How does your “big data” experience relate to what you’re doing at Zymergen?

This is definitely a pretty big leap away from those original businesses. The traditional way of doing this kind of work involves scientists creating hypotheses one by one, and then manually constructing these genetic changes and new microbes with pipettes, which is a pretty low-throughput way of doing the work. It’s a very hit-or-miss kind of proposition because, as it turns out, humans are not terribly good at a priori figuring out which genetic change is going to unlock that increased performance.

At Zymergen, we have an automated wet lab factory where we can produce a very large number of genetic changes using laboratory robotics. At that point, once we have this kind of throughput to test hypotheses, then we can start to think of this more like a search problem. We can use pattern-matching and machine learning to guide the [process and rank results], and then feed them through this research engine that we’ve built in order to test as many hypotheses as efficiently as possible.

Are you hosting the computing portion of this yourself or, presumably, in the cloud?

The servers are hosted on Amazon Web Services. The software stack that we have built on top of it, while relying on some open source infrastructure for data flows and basic handling, is a custom stack that we’ve been developing in-house for the last two and a half years.

I’ve heard Zymergen described as an artificial intelligence company. Is that accurate?

I think people often use the term artificial intelligence to refer to the strong AI concept, something like Siri or Alexa that seems almost preternatural, and we aren’t working at that level. There isn’t an omniscient voice that pipes through the speakers to tell people what to do, but we do use machine learning to help see patterns that humans would not otherwise recognize in our genomic studies.

Something that is worth appreciating is exactly how vast the genome is and the many different levels on which we can comprehend it. We think of the genome as a collection of As, Gs, Ts and Cs — the DNA letters — but making genetic changes at that level is a very difficult proposition. It’s like trying to change the instruction set of a computer without a reference manual.

But we can also read the genome as a higher-order collection of words or sentences or stanzas. We might not know what each one says, but there are relationships between these different elements, and by applying machine learning to the collection of genetic changes that we’ve already made as well, as our knowledge of the genome of the microbe that we are improving, we can target our future studies with considerably better accuracy than if we were mechanistically going left to right.

Where did the big step function, or step functions, occur that made Zymergen’s work possible? In data? Computing? Genomics?

I think that there’s changes in every one of the areas that you’ve mentioned, and it’s really the confluence of all of these that makes this possible. First, laboratory robotics are more reliable and more available, and that allows us to scale up our testing capability. On the software side, we now have the capability to generate large collections of hypotheses to test. That is partially due to the very low cost to scale out cloud computing. It’s partially to do with the availability of high-quality machine learning libraries and other data-handling technology, that we can assemble these open source components and rapidly build it into something that focuses on a particular problem.

I think that it also comes from a cultural change, which is that throughout Silicon Valley we’re starting to see a lot more startups that are a hybrid of a technology company and some other industry. Look at the way that Uber is thinking about cars and driving — and technology. Look at Cruise, which got bought by GM, and was focusing on self-driving cars — and technology.

This is also happening in the biotech space, as well. Traditional biotech was much more heavily focused, with an emphasis on the bio more than on the tech. Whereas, at Zymergen, a fifth of the company is engineering. We have a large number of scientists who are running research campaigns and pushing our capabilities forward, taking advantage of the latest in DNA manipulation techniques, and we have a large collection of engineers who are building powerful analysis platforms that give them a much longer lever with which to do this science.

How does a “tech-plus” company, like an Uber or a Zymergen, use tools differently than a more traditional tech company that exists only in the software realm?

Consider the example of WibiData, the company that I previously co-founded. We were focused on the retail ad-tech space for improving recommendations. In retail, you’re combining this fixed catalog of items for sale with the clickstream data that’s coming in from users, and so it’s this very closed loop of developing internet technology that runs on the internet and only extends the internet. The data is very regularized. Clickstream information is incredibly homogenous and can practically be handled by a SQL engine, were it not for its size.

In biology, you have this much messier collection of data that you’re working on, and everything is a statistical approximation of some ground truth. Experiments in genomics never succeed or fail in a binary fashion. It’s always that some percentage of your samples got the genetic change effectively made — it will never be 100 percent, and it will, unless something’s gone catastrophically wrong, never be 0 percent. There’s more nuanced judgment calls to be made at every step, and so it’s much more important to be statistically rigorous in the boundaries of what you know and what you can apply that to.

For example, the scale of DNA is 3 million to 6 million bases per microbe. That’s a search space of 4 to the 3- or 6 million changes that you can recommend, compared to recommending items from a catalog. There might be 500,000 items in a very large catalog for a retailer. So, it’s a fusion of different data types and you have to read the tea leaves a lot more into what information you can extract from that data.|||

AARON KIMBALL: We’re in the business of industrial fermentation — making microbes that make chemicals. And we help other companies that make microbes that make chemicals improve those microbes. These…