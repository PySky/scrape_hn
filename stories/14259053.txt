The headline was, at best, misleading.

Eric Loomis wasn’t sent to prison by a software program. And he wasn’t sent to prison by a program’s secret algorithms. He was sentenced to prison by a judge, just like anyone else sent to prison. Never forget that. But the length of time for which he was sent to prison was influenced by a program and its secret sauce.

The report in Mr. Loomis’s case was produced by a product called Compas, sold by Northpointe Inc. It included a series of bar charts that assessed the risk that Mr. Loomis would commit more crimes. The Compas report, a prosecutor told the trial judge, showed “a high risk of violence, high risk of recidivism, high pretrial risk.” The judge agreed, telling Mr. Loomis that “you’re identified, through the Compas assessment, as an individual who is a high risk to the community.”

There are two separate issues raised by Loomis’ case, and the Supreme Court appears interested in at least one of them. The first question has to do with whether any human being should be sentenced based upon some empirical measure, the Sentence-O-matic 1000. No matter what the numbers show, or whether it’s just a proxy for racist assumptions, or just an excuse to lift the unpleasant task of putting a person in prison off a judge’s shoulders.

But many who swear by hard, cold data see this as a given, even if they don’t really have a sense of the multitude of potential considerations that might go into a sentence. And they have a point given that the alternative is judicial voodoo.

But the Loomis case deals with a collateral issue, beyond the adoration of data as a substitute for a judge taking the responsibility of her job seriously. This program, Compas, was created and sold by a company named Northpointe, and like any good company trying to make a killing, it wasn’t about to give up its secret sauce.

But that begs the question. Did the report add “valuable information”? Certainly Northpointe thought so, but then, they had a product to sell. Without giving up the proprietary algorithms such that their validity could be tested and challenged, there is no basis upon which the court could determine whether the information was valuable. More importantly, there was no way for the defense to argue that it wasn’t. You can’t challenge what you can’t see.

Or, the algorithms are malarkey, like the great story of the cops using a copy machine as if it was a lie detector, tricking the perp into confessing. If you don’t know how it works, there’s no way to know that it doesn’t. And even if Compas is legit, is it good enough to stake a person’s life on? But even if it isn’t, is it any worse than whatever pops into a judge’s head?

This isn’t to say that Compas is wrong, evil or malarkey, whether total or a little bit. Nor is it even to say that it doesn’t do a better job of determining, in a generic sense, whether a person is more likely to commit more crimes. It may well do the job it purports to do, despite questions raised. But the official response to not knowing is, well, remarkably unhelpful.

This isn’t coffee. “Further percolation” is meaningless gibberish. If Compas is going to be used, it has to be valid. The State of Wisconsin doesn’t get to enjoy the benefits of its purchased program only to figure out, or not, at some point in the future that it’s a steaming pile of feces. Either it can pass muster or not, and until it does, no person should be subject to its data-claimed conclusions.

But what of Nothpointe’s pecuniary interests? It’s no crime to sell a product, and it’s no crime to want to protect the value of the product it sells. Does the Supreme Court hate capitalism?

Of course not, but that isn’t the point. Nobody forced Northpointe to put its efforts into a program to be used by the state, by a judge, to sentence human beings. If that’s where you choose to make your stand, then you don’t get to complain that it comes with strings, such as allowing the defense the opportunity to test and challenge its merit, its efficacy.

No matter how much you love capitalism, you dove into a pool of due process and can’t complain about getting drenched. The question isn’t whether Northpointe should be allowed to keep its proprietary algorithm secret. The question is whether a defendant is entitled to due process before a tool, any tool, is used to determine what will become of his life.

So, easy-peasy case for the Supremes? Not quite. There remains a kicker in the background.

Would he? So they say. And if the sentence falls within the usual parameters, the guideline range of reasonableness as a federal circuit might opine, does it really matter whether Compas is sound or not? It’s a ledge to which Northpointe can cling when defending its moneymaker, and it’s an out for the Supreme Court to shrug off any claim of potential harm. After all, even if the algorithm turns out to be garbage, there’s nothing to do when the error is harmless.|||

