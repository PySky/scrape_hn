Mathematical approaches become more and more relevant in policing. In the CBS series Numb3rs a mathematician genius helps his FBI agent brother to solve crime using maths. It turns out that much of the maths used in the series is actually relevant for law enforcement and indeed Wolfram Inc advised the maker of the program on the maths. There are many approaches described in the series and in the book "The numbers behind Numb3rs": geoprofiling is one of the most prominent methods.

It turns out that Los Angeles mathematicians work together with the police on a methods called predictive policing, where data and mathematical approaches are being used to direct police officers to locations with a high probability of a crime being committed. A substantial drop in crime rates has been reported. The mathematician Prof. Andrea Bertozzi is leading efforts in predictive policing. Here is a brilliant talk on one of the approaches. In the video they discuss a model based on the (near) repeat victimisation theory - which is based on the observation that often the same or similar targets have a higher likelihood of being targeted again.

In this post I will implement (something similar to) the discrete version of their model and then extend it using some data. We will obtain graphics like this one that shows how crime hotspots develop over time.

A higher resolution video can be found on Youtube.

We start by analysing some actual crime data made available by the police in the UK. It is freely available at the website: https://data.police.uk/data/. There is a wealth of data - and actually it is quite frightening to see how many crimes are committed. I suppose that this data would be great for the Wolfram Data Repository. I will start with the December 2016 data for Avon-and-Summerset. Once downloaded I can import the data.

I only show one dataset. There are 13751 entries in this particular file. We can now look at the tally of the different crime types:

So violence and sexual offences "top" the list. The following bar chart visualises the this tally:

Next we define rules to label the different types of crime:

We can then generate a list of locations and types of crime and plot it:

We can also look at particular types of crime and plot that:

We can wrap that into an interactive Manipulate environment:

We can of course also calculate the distribution of a particular crime, here burglary.

Alternatively, we can remove very low incident rates.

We can also focus on the city of Bristol.

Next, we can investigate how this distribution changes over time. We will need more data and, as it turns out there are more categories of crime in the entire dataset.

We can play this with

We will build a model which is very similar to the model of Prof Bertozzi. We start out with a grid of houses. Each has a base attractivity for burglars and "added attractivity" according to the history of close burglarlies. Burglars are placed randomly on the grid and tend to move towards houses with higher attractivity.

With a certain probably proportional to the attractiveness the burglar decides to raid the house.

That changes the "added attractivity" of the house that was attacked and of the neighbouring house. This added attractivity decays over time. When a burglar strikes he is removed from the grid and replaced by a new burglar, which is added at a random position.

The process is then iterated.

The number of burglars is kept constant.

We also introduce a "sure-hit-attractivity", i.e. if a house reaches that limit and a burglar gets there, they will definitely strike. Here is the implementation of that process.

Note that there are several "tricks" that make the code run faster. The most obvious is that I do not add the "addedatractiveness" to all the neighbours one by one, but use the function ListConvolve with the GaussianMatrix.

Here are some snapshots from the model.

Hotspots of crime seem to develop spontaneously and move. So we have moving hotspots - this is interesting because the underlying base attractivity is uniform. This means that we have a sort of self-organising pattern of hot spots. This, of course, depends on the parameters we choose. The following choice for the initialisation leads to no patters at all.

This last set of parameters will lead to stable/periodic spots, i.e. spots that move little over time and lie on lines.

Here is a movie of the three situations (where the list of frames were named intuitively).

In fact, I exported the frames and used an external program to generate the animated gif.

We will now try to add spatial information to the model and thereby try to make it "more similar" to the data. We will use a map of Bristol as background.

We will then crop the image. I have used the crop tool for that and attach the image so that you can work with the same file as me.

This is 560 by 560.

Last but not least we adapt our program as to use a 560 by 560 grid and use the background map as base attractiveness. Note that we are using periodic boundary conditions.

The full movie in low resolution is shown at the beginning of this post. A higher resolution video can be found on Youtube.

There are obviously many bits that can be improved. On thing that is interesting is to study the movement of the potential robbers.

Here are some frames from that movie.

In the respective movie it is possible to follow the robbers:

A high resolution video can be found of Youtube. They obviously move "randomly". Even in the model with the background attractivity they will move in a rather unconstrained way. We could obviously restrict them to the street network etc. Also, we could use data on the properties to get a better estimate of how attractive a house is. Furthermore, we could use the "heat map" data of observed crime and tweak the parameters to try and predict where robbers might strike next.|||

Wolfram Community forum discussion about Predicting patterns of crime "repeat victimisation"  (long loading time). Stay on top of important topics and build connections by joining Wolfram Community groups relevant to your interests.