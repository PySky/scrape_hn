Here is what I learnt while testing backend calls to the database on a project using node.js with Loopback and a PostgreSQL database though this article would apply to any technology.

Basically, it all goes back to saying that each test should have full power over its data. Each test must ensure its independence by cleaning the database first and then defining its own dataset according to its needs.

When testing a function that reads or writes in the database, it is crucial that you know exactly what data it contains. This means that you should setup the dataset yourself and not rely on any previous data it may contain. This also means you need to clean the database before putting any test data in the database.

In our project, we used to clean the data at the end of each test thinking this was a good way to make our tests independent. However, making the assumption of a clean database is nothing else but making all tests dependent. This is actually a bad practice because a test could break because another test changed.

As a matter of fact, we forgot to clean the database after a few tests. As a consequence, other tests that were executed afterwards were failing randomly depending on the order of execution. We would relaunch all tests until they all passed… Then we moved the cleaning of the database at the beginning of the tests so that each test was responsible for its independence. The result of each test became consistent as they would pass or fail always in the same way across executions.

Yes some tests did fail after that. This highlighted the fact that they were poorly written, which leads me to my second point.

At the risk of repeating myself, it should be clear what data you have in your database at the beginning of a test. Otherwise, your tests will not be easily maintainable.

In our project, we used to update a common set of data and load it for each test.

We soon faced two problems:

When it became impossible to update this common dataset, we decided to define an entire new set of data for each new test. This takes time and requires more lines of code, but eventually made us more efficient. We were able to write more tests in the same amount of time and thus write tests for more cases.

You want to make your data as easy to use as possible. Fetching data by id will simplify your tests and make them more readable.

We were not doing this on our project because alls ids were auto-incremented by the database. Consider for instance two persons whose names are ‘Person A’ and ‘Person B’. We want to check that Person A gave 100€ to Person B. If we don’t know the ids for , , and , here is what the test could look like using Loopback.

Now, if you hard-code ids, here is what this test might look like:

What we would love to write is actually this:

The function needs to fill table before table in order to avoid a foreign key constraint violation error on table for constraint . We write this function in a module that will be common to all tests.

Note that feedDatabase needs to be given which is the application instance.

Let’s improve our example above. Each bank account needs to belong to a bank.

To satisfy this constraint, our data in the test needs to look like:

We also need to add the model to in the common module:

However, the bank to which the bank accounts belong has no impact on our transfer function. We would like to keep in the test only what is meaningful.

In another common file, let’s define a data initializer. It should contain no business data but a default value for each model with id 1 by convention. The initializer is not meant to be used as test data. Its aim is only to help satisfy foreign key constraints.

In our test, we can now write:

It’s important that you override and to be able to see all useful data within the test itself and not be dependent on default values such as the default bank account amount.

When hard-coding ids as we did, any further attempt to insert a new entry in the database without hard-coding its id will fail. Indeed, while we inserted data with hard-coded ids, the id sequences were never updated. The database will automatically try to insert the new entry with id 1, which is already used.

The best way to deal with this problem is to reset the id sequence manually. The most transparent is probably to restart the id sequence at the max id of all inserted rows.

When using the function, I once had trouble understanding a bug in one of my tests. I had forgotten to add the new model I had just created to the constant. I made a small change to in order to count the number of inserted models. The function now returns an explicit error when one model of has not been used.

You liked this article? You'd probably be a good match for our ever-growing tech team at Theodo.|||

