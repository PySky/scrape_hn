TensorFlow is a beast. It deals with machine learning algorithms, it uses Bazel to be built, it uses gRPC, etc., but let’s be honest, you are dying to play with machine learning. Come on, you know you want to! Especially in combination with Docker and Kubernetes. At Bitnami, we love apps, so we wanted to!

You just need to add bi-modal in there and you will hit buzzword bingo.

Jokes aside, TensorFlow is an open source library for machine learning. You can train data models and use those models to predict or infer information. I did not dig into TensorFlow itself, but I hear it is using some advanced neural networks techniques. NN have been around for a while, but due to computational complexity, they were not extremely useful passed a couple of layers and a couple dozen neurons (20 years ago at least :) ). Once you have trained a network with some data, you can use that network (aka model) to predict results for data not used in the training data set. As a side note, I am pretty sure we will soon see a marketplace of TF models.

The Inception model is a TensorFlow model trained using the ImageNet library. With that model, you give it an image and TensorFlow (TF) tells you what that image is. In March last year, there was a blog about how to run the inception model in Kubernetes. Great! Except that with things being what they are… what is described in the blog is now broken!

So I am going to share a few tidbits about trying out your first TensorFlow model (the Inception model) and running it in Kubernetes using an 88 MB Docker image. If you are courageous enough to figure out what is broken with the original blog post, you will end up with a ~4.2 GB image, and I think it is way too big and unpractical.

We are working on this at Bitnami to develop a production Helm Chart for TensorFlow and use it with our serverless solution Kubeless.

You can find our (Tomas Pizzaro @tompizmor and I ) WIP right here.

We followed the general build instructions but replaced the base image with our own minideb, a minimalist Debian Docker image. We also put the Bazel build instructions in the Dockerfile, which allows us to build TensorFlow with a single Docker build. It works great if you give enough RAM to Docker and limit the local resources used by Bazel.

You can run this image, but it is BIG (~4.2 GB), and it does not serve any actual trained data model, so it is useless in itself. This is just running the TF serving server.

The build process is less than ideal and we will integrate it with our internal automated toolchain, but for now it will do.

To make this easier and because I refuse to pull a 4.2 GB image every time I want to run this, we did a super terrible hacky thing. We just did an ldd on the TensorFlow serving binary, copied the binary and libraries out of the image, copied them into a minimal container based on minideb, and got an 88MB image:

To load the Inception model, we decided to use a Kubernetes PVC and a Kubernetes Job. That way, we seed the PVC with the model. The Job is just curling the Inception model and sticking it into the PVC. You can try all of this on minikube.

Now that we have the Inception model data in a PVC, we can run the TF serving server as a deployment and use an init-container to load the model before serving it.

Now that the Inception model is being served, you can expose the deployment via a Kubernetes service and run the client to use it.

And locally on your machine, run the client container (actually bigger than the server because we have not yet slimmed down the Python client fully) and stream an image to the server (note that the streaming uses Python grpc).

Give it a beautiful image like this:

And your super buzzword friendly setup of minikube Kubernetes with the TensorFlow Inception model will spit out:

Which I believe tells you that it is 81% certain that this is a Labrador retriever and also tells you that I need to dig deeper into the results of the inception model. :)

If you want to see more blogs like this, don't forget to reach out on Twitter @sebgoa.|||

Machine learning dabblers know about TensorFlow, so dive into containerizing and orchestrating a machine learning model, thanks to Docker and Kubernetes.