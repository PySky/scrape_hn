There’s a new feature in Chrome Canary: JavaScript code coverage. It tells you how much of your code is actually executed, vs how much is loaded unnecessarily.

I wondered how it’s implemented… these are my findings from bumbling through the source code with Chrome code search. It’s C++, but don’t worry, I don’t know C++ either. :)

DevTools uses the Chrome Debugging Protocol to communicate with V8. Before looking at the Chrome code itself we can check the protocol documentation to get an idea what’s going on.

There’s a endpoint that takes a parameter. If that parameter is true V8 will count the number of times the code has run, rather than just giving a binary value.

To generate the coverage report that’s shown at the top of this post we don’t need to count the exact number of calls, we just care whether or not the code has run.

There’s also a endpoint, but unfortunately there’s no example of what a coverage result looks like. There are two ways we can learn more.

First, we can debug the debugger and set a breakpoint after searching for . Stepping into the call we find a method where the results of requests that DevTools makes to V8/Chrome become available.

This is the an excerpt from the data that gets sent to Chrome DevTools:

As you can see it lists ranges of code and says how often they’ve been executed.

But I said there are two ways to get this info. The other way is to find the tests for the module in V8 and look at the expected result:

We now have a decent idea of what the API that V8 provides looks like. Next we’ll take a look at the actual API implementation.

By searching for we can find the relevant C++ code.

I don’t really understand this. But what matters is that we can click on some of the types in Chrome code search and find more code.

For example, if you click on we’ll find this:

Even if you don’t know the language you can always read the comments!

Looking back at the method we can see that is used if is passed in, otherwise .

By clicking through the Chrome Code search UI you can discover more. I’ll highlight some of the things I found interesting below.

One of the things I was curious about was how it knows exactly what code range has run. It turns out that tracking isn’t actually that exact and it happens at the function level.

Functions have a which can store the number of invocations.

Here. The name suggests it’s to do with V8’s new Ignition interpreter. But the code also appears to depend on the platform (there are different implementations for ).

Anyway, I doesn’t matter all that much. This is the code that matters:

We add 1 to the invocation count.

FieldOperand points to the address of the invocation count in memory. at this time points to the location of the feedback vector in memory. Then V8 does some calculations to find out where the invocation count is in relation to the feedback vector object.

A Smi is a small integer. It’s a pretty ordinary integer, except V8 uses one bit to remind itself that this value isn’t a pointer.

When enabling coverage all optimizations are disabled:

Future inlining is disabled - I don’t know exactly inlining means in this context.

However, if we only care whether or not a function has been called - rather than the exact invation count - V8 does enable inlining once the invocation has been reported.

The coverage report works on a per function level by incrementing a counter when a function is called.

And Chrome code search is a truly helpful tool to figure out what’s going on!|||

