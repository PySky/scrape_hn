*In this article we will explore some concrete examples of the many uses and intricacies of the memoize function from the Clojure standard library. If you enjoy this article, you might very well enjoy the Clojure Standard Library book: save 37% off the book with code fccborgatti. *

is a function in the Clojure standard library that adds caching capabilities to another existing function using the invocation arguments as key. When the wrapped function is invoked with the same list of arguments, the result is returned immediately from the cache without any additional computation. The effects of are readily visible if we print any message from the wrapped function:

The first invocation generates the message (the following invocations don’t), confirming that the wrapped function is not invoked again. Conventionally, if the wrapped function is not meant to be used directly, the star character gets added at the end of the name, while the “memoized” version is named without one.

formal specification of the function signature is as follows:

works well for non-trivial computations accepting and returning values with a relatively small memory footprint. The following example illustrates this point. The Levenshtein distance (this Wikipedia article contains a good introduction to the Levenshtein Distance algorithm) is a simple metric to measure how different two strings are. Levenshtein distance can be used, for example, to suggest corrections for the most common spelling mistakes. The Levenshtein distance is straightforward to implement, but becomes computationally intensive for longer strings (above 10 characters long). We could use to save us from computing the distance of the same pair of strings over and over again. The input (the strings arguments) and the output (a small integer) are relatively small in size, so we can cache a large amount of them without exhausting memory (assuming the list of words with which the function is invoked is a finite number that we can estimate).

To feed our example we are going to use the dictionary available on Unix systems at “/use/share/dict/words” which is a plain text list of words. If we were asked to implement an auto-correction service, it could work as follows:

Although, in our example, we are just implementing the essentials, concentrating mainly the application of , we are also going to pre-compute a dictionary of words starting with the initials of the word, a technique to further speed-up the Levenshtein distance calculation:

The memoized version of the Levenshtein distance function is storing each new pair of strings as key and the returned distance as the value of an internal map. Each time the function is invoked with the same arguments, the return value is looked up inside the map. Comparing long strings seems to benefit from caching intermediate results and the elapsed confirms the theory.

This example also shows the way the memoized Levenshtein distance is “trained” before actual use. The application could pre-compute the set of dictionaries by initials (similar to the indexing happening inside a database). This technique contributes to the speed-up seen in our Levenshtein implementation, but consider that there are also other algorithms out-performing Levenshtein (See the list of metrics available on Wikipedia).

There is a reason why storing arguments and return values is called “memoization” instead of just “caching”. Memoization is more specific because it implies two features normally present in functional languages: pure and higher order functions.

Pure functions The wrapped function needs to be referentially transparent. If there was a way for the output to be influenced by factors other than the function arguments, then cached results could be different depending on the context. The cache would then need to be aware of the context and use it as part of the key. Memoization becomes straightforward in functional languages supporting referential transparency.

Higher order functions “Higher order” refers to the property of a function to be treated as a value. As such, the function can be stored, passed to other functions or returned. Not all languages offer higher order functions, although it is now more common to offer this feature. By describing this kind of caching as “memoization” it is implied that a function can be transparently decorated with caching capabilities. “Transparently” in this context means that the original wrapped function remains untouched.

These are other functions in the Clojure standard library that have a similar or related use to .

The main aspect to consider about , is that it stores cached items indefinitely. Constant accumulation of new cached values will eventually exhaust memory. users should pay attention to these facts when designing their solution, more specifically to the prospected distribution of keys in the cache. should not be used in cases of long-running services when the amount of argument permutations is potentially infinite or not easy to predict.

We can gather some statistics about the key distribution with some changes to the original function. The following contains additional atoms to collect data cache hits, misses and total number of calls at run-time.

By accessing the additional stats at run-time, we can estimate the key-space size or the memory footprint. For example, if we run the previous Levenshtein memoize example replacing with we can extract the following results:

As you can see, the first time the function is invoked it generates 400 misses, while the second time it results in all hits. We can also estimate the memory taken by the strings stored in memory which is around 10Kb.

The second aspect to consider when using is the additional hash-map operation and atom that is added for each new key combination presented as input. The hash-map adds steps to add a new key while the could under-perform under heavy thread contention. Depending on the application requirement, could be built on top of a data structure to avoid the performance penalty of filling the cache. Another option to consider, when possible, is “warming the cache”: while the application is still not serving live traffic, the cache could be populated artificially with the most common keys.

Now that you know some of the ins and outs of using , perhaps you’re more interested in learning more about the Clojure standard library. If so, download the free first chapter of Clojure Standard Library and see thia Slideshare presentation for more details.|||

Exploring the memoize function *In this article we will explore some concrete examples of the many uses and intricacies of the memoize function from the Clojure standard library. If you enjoy this...