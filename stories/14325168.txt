It's easy to get lost amid the robots. Self-driving golf carts roll around the Dallas Convention Center. Winged drones hang overhead, missiles at the ready. Torpedo-shaped bots bob in water tanks. Blimps display ads in Blade Runner fashion.

At first, Intel CEO Brian Krzanich's keynote speech at the AUVSI Xponential autonomous vehicle conference seems to fit this hardware obsession. He not only takes the stage riding a robot—a modified Segway built with the company Ninebot—but also invokes a swarm of glowing drones to put on a light show. But Krzanich isn't here just to talk about the machines. There's an invisible data tsunami approaching as these machines get smarter and more ubiquitous.

Self-driving cars are a prime example, Krzanich says. "In autonomous vehicles, the data produced increases exponentially. They are data centers on wheels." A slide titled "The Coming Flood of Data" appears over his head as he does a scripted bit of scratch math: One million autonomous cars will produce as much data as half the population on earth. And the numbers only grow when you consider other uses for emerging robots. Industrial bots on factory floors and hospitals will generate terabytes. Flying drone inspections of bridges, pipelines, and airplane hangars produce information that will need to be evaluated immediately and also archived for any future forensic work, should an accident occur.

To Intel, this approaching wave of data is an opportunity. Krzanich invokes a familiar but still piercing line, telling the crowd "data is the new oil." But, like oil, crude data needs to be refined and delivered, or else it's useless. "Flying a drone and capturing images is not where the true value is found," he said. "You have to process it."

Robots are both consumers and creators of data. Take your workaday military drone. Its primary job is to capture images of the ground below. It also provides data about itself, like the health of its systems and its altitude, and it has onboard radar that captures a radar sweep of the airspace. The unmanned aircraft needs to accept data to operate, too, such as the GPS signals that keep it on course and the commands from human operators. (It's a flying data collection center, someone might say.)

That's just a simple drone with a video camera. Nowadays, sensors are getting smaller and less energy-intensive, so engineers want to add more of them. How about some more cameras to expand the drone's field of vision, or infrared and low-light vision? Now you're talking about a drone that's much more capable—and one that has a data problem. It's collecting plenty of info it wants to share, multiple images in multiple formats, but transmitting all of that to the ground takes up a ton of bandwidth and power. (Think of bandwidth as a straw that can only handle so much data before clogging.)

The drone needs to be smart enough not only to compress all this info, but also, ideally, to filter it so it transmits only the most relevant information. What about the cloud, you say? While relying on servers somewhere else to process this information is a solid idea, the data still has to go from the robot to a server somewhere, which opens you up to problems of speed, security, and bandwidth.

Since this is a military drone is our example, imagine image recognition software that matches the shapes of anti-aircraft below and immediately alerts ground controllers with an image and tracks the target. Now let's go farther and have the drone automatically patch itself into signals intelligence database to check the radio emissions coming from the shape's location captured by an AWACS flight. The drone also asks for and gets earlier images of the area, checking the two images for differences in the two images. In microseconds, the analyst on the ground gets a fully automated rundown on the shape, seeing images of recent track marks and evidence of radio communications on military frequencies coming from the vehicle. The identification is all but confirmed even before the image reaches human eyes.

This is all a long-winded way of saying that there's a difference between data and information. Data is good, but it's the haystack. Finding the needle just when you need it, that's the trick.

Imagine a scenario in which all kinds of sensors work together to create a visual timeline. John Riehl, executive vice president of Video Bank, walks me through one. His example: the deadly Dallas sniper attacks of 2016.|||

The new world of robotics and self-driving cars will create a mountain of data. But that's the haystack, not the needle.