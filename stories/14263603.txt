Imagine that you’ve just moved to a new city. Whenever you need to go somewhere, you ask a special machine how to get there. But it doesn’t show you a map: it tells you to take twenty steps, turn left, go forward a hundred steps, etc. When you step outside, you’re blindfolded, so you can’t observe street names or other landmarks, but after years of traveling this way, you always arrive safely and on time, so you’re not complaining.

Navigating that way, you’ll have no idea how to get somewhere new without those step-by-step instructions. You’re unlikely to discover anything surprising while in transit, you won’t devise shortcuts to your destination, and you won’t notice when one location abuts one you’ve already visited. But this is exactly how we are typically taught!

This approach to knowledge is almost ubiquitous: math students memorize the steps to integrate equations that look a certain way, physics students memorize equations of rotational motion separately from equations of linear motion, computer scientists memorize the properties of various data structures. They know how but don’t understand why. It’s the only way of learning that many people experience throughout their education, so it’s the one they keep applying after graduation.

A student who learns the results of a field—without understanding the explanations which led to those results—is stuck making essentially vocational contributions. He can apply the hows he’s already learned in the scenarios preidentified by his teachers, but without the whys used to make those hows, he can’t readily synthesize new solutions or cope with new scenarios, just like our blindfolded city navigator.

Of course, it’s okay not to know everything all the time! Learning why certainly takes quite a lot longer than learning how. You might even motivate yourself to learn fuller explanations by first learning their exciting results. Danger only appears when pragmatic knowledge of hows is mistaken for true understanding—that’s when the knowledge perpetuates its own limitations and poisons surrounding endeavors. I’ve watched it pacify with intimidation, confine with fear, and (most dangerously of all) promote indiscriminate stasis. I see veterans of industry walking around with eyes closed, counting their steps.

I’m fortunate to live and work in a community of brilliant people. It’s certainly important to recognize peers’ contributions and skills, but sometimes I hear myself and others singing a different kind of praise. Breathless praise, helpless praise, praise almost sighing in frustration: “Wow. That guy’s just so damn good.”

Admiration can be productive: it might help distill that role model’s shine into some useful goal (“looks like I need to brush up on my statistics”) or observation (“maybe that approach would be useful in this other problem”). But that “so damn good” praise hides intimidation; it can’t offer insight because the speaker can’t even begin to imagine how the exemplar’s doing what he’s doing. It’s like yearning for some destination which our directions machine doesn’t know about, without being able to take off the blindfold.

Knowledge can help us plan a path from point A to point B—from the admirer to the role model. But the directions machine’s step-counting knowledge is too narrow to plan a path to somewhere new. For that, you’ll need a broader view—a map. When I catch myself spouting intimidated praise, I take off my blindfold, start exploring the surrounding neighborhoods, draw a map, work my way back home.

For much of my life, though, I couldn’t lift that veil; and worse, I didn’t realize there was anything to lift. I mistook the step-counting directions I was learning for understanding. I thought how was as good as why. Then those memorized facts and procedures became false knowledge, their presence more harmful than nothing at all.

The idea of acquiring knowledge a different way had never even occurred to me: after all, everyone around me seemed to be getting their directions the same way. I’d never seen anyone else take off their blindfold—how would I even go about it? Who would give me directions to make my own directions? How can I know what I know?

Sometimes this brand of false knowledge induces more active fear. You’re invited to a meeting at some distant location, but your machine has never heard of it, so you have no idea how to get there. Questions build as the appointed time approaches: you’ve always been able to get where you needed to go using the machine. Is it possible that there are some places the machine doesn’t know about? How many places? Are they important? You think of yourself as a pretty good navigator—so are you, really? Has it all just been luck so far?

This is a scary line of reasoning. Each step amplifies the mounting cognitive dissonance. At this point it’s clear that a different approach to knowledge is necessary, but there’s so much pressure to resolve the dissonance that it’s easiest to actively reject the goals that incited all those painful questions.

The alternative doesn’t look great. It means summoning the humility to admit that your knowledge is far more limited than you’d imagined. You need to figure out the whys behind the hows you’ve been using, so that you can make some new hows. For a while, since you’re drawing the map (and figuring out that you need a map, then what a map is), you’ll need much more time to get anywhere. The easy conclusion: maybe you don’t need to go to that meeting after all; maybe only “really smart” people understand math proofs; maybe you’ll “let the experts” take care of that tough problem that came up.

Now the situation is much worse than the impotent haze of simple intimidation. The pressure from cognitive dissonance caused active rejection of the path to real understanding.

I’ve seen an even more dangerous hazard emerge when this kind of fear builds, especially after many years of success. Sometimes the mounting cognitive dissonance can’t be fully resolved just by avoiding destinations unknown to the directions machine. You might have to persuade others not to visit those places. You might have to convince yourself that the people visiting those places are foolish or harmful, that their machine will surely lead them astray. Now you’re a zealot.

Of course, you can’t see that those renegades aren’t walking around with blindfolds outside. They’re navigating with a map. Each person has drawn his own, and they’ve helped each other fill in the details.

The convictions I’ve described become dangerous when they fester in someone with power. Overwhelming dissonance will pressure the zealot to yoke his power to perpetuate stasis, forcing others to avoid solutions outside that narrow set he can access, twisting problems into ones which can be solved with answers he’s already memorized. Radical thinking is a threat to the zealot’s psychic well-being.

So when this zealot can influence others or controls something that others rely on, those folks are in trouble. New problems will always emerge in any endeavor, and no machine can be programmed with all the solutions up front. Eventually, some problem will appear with no predetermined solution. The zealot will have to muster all his understanding to synthesize a new answer, but he doesn’t understand anything: he’s just memorized a bunch of results.

Software engineering is full of zealots who fiercely perpetuate this kind of stasis: they only know one language, only want to know one language; it’s the best, and all the others are stupid. Steve Yegge writes about the experience of taking off that particular blindfold and learning some of the related whys:

My own story actually started with physics. I spent years memorizing sheets of equations for physics classes without understanding how they were derived, how they were connected, or their significance. I was learning how to compute answers to some common physics problems without understanding any of the whys behind those hows. That’s just how we were taught, and it appeared to be the level at which my teachers understood the material.

I tried to make games with physics-based behaviors and had all the problems you’d expect: I had no idea what to do when confronted with new problems; I was helplessly intimidated by successful game authors; with that fear ever building, I actively rejected the idea of building real understanding, convincing myself that I could get by copying and pasting together code from random internet searches. Thankfully, I wasn’t in a position to put up a real fight for stasis.

In my freshman year at Caltech, one lecture totally reversed my approach to learning about physics. It was the first time I’d taken off the blindfold in any subject. Over the next two years, it led to the painful realization that I had very little real understanding of almost anything else, including computer science—my purported specialty.

The lecture: we’d just finished studying special relativity and electricity. The professor walked in and drew a new line between those two topics. “Suppose we have an electron moving along a wire at relativistic speeds…” He started by writing the familiar equations from electricity and relativity. A few blackboards of algebra later, the equation of a magnetic field just… appeared.

I’d memorized that equation years earlier, but I didn’t know what it meant. I had no idea about the underlying connections between these phenomena. The difference between magnetism and electricity is—literally—a matter of perspective. Something clicked in my brain. That was when I started to open my eyes and ask why.|||

Blinded by "how" Imagine that you’ve just moved to a new city. Whenever you need to go somewhere, you ask a special machine how to get there. But it doesn’t show you a map: it tells you to take twenty...