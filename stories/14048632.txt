Do good managers look for consensus and strive to predict the future? Not according to William Barnett, a professor of business leadership at Stanford Graduate School of Business. “Humans fear being a fool much more than they hope to be a genius,” he said during a recent discussion at the business school. Rather than risk looking foolish, employees may opt to support a consensus view or fear to voice controversial ideas, and that can lead to poor strategic choices for a business, he says.

Barnett says that if people in your organization are afraid that breaking from the consensus is bad for their careers, it’s a sign that you need to rethink your approach.

He shared this and other insights on managing and building successful companies during a Stanford GSB Faculty Lecture on Oct. 24. His main points:

Geniuses make mistakes. Einstein’s work, for example, contained arithmetic errors; Bob Dylan doesn’t always hit the right note, argues Barnett. But their genius is recognized. It’s easy to overlook genius when an idea seems outside the norm. “In the search for genius, if you want genius, look for systems that create foolishness,” he says.

By foolishness, Barnett really means ideas that fall out of the consensus view. If a company only approves ideas that are within the norm, it is likely missing the unconventional but potentially groundbreaking ideas, Barnett says.

“If you find a system that’s creating foolishness, there might be a chance of genius,” he says. “If you’re finding a system that never does anything foolish, there’s no way you get genius.”

Likewise, when it comes to a competition between business plans, avoid the consensus pick, Barnett says. “What I want to see in a business plan competition is the plan that generates the biggest argument.” For example, when Irwin Jacobs founded Qualcomm, a maker of chips for mobile applications, no one thought that the chips could be based on a controversial technology called CDMA (or Code Division Multiple Access). It was a non-consensus idea and a controversial business plan. But it succeeded, and now CDMA is one of the major radio systems used in cellphones.

Apple’s Steve Jobs presented this now famous injunction to Stanford students when he spoke at the university’s graduation ceremony in 2005. Barnett echoed this message in his talk: “Great leaders are people who understand that it is not their job to know the future. It is their job to create a system that discovers that future.”

Trying to connect the dots (or game out all the possible outcomes of an action) is a recipe for paralysis, Barnett says.

Look to Jobs’ own company for an example. In 2001, Apple Computer introduced iTunes. At the time, Apple considered itself a computer maker and iTunes was merely a device to boost hardware sales. But when music downloads skyrocketed, Jobs realized he could change the company’s direction by making iTunes a Windows application. Within two months, there were an additional 15 million downloads, and later Apple dropped “computer” from its name.

If Apple executives had connected dots forward to continue to focus on selling computers, they would have missed this major opportunity, Barnett says.

Managing for variance, which means allowing change and acting unpredictably, is often a good strategy. Clearly it was for Apple. Singapore, on the other hand, stifled variance when it tried to encourage it. In the 1990s, the country encouraged street musicians to generate a Greenwich Village-like atmosphere but insisted they dress neatly and sing government-approved songs. Not surprisingly, the effort failed. “You see what happens when we try to control the innovation process. We think we’re pushing up the mean. What we’re doing is we’re pushing down the variance,” Barnett says.

Of course, managing for variance is not appropriate in every environment, Barnett says. “The person who flies my airplane? I want them to take off and land the exact same way every time.”

Pivoting, or moving in a sharply different direction from an early strategy, is all the rage these days, says Barnett. “[Young people] all say the word ‘pivot’ all the time. So the recipe is that you try something, it doesn’t work, you pivot, and you’re rich,” he jokes. But handled incorrectly, a pivot can be a major mistake. “You do want to pivot if the very logic that you think is true here is failing its test. But if all you’re doing is just looking at a result without thinking through the logic of the business, you want to think again before you pivot,” Barnett says.

Testing a strategy with data can result in actionable information. But it also could lead to a false positive or a false negative. “False positives are self-correcting. False negatives are not. If I get a false negative, I’ll pivot. And I won’t realize I was right. A false positive, I’m going to do it again,” Barnett says. If, for example, the early feedback on Qualcomm’s use of CDMA technology had incorrectly indicated that it would not succeed and Irwin accepted that false negative, he might well have adopted another, less successful strategy. And he would never have learned that basing Qualcomm technology on the CDMA standard was correct.|||

Kill consensus and beware the false negative, says one Stanford GSB professor.