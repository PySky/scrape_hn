From supercomputers to IoT – processors (or chips) are everywhere. Computer chips protecting our privacy and security would first travel the world to get designed, fabricated, and personalized. Even if we had an unbreakable encryption algorithm, it may be defeated by its manufacturing. Let’s exploit superpowers and their influence to create a practical, unbreakable encryption.

George Danezis (a professor of security and privacy at UCL)and his Ph.D. student Vasilios Mavroudis have reached out to me (and Enigma Bridge) with a project proposition last summer. They have designed a set of multi-party signing and encryption protocols and wondered if they could be verified on commercial hardware. We had the hardware, so I said: “let’s do it”.

There is one unbreakable encryption – one-time pad. While theoretically unbreakable, it was practically broken many times. What about a practically unbreakable encryption system? Maybe we should start thinking that any encryption, even ones unbreakable in theory can be broken. We can still be in luck.

All implementations of encryption are defective, weak, can be broken or bypassed. This includes threats on the silicon level - undocumented or malicious functionality in chip designs leaking all secret. There were several publicly documented cases where hardware chips contained functionality classified as a backdoor or a trojan horse: Breakthrough silicon scanning discovers backdoor in a military chip; Photos of an NSA “upgrade” factory show Cisco router getting implant, or Hardware Trojans in Wireless Cryptographic ICs.

But we don't have to go that far - all Intel vPro processors had a remote execution vulnerability for the last 10 years! (I like the exploit name "Silent Bob Is Silent".)

Detection techniques help prevent the introduction of these “bugs” but they can hardly be effective against malicious attackers as their introduction into manufacturing processes takes time. While attackers can quickly bypass any such mechanisms.

We assume, there are hardware bugs and backdoors, and trojans. We combine mathematics (theoretically secure encryption) with engineering (robust implementation of equations).

We built a high-assurance hardware from these untrusted components. The attacker needs to break all hardware components and get hold of all compromised secrets. We are safe otherwise.

This diversification of the components reduces the probability of all of them being compromised by the same attacker. This assumption can be strengthened by putting each component under the control of a different adversary. Locations are selected across boundaries of political superpowers (Russia, USA, India, China, Brazil).

To achieve that, we deploy distributed cryptographic schemes on top of an N-variant system architecture, and build a trusted platform that supports a wide range of commonly used cryptographic operations (e.g., random number and key generation, decryption, signing).

The next step was to build the protocol and show that it is practical. That it works and also it scales nicely with an increasing number of cooperating parties – i.e., with increasing number of processors needed to sign (or encrypt or decrypt) documents. These results are on the right. As you can see, the increase in the time needed for a single signature is linear with small increases. (and Petr still has up his sleeve a trick significantly reducing the processing times).

When you think about it, it takes just above 2 seconds to sign a document where 10 parties (laptops, secure processors, cloudHSM, mobile phones, etc.) have to do their bit.

I should also note that while I focus on signing, distributed decryption is much quicker!

Digital signing is used in a number of applications – from code-signing to legally binding signing of legal documents (especially in the EU - eIDAS) or bitcoin operations and blockchain (each block-chain update is technically a digital signature).

We are really excited about the potential for code-signing, i.e., to verify the origin of software. This is a mandatory technique for all mobile phone apps, but it is also important for secure distribution of packages for servers and desktop computers.

The simplest implementation would involve just two parties:

The developer controls the signing process and requests the cloud service to contribute its part of the computation. The cloud service logs all uses of its secure processors (smartcards with physical security), and provides these logs to managers, who are responsible for correct use of code-signing keys. The cloud service can also be used to introduce “release time-windows”, remove developer’s rights to sign new software versions, if his/her laptop is stolen, taken over by malware or similar situations.

QED: practical and unbreakable encryption. Well, as long as the price of Russians selling exploits to US or Brazil is high enough. We should be fine so long as there are believers in idealogy :)|||

