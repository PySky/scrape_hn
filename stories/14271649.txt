One of the most common questions we hear at Symphonia when discussing Serverless is ‘what about vendor lock-in’ ? Unpacking this question, the concern is that while we may currently be making use of one cloud provider, will there be a significant cost, either in terms of time or money, in switching to a different provider in the future?

The summary of my opinion is that while there are some risks here, the benefits of fully utilizing the features of one cloud vendor are significant, and in most cases you’ll want to focus on one cloud rather than considering multi-cloud as your guiding strategy.

A longer opinion is as follows.

Because of the concern around vendor lock-in people sometimes take one of the following strategies:

Are these strategies useful?

Overall my opinion of (1) is that while there is some amount of vendor lock-in with Serverless, there’s no big difference here compared with other aspects of higher level cloud services. In fact with Serverless FaaS / Serverless Compute you may see very little vendor specific code in your functions at all, if any.

Your choice of whether to use Serverless, at least with regards to lock-in, should be aligned with your general cloud strategy.

In other words if you’re already using some non trivial cloud services you shouldn’t have any significant concerns with Serverless services, assuming technically they do what you need.

As to question (2) I have to say I find this an odd position to take in most situations. Typically what people do here is one of two things. Either they use some more fundamental cloud services, such as basic EC2 and S3, and then run their own higher level services on top of this, e.g. managing their own deployments of database servers, message busses, etc. Alternatively they only use features of a higher level service that are universally available elsewhere.

The problem with the first of these — building or operating your own higher level services — is that this implicitly comes with higher initial and ongoing cost. If your product teams are the ones implementing any of these services you are also paying opportunity costs.

A problem with the second approach — only use universally available features — is that you can often end up designing to the lowest common denominator of what is available across providers. A point to remember here is that while there is some amount of utility in certain basic cloud infrastructure services there are still considerable differences for higher order services. So designing merely to what is common across platforms means missing out on significant cost, time and functional opportunities.

While as engineers we often like to optimize and control as much of our overall system as possible, as architects of business systems our decisions often need to be as much economic as they are technical. Using strategy #2 from my original list you are effectively buying an option for the hope of cheaper migration down the road. But this is a mighty expensive option, and the value of it is far from certain — will AWS (for example) be something you really desperately want to move from before your system comes to the end of its life? And even if you do, how much cheaper will the migration really be?

Before I close out I want to mention 2 other points.

First of all the question of vendor lock-in can sometimes be merged with disaster recovery (DR). Some people may say ‘we should build a cloud agnostic system so that we don’t have vendor lock-in, and so that we can run redundant deployments across multiple clouds’. These 2 drivers are vastly different and care should be taken before linking them together. For instance a single-cloud / multi-region approach to cloud deployment is almost certainly going to be easier and cheaper than a multi-cloud approach. Apart from the technical differences you’ll obviously need to implement, exercising your DR strategy will become even more important, and probably more costly to do. Are you really sure that single-cloud / multi-region is insufficient for your DR needs? It’s sufficient for Netflix, and they’re not exactly a trivial use case.

Finally in some situations it is useful to use multiple clouds — but this is when you explicitly want to use functionality from one cloud that isn’t available from another. For instance you may have a lot of your operational systems deployed to AWS, but you see significant value from using some of Google’s data products in comparison to Amazon’s. This consideration is absolutely reasonable if there really is a big enough difference that you want to exploit between 2 products.

So, in summary, ‘multi-cloud’ is now a phrase that is getting used by some as a ‘best practice’ to avoid vendor lock-in, or to implement disaster recovery. I would urge you to not think this way by default, at least if you’re using a major cloud provider, and instead to embrace the rich functionality, and the multiple regions, of your vendor, to the maximum extent.

Note — there are at least a couple of recent articles on this subject, including this one by Paul Johnston. My article was drafted before having read those, but I recommend you seek multiple opinions before making such important decisions.|||

One of the most common questions we hear at Symphonia when discussing Serverless is ‘what about vendor lock-in’ ? Unpacking this question, the concern is that while we may currently be making use of…