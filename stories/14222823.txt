This week at RailsConf, we found ourselves sharing a lot of tips for using PostgreSQL with Rails. We thought it might be worthwhile to write up many of these and share more broadly. Here you’ll find some tips that will help you in debugging and improving performance of your database from your Rails app.

Second, for anyone in the Rails community wasn’t at RailsConf in Phoenix but still wants some swag, we’d love to send you some. Sign up for our newsletter at the bottom of this post and we’ll follow up to get your address and mail you some Citus socks.

And now, on to the code.

Long running queries can have all sorts of negative impact on your database. Whether running for hours or even several seconds they can hold locks, queue up WAL, or just consume a lot of system resources. Postgres makes it easier to have a bit more safety around this with a default statement timeout. What’s nice is you can set a default such as 5 seconds shown here, any query that then runs longer than 5 seconds will be killed:

Should you need a query to run longer within the database session you can set a custom statement timeout just valid for the current connection:

Rails abstracts away a lot of things when interacting with your database. That can be both a good and a bad. Postgres can show you long running queries, but as your Rails app grows that doesn’t by itself give you everything you need to solve the problem. To know where the query originated from there’s one particularly handy gem marginalia which will log exactly where your query came from. Now when you see some query that is wrong, or running too slow, or could just be removed you know exactly where to go in your code to fix it:

Often you need a high-level picture of what is currently going on in your database. is a Postgres extension that comes pre-installed in cloud environments like Citus Cloud, and allows you to see which queries have been running since the last statistics reset, and how they were performing.

For example, to see the 10 most time consuming queries, and their average time, do the following:

If you enable “track_io_timing” on your Postgres database, this also allows you to see whether you are bottlenecked on CPU or I/O performance. You can read more on pg_stat_statements here

By default Rails uses a file called to store a copy of the database schema, typically used to initialize the database before running tests. Unfortunately, many advanced Postgres features, like functional and partial indices, as well as multi-column primary keys, can’t be represented in the DSL used for that file.

Instead, it makes sense to switch to having Rails generate and use the “db/structure.sql” file, which you can do like this:

Under the hood this uses Postgres’ pg_dump format, which can be a bit verbose at times, but ensures you get the complete database structure restored. If you find yourself running into issues with overly long diffs, you might want to take a look at activerecord-clean-db-structure.

Rails likes to put everything in a transaction, especially when using before_save hooks and multi-level relationships between models. There is one important caveat to watch out for with transactions, which can bite you as you scale out. In a transaction like the following:

The first UPDATE statement will start holding a row-level lock on the row with id as soon as you issue it, until the COMMIT happens.

Imagine another request for the same organization coming in (e.g. from a different user), making a similar transaction. Typically that other request will have to wait for the transaction to commit, in order to be able to proceed, slowing down the response time. To fix this, it often helps to rearrange the transaction so UPDATEs happen towards the end, as well as consider pulling out changes to timestamp fields to happen outside of the transaction, after the main work has been done.

In order to find problems like this earlier, you can set “log_lock_waits = on” in PostgreSQL.

Rails by default maintains a pool of connections to your database. When a new request comes in it will take one of the connections from the pool and give it to your application. As you scale your Rails app this can result in hundreds of open connections to your database, though in reality only a portion of them are doing work. The key here is to use a connection pooler like pgBouncer to reduce the active connections to your database. A connection pooler will open up connections when transactions are active as opposed to passing on the idle ones that aren’t doing any work.

We hope you found these tips for managing your Postgres database with Rails useful. If we missed any handy tips, just let us know @citusdata.

And if you’re interested in staying informed about other similar posts, leave your email below to sign-up for our monthly newsletter. No spam, just good content.

Thanks for signing up.|||

Citus Data makes sharding simple, to bring horizontal scale to Postgres databases everywhere.