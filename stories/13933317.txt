RabbitMQ provides, among other features, clustering capabilities. Using clustering, a group of properly configured hosts will behave the same as a single broker instance.

All the nodes of a RabbitMQ cluster share the definition of vhosts, users, and exchanges but not queues. By default they physically reside on the node where they have been created, however as from version 3.6.1, the queue node owneriship can be configured using Queue Master Location policies. Queues are globally defined and reachable, by establishing a connection to any node of the cluster.

Modern architectures often involve container based ways of scaling such as Docker . In this post we will see how to create a dynamic scaling RabbitMQ cluster using CoreOS and Docker:

We will take you on a step by step journey from zero to the cluster.

We are going to use different technologies, although we will not get into the details of all of them. For instance it is not required to have a deep CoreOS/Docker knowledge for the purpose of executing this test.

It can be executed using your pc, and what you need is:

What we will do:

First we have to configure the CoreOS cluster:

2. Use the user-data example file:

4. Open the file then uncomment and change it to 3, or execute:

7. Use vagrant to login, ex:

8. Test your CoreOS cluster, login to the machine core-01:

As result you should have:

13. (Optional step) Run the first image with docker run :

The CoreOS the cluster is ready, and we are able to run Docker inside CoreOS. Let’s test our first RabbitMQ docker instance:

15. Check your vagrant IP (used to access the machine) :

Go to in this case: http://172.17.8.101:15672/#/.

You should see the RabbitMQ management UI as ( ):

In order to scale up the node above, we should run another container with parameter and execute . In order to scale down we should stop the second container and execute .

Turn into more positive. e.g. This is one of the areas where further enhancements on automation would be helpful.

We need docker orchestration to configure and manage the docker cluster. Among the available orchestration tools, we have chosen Docker swarm.

Before going ahead we should remove all the running containers:

Docker Swarm is the native clustering mechanism for Docker. We need to initialize one node and join the other nodes, as:

automatically generates the command (with the token) to join other nodes to the cluster, as:

Docker swarm cluster is is composed by leader node and worker nodes.

2. Join the core-02 to the cluster (you can copy and paste the command generated to the step 1) :

3. Join the core-03 to the cluster :

There are different ways to create a RabbitMQ cluster:

To create the cluster we use the rabbitmq-autocluster plugin since it supports different services discovery such as Consul, etcd2, DNS, AWS EC2 tags or AWS Autoscaling Groups.

We decided to use etcd2, this is why we tested it on Configure CoreOS cluster machines see step 8.

The swarm makes the overlay network available only to nodes in the swarm that require it for a service

Note: The first time you have to wait a few seconds.

4. You can check the RabbitMQ instance running on most likely http://172.17.8.101:15672/#/

5. Scale your cluster, using as:

Since the 3 CoreOS machine are in cluster, you can use all the 3 machines to access the cluster, as:

6. Check the cluster status on the machine:

Same to the other nodes, you have more or less the same number of containers.

Let’s see now in detail the parameters:

Next are the auto-cluster parameters:

to true removes the node automatically, if is false you need to remove the node manually.

Scaling down and can be very dangerous, if there are not HA policies all the queues and messages stored to the node will be lost. To enable HA policy you can use the command line or the HTTP API, in this case the easier way is the HTTP API, as:

Note: Enabling the mirror queues across all the nodes could impact the performance, especially when the number of the nodes is undefined. Using we enable the mirror only for 3 nodes. So scaling down should be done for one node at time, in this way RabbitMQ can move the mirroring to other nodes.

RabbitMQ can easily scale inside Docker, each RabbitMQ node has its own files and does not need to share anything through the file system. It fits perfectly with containers.

Scaling RabbitMQ on Docker and CoreOS is very easy and powerful, we are testing and implementing the same environment using different orchestration tools and service discovery tools as kubernetes, consul etc, by the way we consider this architecture as experimental.

Here you can see the final result:

Erlang Solutions is the world leader in RabbitMQ consultancy, development, and support.

We can help you design, set up, operate and optimise a system with RabbitMQ. Got a system with more than the typical requirements? We also offer RabbitMQ customisation and bespoke support.

Learn more about our work with RabbitMQ >|||

Our blog on scaling RabbitMQ on a CoreOS cluster through Docker. Read more!