Last week we launched TimescaleDB in beta with our first blog post, and then posted it to Hacker News.

Since then, our HN post received over 300 points with 130+ comments, our blog post was viewed over 20,000 times, and our project surpassed 1,000 stars on GitHub. (What a week!)

Our HN post also generated a lot of great comments (some positive, some negative, but all equally valuable). In particular, there are 6 themes we noticed that we’d like to discuss in detail.

But first, a big thank you to the HN community! We could not have reached these milestones without your support.

And this is just the beginning. In the coming weeks, we plan to: describe our architecture, design decisions, and motivation in detail; release new optimizations and features; publish (and open source) more benchmarks; integrate with important 3rd party tools (e.g., Grafana); and more. Your feedback and support will be invaluable as we continue to improve and grow.

Here are 6 insights from our HN post comments:

Looking back on these last several days, the biggest thing that stood out was the healthy nature of the discussion. People are very passionate about databases and have deeply held beliefs, some of which are challenged by TimescaleDB.

Here is one question that was on a lot of people’s minds: Really, a row-based store for time-series data?

While column-oriented datastores are good for some types of queries (e.g., key-value lookups, rollups on a single field), they are quite limiting or inefficient when it comes to more complex queries (e.g., complex predicates involving multiple columns). It’s for this query power that we are betting on PostgreSQL.

We also believe that having access to a full SQL interface is also powerful. This response to endymi0n’s comment captures that sentiment:

That said, one reason why NoSQL databases are popular is that not everyone likes SQL:

Although we believe SQL is a very rich language for time-series data, we do recognize that SQL is not for everyone (e.g., the popularity of PromQL). That said, SQL is quite powerful, and a lot of developers are familiar with it:

In fact, being able to apply SQL on time-series data may also force you to rethink how to most efficiently store your data, e.g., to take advantage of features like JOINs:

Benchmarks are the double-edged sword of database evaluation. On the one hand, with so many database options out there, benchmarks provide a degree of objective comparison. Yet, as we have all seen, benchmarks can be cherry-picked and tuned in a way that doesn’t tell the whole story (similar to the complaint about statistics in general).

We agree that cherry-picked benchmarks are a bit of a pox on our industry (and have ourselves experienced the annoyance of not being able to reproduce previously-touted performance). We are doing our best to be transparent with benchmarks, and will soon publish broader results that hopefully cast our database in an honest light (e.g., won’t always present TimescaleDB in a positive way). We also expect those results to clarify how the tradeoffs between row- and column-oriented stores are more complex and nuanced than many think (i.e., your data model and query workloads matter a lot).

Evaluating and comparing database systems is also a lot more than just comparing benchmark numbers. For example, PostgreSQL has many features (e.g., complex data types, geospatial support via PostGIS) that many NoSQL databases don’t even support. Operational management (including backups, disaster recovery, etc.) is also something that benchmarks don’t capture. On the other hand, PostgreSQL is worse on data compression and any fair evaluation must consider that as well. Our goal going forward will be to provide more holistic system evaluations to the broader community (which also lets us scratch our scientific itch).

Stay tuned for more benchmarks and evaluations soon.

One of the biggest things we took away from attending PGConf a couple weeks ago was the vibrancy of the community. While PostgreSQL has been around for 20+ years, the project is still quite active and feels to be “coming of age” (with version 10 slated for release later this year). As Amazon announced at the same conference, the top 3 fastest growing AWS products are all PostgreSQL related: Redshift, RDS, and Aurora.

Members of the PostgreSQL community are also quite helpful to each other. When some asked about other PostgreSQL extensions/features, other members of the community were kind enough to jump in (e.g., this very detailed response from ozgune, CTO of Citus Data, or this suggestion from X86BSD on ZFS as a compression option).

In fact, quite a few people are already trying to store time-series data in PostgreSQL:

For many use cases, it is convenient to just throw some data at your time-series database without jumping through hoops to define and manage schemas. This sentiment was captured well in the following comment:

We recognize these concerns. That said, most databases (including many that claim to be “schema-less”) actually have some type of schema internally. Columns often cannot mix datatypes, e.g., integers cannot suddenly store string values. Basic datatypes are necessary for good reasons, such as being able to perform aggregations on integers or define predicates on labels. For similar reasons, a database needs some structure to ingest data for computations, e.g., the average CPU usage across a cluster of servers.

What the comment is really saying (as we see it) is that the schema should be implicit from the structure of the ingested data, and that the schema should be able to expand to accommodate additional columns in the future. In other words, sometimes you just want to throw time-series data into a store without worrying about managing the schema.

Even though we already support semi-structured data through PostgreSQL’s native JSON and JSONB datatypes, we plan to explore HTTP interfaces that will give the option to auto-define and auto-manage a structured schema.

This one we’ve heard many times before, and saw again on our HN post:

In the abstract, we agree with the author: most of the time, there’s no need to reinvent the wheel. (And this is part of the reason why we choose to engineer up from PostgreSQL, as opposed to building an entirely new DBMS from scratch).

We also believe that database teams like ours should focus on improving the database-state-of-the-art so that product teams like his can focus on the product.

Questioning and rethinking the status quo is how innovation happens, especially within the database industry. Cassandra, PostgreSQL (and every other successful database) was developed by engineers questioning their status quo.

You can’t make everyone happy, even when it comes to writing style. Try these two opposing comments:

In fact, both of our founders have very different writing styles themselves (and they first started writing papers together nearly 20 years ago).

For those who liked the writing, don’t worry, there will be more posts in that style.

And for those who wanted something “less hipster”: don’t worry, we’ll have articles like that as well. Including a technical post that our part-CTO / part-Professor Mike Freedman is already working on (coming soon!).

Before we sign off, we’d like to take this moment to gather even more feedback:

As always, we greatly appreciate feedback: hello@timescale.com.|||

Last week we launched TimescaleDB in beta with our first blog post, and then posted it to Hacker News. Since then, our HN post received over 300 points with 130+ comments, our blog post was viewed…