The python serverless microframework for AWS allows you to quickly create and deploy applications that use Amazon API Gateway and AWS Lambda. It provides:

Up and running in less than 30 seconds.

This project is published as a preview project. Until the 1.0 GA release, we may introduce backwards incompatible changes based on customer feedback we receive. As a best practice, we do not recommend launching production APIs until 1.0 GA because of potential backward incompatible releases. Please see the CHANGELOG.rst file to see the changes for each release.

Give this project a try and share your feedback with us here on Github.

The documentation is available on readthedocs.

In this tutorial, you'll use the command line utility to create and deploy a basic REST API. First, you'll need to install . Using a virtualenv is recommended:

Note: make sure you are using python2.7 or python3.6. The CLI as well as the python package will support the versions of python supported by AWS Lambda. Currently, AWS Lambda supports python2.7 and python3.6, so that's what this project supports. You can ensure you're creating a virtualenv with python3.6 by running:

Next, in your virtualenv, install :

You can verify you have chalice installed by running:

Before you can deploy an application, be sure you have credentials configured. If you have previously configured your machine to run boto3 (the AWS SDK for Python) or the AWS CLI then you can skip this section.

If this is your first time configuring credentials for AWS you can follow these steps to quickly get started:

If you want more information on all the supported methods for configuring credentials, see the boto3 docs.

The next thing we'll do is use the command to create a new project:

This will create a directory. Cd into this directory. You'll see several files have been created for you:

You can ignore the directory for now, the two main files we'll focus on is and .

Let's take a look at the file:

The command created a sample app that defines a single view, , that when called will return the JSON body .

Let's deploy this app. Make sure you're in the directory and run :

You now have an API up and running using API Gateway and Lambda:

Try making a change to the returned dictionary from the function. You can then redeploy your changes by running .

For the rest of these tutorials, we'll be using instead of (https://github.com/jkbrzt/httpie) to test our API. You can install using , or if you're on Mac, you can run . The Github link has more information on installation instructions. Here's an example of using to request the root resource of the API we just created. Note that the command name is :

Additionally, the API Gateway endpoints will be shortened to for brevity. Be sure to substitute for the actual endpoint that the CLI displays when you deploy your API (it will look something like .

You've now created your first app using .

The next few sections will build on this quickstart section and introduce you to additional features including: URL parameter capturing, error handling, advanced routing, current request metadata, and automatic policy generation.

Now we're going to make a few changes to our file that demonstrate additional capabilities provided by the python serverless microframework for AWS.

Our application so far has a single view that allows you to make an HTTP GET request to . Now let's suppose we want to capture parts of the URI:

In the example above, we've now added a view that allows a user to specify a city name. The view function takes the city name and returns name of the state the city is in. Notice that the decorator has a URL pattern of . This means that the value of is captured and passed to the view function. You can also see that the takes a single argument. This argument is the name of the city provided by the user. For example:

Now that we've updated our file with this new view function, let's redeploy our application. You can run from the directory and it will deploy your application:

Let's try it out. Note the examples below use the command from the package. You can install this using :

Notice what happens if we try to request a city that's not in our map:

In the next section, we'll see how to fix this and provide better error messages.

In the example above, you'll notice that when our app raised an uncaught exception, a 500 internal server error was returned.

In this section, we're going to show how you can debug and improve these error messages.

The first thing we're going to look at is how we can debug this issue. By default, debugging is turned off, but you can enable debugging to get more information:

The enables debugging for your app. Save this file and redeploy your changes:

Now, when you request the same URL that returned an internal server error, you'll get back the original stack trace:

We can see that the error is caused from an uncaught resulting from trying to access the key.

Now that we know the error, we can fix our code. What we'd like to do is catch this exception and instead return a more helpful error message to the user. Here's the updated code:

Save and deploy these changes:

We can see now that we have received a and key, with the message being the value we passed to . Whenever you raise a from your view function, the framework will return an HTTP status code of 400 along with a JSON body with a and . There are a few additional exceptions you can raise from your python code:

You can import these directly from the package:

So far, our examples have only allowed GET requests. It's actually possible to support additional HTTP methods. Here's an example of a view function that supports PUT:

We can test this method using the command:

Note that the kwarg accepts a list of methods. Your view function will be called when any of the HTTP methods you specify are used for the specified resource. For example:

The above view function will be called when either an HTTP POST or PUT is sent to . In the next section we'll go over how you can introspect the given request in order to differentiate between various HTTP methods.

In the examples above, you saw how to create a view function that supports an HTTP PUT request as well as a view function that supports both POST and PUT via the same view function. However, there's more information we might need about a given request:

All of this and more is handled by the current request object that the library makes available to each view function when it's called.

Let's see an example of this. Suppose we want to create a view function that allowed you to PUT data to an object and retrieve that data via a corresponding GET. We could accomplish that with the following view function:

Save this in your file and rerun . Now, you can make a PUT request to with a request body, and retrieve the value of that body by making a subsequent request to the same resource. Here's an example of its usage:

You might see a problem with storing the objects in a module level variable. We address this in the next section.

The object also has the following properties.

Don't worry about the and for now. We haven't discussed those concepts yet. The object also has a method, which returns all the information about the current request as a dictionary. Let's use this method to write a view function that returns everything it knows about the request:

Save this to your file and redeploy with . Here's an example of hitting the URL. Note how we're sending a query string as well as a custom header:

The default behavior of a view function supports a request body of . When a request is made with a of , the attribute is automatically set for you. This value is the parsed JSON body.

You can also configure a view function to support other content types. You can do this by specifying the paramter value to your function. This parameter is a list of acceptable content types. Here's an example of this feature:

There's a few things worth noting in this view function. First, we've specified that we only accept the content type. If we try to send a request with , we'll now get a response:

If we use the argument, we can see the expected behavior of this view function because sets the header to :

The second thing worth noting is that is only available for the application/json content type. In our example above, we used to access the raw body bytes:

is set to whenever the is not . This means that you will need to use and parse the request body as needed.

The return value from a chalice view function is serialized as JSON as the response body returned back to the caller. This makes it easy to create rest APIs that return JSON resonse bodies.

Chalice allows you to control this behavior by returning an instance of a chalice specific class. This behavior allows you to:

Here's an example of this:

This will result in a plain text response body:

You can specify whether a view supports CORS by adding the parameter to your call. By default this value is false:

Settings has similar behavior to enabling CORS using the AWS Console. This includes:

The preflight request will return a response that includes:

If more fine grained control of the CORS headers is desired, set the parameter to an instance of instead of . The object can be imported from from the package it's constructor takes the following keyword arguments that map to CORS headers:

There's a couple of things to keep in mind when enabling cors for a view:

The last point will change in the future. See this issue for more information.

In the previous section we created a basic rest API that allowed you to store JSON objects by sending the JSON in the body of an HTTP PUT request to . You could then retrieve objects by sending a GET request to .

However, there's a problem with the code we wrote:

We're storing the key value pairs in a module level variable. We can't rely on local storage like this persisting across requests.

A better solution would be to store this information in Amazon S3. To do this, we're going to use boto3, the AWS SDK for Python. First, install boto3:

Next, add to your requirements.txt file:

The requirements.txt file should be in the same directory that contains your file. Next, let's update our view code to use boto3:

Make sure to change with the name of an S3 bucket you own. Redeploy your changes with . Now, whenever we make a request to , the data send will be stored in S3. Any subsequent requests will retrieve this data from S3.

IAM permissions can be auto generated, provided manually or can be pre-created and explicitly configured. To use a pre-configured IAM role ARN for chalice, add these two keys to your chalice configuration. Setting manage_iam_role to false tells Chalice to not attempt to generate policies and create IAM role.

Whenever your application is deployed using , the auto generated policy is written to disk at . When you run the command, you can also specify the option. Doing so will result in the CLI loading the file and using that file as the policy for the IAM role. You can manually edit this file and specify if you'd like to have full control over what IAM policy to associate with the IAM role.

You can also run the command from your project directory to print the auto generated policy to stdout. You can then use this as a starting point for your policy.

The automatic policy generation is still in the early stages, it should be considered experimental. You can always disable policy generation with for complete control.

Additionally, you will be prompted for confirmation whenever the auto policy generator detects actions that it would like to add or remove:

AWS API Gateway routes can be authenticated in multiple ways:

Only requests sent with a valid X-Api-Key header will be accepted.

To integrate with cognito user pools, you can use the object:

Note, earlier versions of chalice also have an method as well as an argument on the method. This approach is deprecated in favor of and the argument in the method. will be removed in future versions of chalice.

To integrate with custom authorizers, you can use the method on the object. You'll need to set the to the URI of your lambda function.

As you develop your application, you may want to experiment locally before deploying your changes. You can use to spin up a local HTTP server you can use for testing.

For example, if we have the following file:

We can run to test this API locally:

We can override the port using:

We can now test our API using :

The command does not assume the role associated with your lambda function, so you'll need to use an that has sufficient permissions to your AWS resources used in your .

You can use the command to delete your app. Similar to the command, you can specify which chalice stage to delete. By default it will delete the stage:

We'also love to hear from you. Please create any Github issues for additional features you'd like to see over at https://github.com/awslabs/chalice/issues. You can also chat with us on gitter: https://gitter.im/awslabs/chalice

Q: How does the Python Serverless Microframework for AWS compare to other similar frameworks?

The biggest difference between this framework and others is that the Python Serverless Microframework for AWS is singularly focused on using a familiar, decorator-based API to write python applications that run on Amazon API Gateway and AWS Lambda. You can think of it as Flask/Bottle for serverless APIs. Its goal is to make writing and deploying these types of applications as simple as possible specifically for Python developers.

To achieve this goal, it has to make certain tradeoffs. Python will always remain the only supported language in this framework. Not every feature of API Gateway and Lambda is exposed in the framework. It makes assumptions about how applications will be deployed, and it has restrictions on how an application can be structured. It does not address the creation and lifecycle of other AWS resources your application may need (Amazon S3 buckets, Amazon DynamoDB tables, etc.). The feature set is purposefully small.

Other full-stack frameworks offer a lot more features and configurability than what this framework has and likely will ever have. Those frameworks are excellent choices for applications that need more than what is offered by this microframework. If all you need is to create a simple rest API in Python that runs on Amazon API Gateway and AWS Lambda, consider giving the Python Serverless Microframework for AWS a try.|||

chalice - Python Serverless Microframework for AWS