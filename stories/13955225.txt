1. This typically happens when the compiler has different equivalent choices (for example, should it spill variable or to the stack), and it just chooses the first alternative. The first alternative is found by iterating over some kind of container, and this container may be an associative array using pointer values as the key...

2. For example, x86 CPUs tend to fuse and so that they execute as one instruction.

The first example is meant to illustrate the difference between array subscripts and pointer access with the two functionsandThe first function is generated in a natural waywhile the second function has its loop unrolledThe reason for this difference is that compiling withshould not unroll loops if unrolling increases the code size. But it is hard to estimate the resulting code size, as later optimization passes should be able to take advantage of the unrolling and be able to remove redundant code, so the compiler is using a rather imprecise heuristic. These loops are really close to the threshold (unrolling increases the code size by 4 bytes) and the minor difference between how the loops look when passed to the unroller makes the heuristic estimate that unrollingwill increase the size by one instruction whilewill get the same size after unrolling.This does, however, not illustrate any fundamental difference in the compiler’s understanding of array subscript compared pointer access — any difference in the code could affect a heuristic and have a similar effect (I have worked on compilers that generate different code if you rename variables or even add a comment!).The second example uses the two functionsandto illustrate that it is better to write loops decrementing the iteration variable, as the CPU can do the end of loop check for free asinstead ofThat is true, but the compiler can in many cases transform the loop to change iteration order, so the iteration order in the generated program depend more on what the loop does than how it iterates in the source code.Note that the two functions do not do the same thing —outputs the numbers in increasing order andoutputs them in decreasing order. Modifyingto do the same thing as, by changing the function call tomakes it generate identical code as(as the compiler decides that it is better to iterate using increments in order to eliminate the subtraction) even though the function was written as using decrements.The third example consider pre- vs. post-decrement using the examplesandThe example is meant to illustrate thatis better, as it can get the comparison as a side effect of the subtraction in the same way as the previous examplebut it depends much on the microarchitecture if this is beneficial or not. Many microarchitectures can do compare and branch efficiently,so a compare and a branch are not necessarily slower than branching on the status code from the subtraction. The problem withis that it adds a data dependency — you must do the subtraction before you can evaluate the if-statement. Withyou can evaluate the if-statement and subtraction in parallel, with the result thatneed one extra cycle to execute compared tofor superscalar CPUs having efficient compare and branch.|||

