Pundits will tell you the era of self-driving cars is right around the corner, but a series of iPad paintings by San Diego-based engineer Filip Piękniewski shows that artificial intelligence researchers still have their work cut out for them.

Piękniewski illustrates seven strange scenarios that today's machine learning algorithms would have trouble processing. Some are simple, like an open manhole that's visually similar to a covered one, while others incorporate surrealism or political implication. He tells Creators he started the project, "To remind people that driving is not just about following lanes on the freeway. Bizarre situations such as those depicted happen and need to be dealt with robustly."

For one illustration, Piękniewski wondered how a program designed to keep pedestrians safe might respond to a robbery or a military invasion. In another, he questions how the sign recognition protocols would process an absurdist prankster installing a string of stop signs along a deserted freeway, like artist and good samaritan Richard Ankrom's evil twin. We can already imagine the Black Mirror episode. Piękniewski says solutions to these few examples are possible, but, like James Bridle's tongue-in-cheek Autonomous Trap 001, the point of the series is to raise questions. "These are merely examples of the possible unknown unknowns and therefore specific solutions are not be really scalable or feasible," he says.

What are these guys doing in the middle of nowhere? Are they real soldiers or police? Or are these bad guys? Maybe it is an ambush? The answer may depend on the social/political context. Should the car turn back? Should the car stop?

The stop sign detached from the school bus and is swinging on the wind in opened position. It is clearly a stop sign of the right size and shape but the context (75 mph on a multi-lane freeway) is clearly wrong. What to do??

The spider made his web in a wrong place. Although in this particular example the situation could be salvaged by using input from multiple cameras, it highlights an important point: a device cannot act if one of the sensors is obstructed. Humans easily clean their windshields, use sun shades, move their head when they cannot identify an object. In the extreme case they can get out of the car to inspect the situation directly. A robotic car, though having superior sensors, cannot act on them like humans do and can only rely passively on what those sensors report.

While his parents are involved in the arts and education, Piękniewski says he's the black sheep of the family, studying math and science instead. Nonetheless, his position at the crux of the two worlds yields ripe opportunities for crossover in his research. "There could be interesting artistic byproducts of the machine learning technology I'm working on, much like there were are a few artistic side effects of deep learning, such as the Prisma app, style transfer, etc.," he says. His blog devoted to "bringing AI down to earth," is full of thought experiments like this one.  Unpack more of his ideas here.

This Driverless Concept Motorcycle Is Straight Out of 'The Dark Knight'



Meet the Artist Using Ritual Magic to Trap Self-Driving Cars|||

Will cars ever have the common sense to realize when they're being f*cked with?