From blinking lights, punch cards and paper tapes, through CRTs, the introduction of colour, and the development of LCD panels; display technology has come a long way.

Today we enjoy a range of inexpensive, high resolution monitors able to display a remarkable amount of information and employing a bewildering range of technologies.  This article will identify and explain technological differences between available monitors, and help you weigh your choices to pick the best option for your needs and budget.

Resolution: More pixels means more POTENTIAL detail, but consider your eyes, screen position, and problems displaying older applications.

Size: A large monitor with modest resolution may result in a grainy image.  Consider distance from your eye and resolution.  A smaller screen closer to your eye can be a better option.

Colour Depth: More grades of colour gives smoother colour transitions. 10 and 8 bit panels give better results than 6 bit.  Technical tricks to improve apparent colour depth allow marketing departments to represent 6 bit panels with equivalent colours as native 8 bit.

Colour Gamut: A wider gamut gives more realistic colours. 85% Adobe RGB or NTSC cover a wider range than 100% sRGB.  IPS screens rule here.

Refresh Rates: A 60Hz standard refresh rate is fine for most people. Some benefits for particular applications going higher, especially gaming.  Adaptive refresh rates help a lot when gaming (G-Sync, Freesync)

LED Backlights: Single edge white LEDs can result in brightness variance across a panel. Direct Lit W-LED may offer better blacks and more consistent brightness.

Contrast: Specifications can be misleading. Look at the panel type and inspect the model in person.

Brightness: Maximum brightness is largely irrelevant given panels brightness needs to be reduced in normal use.  Pulse Width Modulation Dimming can occasionally cause issues.

Viewing Angle: Panel type will give you an idea. Hard to quantify image changes at angle in a way relevant to the eye.  Ignore stated angle of view in specs.  Check in person if important.

Response Times: Typical response times fine for most use with any modern panel. Gamers may trade off other characteristics for modest benefits of very low response times, especially with high refresh rate screens.

Input Delay: Gamers should consider the time a signal takes to be displayed. Most panels are fine, but gaming targeted panels can give an edge to top players.

Panel Technology: IPS for premium image quality, TN as a cheap, general use or gaming screen, VA for high contrast. Higher end panels reduce inherent limitations.

Power Consumption: LED backlights are highly efficient. Size and brightness setting is the main determinant of power use.  Little distinction between models.

VESA Mounts: When considering custom mounts, ensure the monitor includes VESA support.

Probably the most important and obvious characteristics of your screen are its physical size, and its resolution.  People often confuse these two specifications, assuming a large screen shows more detail.  That’s not always true.

We have all heard of HD (High Definition) though exactly what it means is not always clear.  High Definition sounds like something you want but without context it’s a meaningless term, typical marketing nonsense; high definition compared to what?

The detail that a modern computer screen is able to provide is defined and limited by how many picture elements (pixels) it is capable of displaying.  In most cases, that’s what we mean by resolution, or definition, though the terms can be a little fuzzy!

Modern screens are made up of an array of tiny, addressable elements, each capable of displaying a specified colour.  The more physical pixels built into a panel, the more detail you can potentially display.  Pixels tend to be square, and if you look closely at a lower resolution monitor, you are able to see the individual dots as a staircase effect at diagonals and curves such as shown below.

The most common resolution today is 1920×1080, which is also called Full High Definition (FHD) and means the screen has 1920 columns of pixels across the panel, and 1080 rows of pixels deep.  All up, it has 1920×1080 = 2,073,600 addressable picture elements and it is wider than high by a ratio of 1920/1080 = 1.777, which is more commonly represented as an aspect ratio of 16:9.  For bigger screens of the same resolution, the dots simply get bigger or further spaced, and cannot technically display any additional detail.  The picture will seem to get grainy as it gets physically bigger.

Monitor technology continues its decade’s long march toward higher resolution panels and is currently transitioning from FHD to 4k resolution, doubling the number of rows and columns to 3840 x 2160.  This practically means that each pixel from a FHD screen is being split into four equal parts, and each part is now addressable and may be set to a different colour, POTENTIALLY showing 4x the detail compared to a FHD screen.

You could reasonably assume that the higher the resolution the better, under all circumstances, but that is not true.  In some circumstances a higher resolution screen offers minimal or no advantage and can in fact can offer some negatives because of the way Windows applications handle higher pixel densities.  It is an important and often misunderstood consideration that we will look at in detail to help you determine the best resolution for your personal needs.

Consider the following marketing material that attempts to show how a 4k screen can display much higher detail than a FHD screen.

The grid shown represents the increased number of addressable pixels on the higher resolution screen (though each square does not represent a pixel, if it did then each square could only be one colour across the square) and the close up of the wolfs face attempts to represent the 4x more detail that can be shown with a 4k image.  That is also not quite right but it does simulate the effect under limited conditions where the advantages will show up best.

Where a 3840×2160 source image is displayed full screen on a 4k display, every single pixel in the picture will map to a discrete pixel on the screen and it will be displayed, hopefully, as the same colour as intended in the picture file at its best possible resolution (more on colour accuracy below).  The same picture cannot be displayed on a FHD screen at the same definition, simply because the picture has more detail (4x more pixels) than the physical pixels available on a FHD screen.  If you want to display this picture using at FHD resolution, the usual method is for the computer to break the source picture up into blocks of 4 pixels, average their colour and convert each block into a single pixel, so producing a down sampled image at 1920×1080 and then displaying that lower resolution picture on the FHD display.  Not good, you have just lost a lot of detail.  Or have you?

Try walking to the other side of the room and read this blog article on your screen.  If you can, your eyes are better than mine (or you live in a closet!).  Do you think you would be able to read it if the text was the same physical size on a 4k screen vrs a FHD screen?  Of course not, the limit is not what the screen can display, but rather the detail that your eyes can capture.

As you move closer to a screen, you can see more detail.  At some point, if your eyes are good enough, you may be able to see the evidence of individual pixels, such as jagged lines on diagonals and then as you get closer you no longer see more detail, just more grain.  When you can start to see that grain in the picture, then splitting those pixels into smaller blocks makes sense and will let you see more detail.

Based on a person with 20/20 eyesight, you are seeing the limits of a 24” FHD screens resolution at about a 1M distance, any closer and it will start to look grainy, any further away and you lose detail.  By comparison, a 24” 4k screen will show the same detail as a FHD screen at 1M, but show progressively more detail as you move it closer till at 44cm it will show its full advantage.  Optometrists suggest a viewing distance or around 50-75cm for most people, so this suggests if you have excellent eyesight and can comfortably focus relatively close, a 4k screen will offer a significant advantage, especially for larger screen sizes.  A 32” 4k screen has an ideal viewing distance, assuming 20/20 vision, of about 61cm.

Consider another example of 4k marketing material, displayed below.

These two images correctly suggest that a 4k panel, represented with the lower image, can show 4x the content on a fixed size screen compared to a FHD resolution screen.  In theory, you will lose no detail in the quadrant of the screen that has been shrunk down as the same number of pixels are still in use, but the apparent resolution may be limited by a combination of your eyes, your capacity to take in the extra information, the resolution of the screen, the size of the screen, and how far away the screen is located.

Have a look at the toolbar on the right side of the images. Let’s assume that it is shown at its native size in the top image, and so we note on a FHD screen it takes up a lot of space.  On the 4k screen, it takes up ¼ as much space and the rest of the bar is visible, and appears to be at a size still easy to read and use, so in his case we see a (simulated) advantage of a higher resolution screen.  This would only apply if the original menu design was set excessively large.  Alternately, consider that the second image is the display and sizing of a program at the physical size as planned by designers where the menu is set to its best for size and function. If that menu was then displayed on a screen that had 4x the resolution, the menu would naturally shrink to ¼ of its previous physical size.  The toolbar will become tiny, hard to see, and hard to click.  To be useful, it would need to scale back up to still take up about the same screen space as it would on the lower resolution screen.

Modern versions of windows have added functions that allow the user interface to scale appropriately and can help solve this problem.  You can manually select scaling in windows 10 from your display settings, and set scaling for high pixels per inch (ppi) screen to more than 100% as shown below.  This will let you adjust the display elements of modern applications to suit high ppi screens, essentially scaling them back up to their design size.

Unfortunately, ppi scaling is not a perfect solution.  Older applications were not built to take into account scaling and there are a range of problems that can result.  The following image shows an issue where scaling works well for a recent build of Notepad, but a similar looking application on the same high ppi screen has failed to scale correctly and appears relatively small and difficult to read and use.

Interface scaling can result in a mish mash of display elements, some which are well proportioned where others may seem too small, too big, or a bit blurry.  The basic rule is that higher the resolution at a given size (high ppi), makes it more likely that you will run into annoying scaling issues.  The problem is improving over time and is not an issue for people using modern applications and the current version of windows.  Don’t be scared off a high ppi panel because of these problems, but they do give a reason not to go overboard on high resolution without other clear benefits, especially if you use a lot of older applications.

Now we have a better understanding of resolution, its worthwhile further considering screen size in the context of resolution.  How big is the screen size of your monitor?  Most people would answer 22”, or maybe 27”, or similar.  Yes, that’s the physical size (measured diagonally) of the panel, but so what?  How does the size impact what you see?

A monitor right in front of your face seems much bigger than the same screen across the room.  The practical size of the screen is better measured by the proportion of your field of view that it takes up – angular size is more important than physical size.  To choose the best physical size you want to take into account the position of the monitor as well as its resolution and other factors as mentioned previously.  On average, the closer you like to position a screen, the smaller it should be, and the higher the ppi.  Consider that the image on a 24” FHD screen looks identical to the picture on a 22” FHD screen after the smaller screen moved forward a few inches so it takes up the same field of view.  In that case, which is best might be determined by your desk space, or perhaps how closely your eyes are comfortable to focus.

Before you go trying to maximise your angle of view, a word of warning.  A screen positioned with a high angle of view can at times be uncomfortable and difficult to use, particularly when rapid motion is involved, such as for gaming.  Your eyes pick up more detail in the centre of your vision and when you rely on your peripheral vision to pick up detail you may find you experience a motion sickness type effect or develop a headache.  You may run into issues where the screen is close and large so that the image is distorted or discoloured when looking toward the edges of the screen (as you are no longer looking directly at a flat panel) and your eyes are being hit with bright screen light for a broader angle.  Personally I prefer a modest angle of view of around 50 degrees, but that’s a figure that’s very dependent on personal preference.  Consider the technical side but go with what is comfortable.

Since picture elements have the same height and width in most screens, then the number of rows and columns of pixels defines not only screen resolution, but also its aspect ratio.

The aspect ratio of a monitor will vary with the proportions of columns vrs rows of pixels.  Older LCDs were closer to a square shape with a 4:3 ratio implemented using resolutions including 1024×768 and 1600×1200.  Some current models have an extreme widescreen aspect with resolutions including 2560×1080, and 3440×1440, or a 21:9 ratio.  A very wide screen aspect ratio may be attractive when displaying appropriate content, such as movies and photos, and some games but may not be a good choice for certain types of work, such as word processing.  For the most part, a monitor with a 16:9 ratio is a good choice.  Don’t get caught up with the marketing hype of ultra wide screens unless you have a very clear purpose in mind (eg two pages side by side, a wide spreadsheet etc).

An ideal representation of colour may not be important for many business applications and games, but will be more important when working with video or photos.  A monitor that can accurately represent the colours in a photo or video will let you appreciate the media in the way the author or camera intended with for example, reds looking red, rather than perhaps brown.

Monitors capable of more accurate colour representation tend to cost more and can have other trade-offs, such as lower contrast and response times, so it can be important to understand these specifications to help chose the more appropriate monitor.

Colour depth refers to how many colours a panel can theoretically produce and the larger the depth, the bigger the range it can potentially provide and the closer each increment of colour can potentially be.  For example, the smooth transition of a blue sky from zenith to horizon may require a very subtle transition which cannot be captured with a low colour depth, resulting in a harsh and granular representation, and often distinct colour bands.

Colour is produced by passing light through three primary coloured subpixels, the combination of three subpixels is what I have been referred to as a “pixel” on a LCD panel.  The colour depth available to each pixel is limited by the combination of incremental changes of light intensity passed through each of these subpixels.  Low colour depth panels are able to provide 6 bits of graduations per subpixel, so (2^6)^3 = 64^3 = 262,144 colours.  8 bit panels by comparison can show (2^8)^3 = 16.7 Million colours and 10 bit (2^10)^3 = 1.07 billion colours.

In order to improve the apparent colour depth of panels, various methods can be used to trick the eye into seeing additional colours.  Spatial or temporal dithering are most commonly used with 6 bit panels and sometimes with 8 bit panels.  This is where you need to be careful with specifications.  Documentation may proclaim 16.7 million colours and you might reasonably assume the panel offers 8 bit, but in fact it may be a 6 bit panel using these tricks to simulate an 8 bit panel.  Now a “trick” that works as well as the original effect is fine, but in my view these tricks do not do the job quite as well as native support and are misleading, so if you want a nice colour depth, look for genuine 8 or 10 bit panels.

The colour gamut of a monitor defines the range of colours that it is capable of displaying and is measured against standards that will be referenced in the monitor’s specifications.  The standards quoted are often chosen by marketing departments to make their product look as good as possible, so it can be handy to understand what they represent and the differences between different colour gamut’s.

There are two fundamentally different ways to define a colour gamut, additive or subtractive.  The method of colour generation by computer monitors and other light emitting screens is additive, where a number of colours are added together to produce a final colour, and is normally referred to as RGB, for the Red, Green, and Blue colours most often used to generate the final colour.  By comparison, reflective media, such as printed media use subtractive colour where a number of base colours are mixed together to remove colour from reflected light, leaving a particular colour to meet the eye, referred to as CMYK for the cyan, magenta, yellow, and black ( K = key colour = black) most commonly used.

A colour space is defined by its colour model (the way colours are represented by tuples of numbers) and its colour gamut (a range of colours that can be accurately represented).  The specifications quoted on a monitor will usually reference either the range of colours with the sRGB, AdobeRGB, or NTSC colour spaces that they can display.  For example, a monitor may indicate it can produce 70% of the NTSC space. Each of these represents a particular range of colours and the specification will define what proportion of the range that the monitor can represent.

The below chart shows the range of colours represented by common standards.  sRGB is the most limited and most common used to measure against consumer electronics as it covers the range that has been practical to target in consumer devices.  Many panels can do better nowadays.  NTSC is a standard developed in 1953 to represent the range of colours than can be perceived by the human eye and is mainly used as a reference.  sRGB covers about 72% of the NTSC gamut.  AdobeRGB is also much wider than sRGB at around 94% of NTSC and is heavily used in the publishing industry.  There are also a number of relatively new, emerging standards such as Adobe Wide Gamut RGB which define a very wide range of colours and are relevant to high end professional panels and high end TV panels.

To give perhaps some idea of the difference support for a wider colour space can make, take a look at https://webkit.org/blog-files/color-gamut/comparison.html or http://furbo.org/color/WideGamut/ and preferably on a high end panel.  Be aware on most screens you might get some appreciation of differences but that does not mean the more accurate image is able to be presented accurately on your particular panel.  It will show you differences, but not necessarily show you the benefits without a matched panel.  Try a range of different average panels and the image may look different on each one.

Modern panels are able to display a much broader depth and range of colours than early model LCD screens and if colour matters at all for you, it is worth a quick look over the related specifications to get the best result within your budget.  It is quite often the case that you can go with a panel that offers better colour depth and range for a comparable price to the first monitor that may catch your eye, or only a few dollars more.  Keep in mind that you can’t normally pick colour range or accuracy by glancing at screens on display.  The pretty picture is not the same as an accurate picture.

While we are on colour gamuts, it is worth mentioning that because of the differences between additive and subtractive methods to generate colour, and the wide range produced using CMYK, images on a screen may appear different when printed.  It is easier to translate the wider AdobeRGB and NTSC gamuts to print than the limited sRGB gamut but even when colours are accurately translated the look of an image in a print and on a screen will be different.  For people working with prints, I suggest monitors that cover better than 90% of NTSC and 95% AdobeRGB.

The below image gives you some idea of the effect you will see when additive produced colour is transferred to subtractive based.

Be aware of a small gotcha when buying a high end monitor and attaching it to older technology.  The type of cable you use to plug in your monitor can matter and can place a dirty filter between your high colour depth source and your matching panel.  A lot of information needs to be sent down the monitor cable to display a picture, and the more frames or colours, the more bandwidth is needed.

Recent standards such as HDMI 2.0 provide more data per second and can handle high colour depth at high resolutions (up to 36 bit colour).  The new HDMI 2.1 goes even further with 16 bits per channel = 48 bit and BT .2020 (represents a massive colour range.  Overkill!  But good.).  You will probably be OK with your existing video card, but if buying a high end monitor, but sure to check so you can get the best out of it.

The rate at which a monitor can update the image on a screen is referred to as the refresh rate.  Modern LCD panels typically operate at a fixed refresh rate of 60Hz, or 60 times per second, though some screens can go much higher with 144Hz now common for high end gaming screens and some panels can vary the refresh rate dynamically (more on why that matters below).

For comparison, movie and TV frame rates are typically 24fps and that’s sufficient to trick the eye into seeing smooth motion for most people and under most circumstances.  The human eye is able to perceive up to about 12 individual images per second and much past that we tend to perceive a series of images as continuous motion.  So that should mean 60Hz is tons for anyone?  Not necessarily.

Something to consider here is that the refresh rate is not necessarily the same as the frame rate.  A screen able to display the images of a 24fps movie at 72Hz might display each image 3 times in sequence.  This matters, depending on the technology in use. Further, consider what happens when the refresh rate is not some multiple of the source, say a 24fps signal but a 40Hz refresh rate?  Issues!

If we could switch out flash cards in front of the eye instantly at a rate of 24 times a second, then each individual frame could be represented to the eye for 1/24th of a second before being instantly replaced by the next.  During the fraction of a second the eye is seeing a fixed and constant image and the limit on our perception is our eyes ability to grab the new information and the brains processing time and we would likely perceive smooth, continuous motion.  There are no gaps between the display of each image and light intensity remains constant so a refresh rate of 24Hz is perfectly fine to represent a 24fps movie.

Unfortunately, computer displays don’t display images for a fixed duration and that introduces some problems for our vision.  It takes time for monitors to draw the next image and that image may take an appreciable amount of time to complete drawing.  What’s more, the light used to present the image may pulse and then be dark for a moment, providing a burst of photons representing the image to find its way and stick on our retina, but immediately after each burst there may be darkness.  If the flashes are slow, below the critical flicker fusion rate, we will notice the flicker.

Older CRT monitors would draw images on the screen from top left to lower right at a rate of 60 times per second as an electron beam moved over their phosphor dots and lit them up for a moment, but leaving essentially no light or picture between passes of the beam.  A 60Hz refresh rate is below the critical flicker fusion rate for many people so they will notice a flicker under those circumstances. The below shows a CRT screen photographed a 1/200th of a second to demonstrate the effect that your eye just barely may notice.

LCD screens use a backlight that’s always on and operates at a very high frequency so largely removing the issue with flicker and are closer to the instant flash card example.  That’s a positive over older technology, but unfortunately the flicker effect is often added back into the equation with many panels by using pulse width modulation to dim the panels on a frequency of around 175Hz.  That’s where the backlight is cycled on and off to trick the eye into seeing a lower brightness level on average.  Some studies have shown flicker effect can be perceived up to 500Hz where the display includes high frequency spatial edges (see further reading).  Monitors that use marketing terms like “Flicker Free Technology” use alternatives to PWM and can be worth looking for to avoid eye strain and headaches.

Note the PWM effect does not map to refresh rate, its more about the backlight and dimming technology.  Even given a practically constant backlight, LCD screen refresh is limited by distribution of the signal and responsiveness of the tiny gates that block part or nearly all of the light from each sub pixel.  If a new frame is sent to the panel every 1000ms/60Hz = 16.6ms and the pixel takes say 20ms to respond then apparent refresh rate will not be as expected.  That’s relates to another spec called response time, more on that below.

Some panels, particularly TV panels, will add processing to your video stream where the refresh rate allows.  For example, if your source is a signal providing 60fps to a screen with a 120Hz refresh rate, rather than displaying each image twice, the screen might display the incoming image once, and then average that frame and the next in order to present an interpolated middle frame that potentially allows a smoother stream of images.  Personally, I prefer to trust my brain to handle the image processing, but for some people this type of effect can provide a more pleasing image.  It’s a technology more commonly used in TV screens rather than PCs (fortunately!).  More advanced image processing can help with motion blur and judder when watching fast paced video and are dependent on high refresh rates.

Picking a monitor with an appropriate refresh rate is surprisingly complex and varies considerably by individual, use, and other aspects of the environment and technology used.  Some of the variables to consider are explained further later in the article and become relevant for particular use, such as gaming.  Be aware not all video cards can handle high refresh rate monitors at their native resolution, so if you go that way be sure to check your GPUs specifications.

A LCD panel works by positioning a matrix of sub-pixels backed with a (mainly) constant source of light.  The nature of the light and positioning has an impact on various parameters such as colour depth, brightness, and contrast, and consistency of those factors across the panel.

Edge W-LED Backlights use white LEDs placed in a line along the edge of a LCD with diffusers attempting to provide uniform brightness across the screen.  They are cheap and work well for most panels.  They can be arrayed across up to four sides, but to keep costs down, use of a single side is common and adequate for smaller screens.  There is no way with this design to reduce brightness by zone. They can’t produce an ideal colour gamut to cover the fill NTSC range.

Direct Lit W-LED lights use while LEDs distributed uniformly in a plane parallel to the matrix and allow for brightness variance across the screen.  This arrangement can give better results for consistent brightness and contrast.

RGB LED Backlights use an array of Red, Green and Blue LEDs are used to produce very pure and accurate colours.  Unfortunately they are very expensive to produce and only used in high cost professional screens.  If you are using your panel to make money in a profession where colour accuracy is critical, then they are worth looking at.

Contrast and Brightness specifications are two of the most abused numbers you will see on a specification sheet.  On many modern screens in a typical indoor environment you will find yourself turning down the brightness as the maximum level is far too high to be useful and is therefore largely irrelevant.  Modern screens will often be capable of 500 cd/M2 where under most indoor conditions you probably only want around 100-200 cd/m2.  If you are setting up a panel under very bright or outdoor conditions it may be worth looking at the brightness specification, but otherwise don’t worry about it.

Just to reinforce that fact, note that a very high brightness level on a cheap monitor can in fact be a (minor) negative.  As mentioned in the Refresh Rate section above, a common way to reduce brightness is to use Pulse Width Modulation, essentially to cycle the backlight on and off very quickly to lower the perceived brightness.  This is less than ideal and can induce a perceived flicker, headaches and other effects in rare circumstances.  It doesn’t tend to be an issue for most people, but the bigger the difference between the brightness of the backlight and the preferred brightness, the bigger the potential impact.  An alternate method to dim panels uses DC current is increasingly popular and negates the issues related to PWM.

Brightness uniformity is probably more significant than absolute brightness and can vary across a panel by typically 10-20%.  Uniformity of brightness can be quite important in how you perceive an image but unfortunately it is not a specification that can be simply looked up and the impact will vary based on the pattern rather than a simple number.  For professionals where consistency across the panel is critical, I suggest looking up technical reviews of your shortlist of panels which should include testing of brightness uniformity.  You will find that better quality panels will also include a factory tested chart of luminosity packed with the panel.  On average, high end models that also target accurate colour reproductions will tend to have more uniform brightness.  The below gives you an idea of how brightness can vary on a large panel.

High contrast, where blacks are back and detail can be seen in deep shadows is important, but the ways it is measured can vary so it is not wise to trust the specifications on monitors, particularly between manufacturers.

Brightness and contrast tend to be linked as measured contrast may naturally go up when you increase the screen brightness.  For that reason a specification for contrast measured at maximum panel brightness, well about a preferred level for use, will give a more impressive result than actual contrast under normal conditions.

Measures for Dynamic Contrast are essentially useless when noted on LED backlight screens.  The LEDs can change from fully bright to off very quickly so can theoretically provide contrast ratio in the millions to one, but in reality there is usually something on the screen so what should be a complete black sitting near any other colour will never provide an ideal black as it is not possible to turn off the LEDs on the screen to provide it, though direct lit LED panels often will have some advantage over edge lit.

LED panels are designed to look best when viewed perpendicular to the panel.  When viewing the panel from a significant angle, colours will fade and the contrast will be reduced.  Certain design technologies can limit, though not entirely remove the effect.

Do not believe manufacturers angle of view specifications.  Like contrast, this “specification” is too easy to misrepresent and practically worthless when presented by a marketing department.  The panel type can give you some idea of likely characteristics when viewing from an angle (see below), but practically, you need to take a look at the panel at an angle before buying if this characteristic matters to you.  It is rare that viewing angle will matter with a modern panel at typical viewing distance.  Don’t worry too much about it unless your setup is unusual or if you often have a second person viewing from an angle.

Note if you like a large screen close up, the viewing angle to the corner will be much greater than your viewing angle to the centre of the screen, so the image may appear different across the panel and the viewing angle at modest angles does matter.  Check it out before buying.  One way around that issue in recent times is consider a curved screen.  In fact, that’s about the only setup where I would recommend one – very large panels viewed relatively close (it is very immersive for gaming).

I remember selling one of the early 40” LCD TV models when flat panels emerged.  It was a $10,000 RRP unit that sold through surprisingly well (some people have too much money!).  The picture was very impressive when static, but I was not personally impressed or tempted to buy one, simply because the panel suffered from noticeable ghosting when any fast action was on the screen.  The new funky technology was still inferior to a CRT to my eyes.  The problem was apparent when hooked into a PC where the mouse cursor was followed by a ghostly trail and if you moved it too fast, it would seem to disappear and take some hunting to pick it up again.

The problem was that the panel took a long time to change the colour of its pixels so any rapid change in the image was not immediately reflected on the screen but took noticeable time to transition in.  The small white mouse cursor left a trail because it took an appreciable amount of time to drop the brightness down, or crank it up, as it moved off an area and you could very much notice the operation.  An unpleasant version of watching fireworks sparklers being waved about in the dark!  The time to change from extremes, such as a white mouse pointer across a black background was longer than the change needed to adjust to a similar colour, say that cursor moving across a bright part of the screen, and the inconsistency made the effect even more annoying.  From memory the quoted response time spec on that old model was 40ms though that number seems to underestimate the effect. The below image shows a ghosting effect caused by inadequate response time occurs.

Published response times should not be taken at face value.  While specifications are rarely outright lies, the information is obfuscated by varying the way it is measured and with various unstated assumptions.  It is genuinely difficult to define and compare across panels as response times vary depending on the range of the change.  The response time in the early days of LCD panels normally referred to the time taken for a pixel to switch from fully inactive (black) to fully active (white) and then back to inactive again.  Over time, marketing departments went into action and started using different ways to measure response time that related to a grey to grey response time (though not always the same greys!) or only measuring the rise time.  This was complicated by the introduction of “Overdrive” or Response Time Compensation (RTC) technology which helps improve primarily grey to grey changes by sending an overvoltage to the pixels to help then switch faster.  This technology does not help black to white changes significantly, so the response times started to vary greatly between extremes.

I recall some years ago when I noticed a certain model that had specified 10ms response time was suddenly quoting 8ms.  Both were grey to grey figures.  We were pretty sure the units were identical, they were just keeping up with how competitors were specifying the number (or getting ahead, a faked up spec arm race).  Be a bit cautious with quoted response times.  As a rough idea, a 5ms quoted number grey to grey might be more like 16ms by the older method and that’s the more useful number, but also consider 5ms quoted on two different panels may not in fact exhibit the same response times in use, particularly if the panels are built with different technology such as TN panels vrs IPS panels (more on these further into the article).   The below curve shows how a particular panels response curve may appear.  Guess which number will appear on the specification sheet?

While your eye is probably happy with any sub 10ms response time, when looking at specifications that tend to underestimate response time, for general use you probably want a quoted spec under 5ms G2G though a little higher is probably acceptable.  For gaming and especially with high refresh rate monitors, you probably want a number closer to 2ms or lower with 5ms being acceptable on a tight budget.

Be aware that high colour accuracy panels tend to exhibit relatively high response times and for most users I always suggest going for the better colour accuracy when there is a trade off at a given price.  The main exception are gamers though note if you are a gamer who also wants quite accurate colours there are now high end gaming monitors based on IPS technology that offer solid colour accuracy and decent G2G response times (with techniques like overdrive), largely the best of both worlds.  For professional media creators, ignore response time and look at colour depth and accuracy before all.

Previous generation CRT screens worked with analogue signals that were actively and immediately transformed into an image, mainly limited by the time it takes to draw a frame on the screen (in the order of 10ms depending on refresh rate).  A modern PC sends digital data down a cable to your screen for it to interpret and display.  The difference means that new LCD and other digital technologies add a small delay between the image signal hitting the monitor to when that image information is displayed on the screen.  For most people the extra latency is not noticeable, but for some time critical applications, in particular some games played at competitive levels, it can be significant when added to other lag factors in the chain.

Input lag noticed by the user is more than just the monitor lag.  The time it takes between some input action, like moving a mouse, to when you see the response at the monitor level involves a chain of actions that take time at each step.  The sampling delay/signal time from the mouse to the PC, the time for the software to see and act on the signal, the time to process a required change and act on it, and so on till eventually a signal is sent to the monitor.  I won’t go into detail on the full chain, since this is an article about monitors after all, but I will note that input lag BEFORE the monitor sees a signal is typically in the 10s of ms and often much more depending on the application and hardware in use.  Keep in mind that any monitor lag adds to the delay in seeing a response.

Many current model LCD screens introduce input lag of around 10-20ms, particularly when targeted at gaming.  I know people who think they can notice introduced latency at that level.  I think they are kidding themselves, or perhaps more accurately blaming the monitor for more significant contributions to lag further up the chain!  Some popular screens, particularly higher image quality IPS screens introduce latency of around 30ms and higher, still not too bad for gaming but not ideal for the most serious gamers.  TV screens tend to be worse for lag, often more than 60ms.

Consider that at the 60HZ refresh rate of a typical monitor, you are looking at 17ms between each frame arriving.  Consider further than the frames being sent won’t likely line up with that refresh rate.  Additionally, some screens will need to process each new full frame to modify the image for sharpness, resolution, and possibly other factors  (TVs in particular often have extra processing).  Some models will hold a couple of frames before displaying.  Finally the pixels on the screen will take some time to change once they receive the signal.  All up, you can see how 30ms is not uncommon or unreasonable lag and up to 100ms not unheard of when a lot of processing is involved.

If you are planning to plug a PC or gaming console into a TV sized screen or if you are a hard core gamer, it may be worth researching the introduced latency.  For most people, it’s a minor factor.  As usual, fussy gamers might want to check a technical review of their chosen panel, but don’t get excessively critical!  A few milliseconds between panels is insignificant.

Monitors with a fixed refresh rate draw a series of images at a steady rate, typically 60Hz, but sometimes faster depending on the panel.  While the monitor wants to display images at a fixed rate, when playing a game your video card will likely construct new frames at differing rates depending on how complex the frames are.  For example, when use a spell effect off in game the extra visual workload and complexity may result in the frame rate dropping to half or more till the effect ends.  The difference in timing results in a less than ideal outcome for the player with issues like screen tearing, input lag, and stuttering potentially causing problems depending on the way that the problem is handled.  Some monitors now incorporate technology to reduce these problems and so when buying a new monitor you should consider if you need this technology and if so ensure you buy a screen with technology that matches your GPU.

The following diagram helps us visualise what is happening when the PC is constructing and sending new images to be displayed on a monitor at a varying rate.  The monitor will do its best to draw whatever data it has been presented with each time it draws a new frame.  Unfortunately, when the picture data does not line up with the refresh rate, we see an effect called tearing where parts of different frames might be displayed on the screen at the same time.

The windmill picture below gives you an idea of what tearing will look like on the monitor with the left using no solution on what appears to be a low refresh rate screen and the right showing the ideal situation.

The first solution that attempts to solve this issue was implemented at the PC level for common, fixed refresh rate monitors.  With V-Sync on, the GPU limits the frames sent to the monitor, delaying the frame being sent until after its next refresh cycle, preventing the overlap of data and screen tearing.  Unfortunately this solution can fix tearing, but introduces new problems of additional input lag as frames are held back, and stutter effects where the same frame may be displayed on two refresh cycles before a catch up when the frame rate drops.  It can make a game feel choppy.

To avoid the problems introduced by V-Sync, GPU suppliers teamed up with monitor manufacturers to introduce technology that changes the refresh rate of the monitor dynamically to match up with the varying rate at which it is supplied new images.

The first technology introduced using this was from NVidia and called G-Sync.  It requires the addition of a G-Sync module in the monitor and will only work with compatible NVidia GPUs.  The technology is licenced by NVidia, and monitors with the technology tend to cost significantly more than an identical monitor without the technology.  G-Sync does have noticeable benefits over V-Sync and can be worth the investment for serious gamers.

NVidias main competitor in the GPU gaming market is AMD, who have responded with a technology marketed as FreeSync.  An important difference with G-Sync is that Freesync does not require additional hardware built into the monitor but rather manages the adaptive refresh rate with an open standard supported by display port 1.2 and HDMI 2.0.  The monitor still needs the capacity to dynamically change its refresh rate but the absence of proprietary hardware keeps costs down.  There are technical differences in these technologies that makes some differences in performance, especially under particular circumstances, but for the most part the differences between these solutions are minor.  Both G-sync and Freesync do a good job.

For the most part, if you are a serious gamer, look for a monitor with G-Sync if you have an NVidia (GeForce) GPU and Freesync if you have an AMD (Radeon) GPU.  For casual gaming and most other use, these technologies are not necessarily worth trading off for other image quality or cost considerations.

The technology used to develop a panel will help define the characteristics of the display.  Different types of panels are not necessarily better or worse than another.  In some cases a certain panel type may offer some benefits over another panel type, but be inferior in other ways.  Some high end monitors use panels best suited to their target market, but also place additional effort and technology into greatly reducing the intrinsic weaknesses of the underlying panel design, providing an excellent overall monitor.  In other words, don’t immediately rule out a panel based on its technology, take a deeper look, especially for gaming screens.

The below provides an overview on panel technologies.  If you want a more in depth look, I suggest you have a read of http://www.tftcentral.co.uk/articles/panel_technologies.htm

Twisted Nematic (TN) panels are very common among cheap monitors and offer excellent response time, and can easily support high refresh rates, but are commonly poor in colour accuracy and angle of view.

TN panels often use 6 bits per colour channel so can only represent 2^6 = 64 shades of each RGB colour and that limits the number of discrete colours possible to 64^3 = 262k.  Six bit panels will not produce clean images when there is a gradual and subtle change in colour across parts of the image and colour accuracy will be poor compared to 8 or 10 bit panels.

Many TN screens use dithering to try to increase the perceived colour range by alternating colours across two pixels so your eyes perceive a third colour.  I am not a fan of this trick when its used to pass off a monitor as using a native 8 bit panel, though to be fair the effect does improve apparent image depth and 6 bit + FRC is much preferred over native 6 bit.  Some TN panels using this technique will still quote 16.7 million colours in their specification sheets, not entirely a lie, but the result to your eye may not be as good as the 16.7 million colours produced by a native 8 bit panel.

TN panels are a good choice for gaming on a budget, business workstations, and general use.

If you are involved in media creation, or even like viewing photos and videos, an entry level IPS panel will probably be a better option.

In Plane Switching (IPS) was for a long time an expensive, premium panel with the best overall image quality, colour accuracy, and viewing angles.  Their response times tended to be poor and they can exhibit poor contrast and as a result were not ideal for gaming.  Some of those issues have been largely negated with particular implementations of the technology.  Their strongest negative characteristic, one that annoys me, is “IPS glow”, an effect where darker colours can appear a bit washed out, mainly when viewed at even slight angles and can be particularly annoying with big screens up close.

Modern IPS panels tend to support native 8 bit (256 colours RGB shade = 16.7M colours) and often with FRC to simulate 10 bit, or native 10 bit  (=1Billion colours) per RGB colour. Some 6 bit + FRC IPS panels are produced targeted at the gaming market.

IPS panels are the choice for professionals and anyone looking for a premium screen.  You will find 10 bit panels that can cover the entire Abobe RGB colour space and 100% sRGB is common even with some cheaper IPS panels.

Common IPS technology includes S-IPS and H-IPS panels as well as various proprietary but related technologies.  A related technology developed by Samsung is Plane to Line Switching (PLS) which is similar to IPS in design and characteristics and may offer a better viewing angle and brightness.

I should mention the name IPS is largely controlled by LG where PLS is the name used by Samsung for their variant, and while there is a distinction between the technologies, they are closely related.   It is arguable which of the technologies is “better” and depends much on the design of each specific model.

Another proprietary IPS like technology is Advanced Hyper-Viewing Angle AHVA developed by AU Optronics and these panels are often using in IPS gaming targeted monitors at high refresh rates such as 144Hz.  You will still see some of these panels using 6 bit colour depths with FRC.

There are many IPS variant on the market that share only broad characteristics and target various use cases and budgets.

Vertical Alignment (VA) panels including S-PV and MVA sit somewhere between TN and IPS panels in both colour accuracy, viewing angle, and cost.  They can be poor with response times but tend to be the best option for high contrast with excellent blacks.  They usually suffer from severe colour shifting with the angle of view.

VA panels were quite popular a few years back, but cost reductions in IPS panels has eaten into their market share in recent times.

Modern LED backlit panels are highly power efficient.  I recall testing my first LED replacement over a same brand and size LCD panel.  The older screen used about 50W, the replacement around 25W.  As an interesting calculation, assume you save 25W, use the screen 8 hours a day and keep the screen for 10 years.  That’s 25 x 8 x 365 x 10 = 730kWh x 25c = $182 of electricity saved over 10 years!

There is not a lot of variance in power consumption between most LED backlight panels.  The consumption rate is more to do with the size, and brightness setting of the monitor.  For the most part, power consumption is not a significant variable that you can manage with a buying decision, though perhaps keep in mind that the smaller the screen, the less power it will use.

Monitor arms let you position screens outside the range of their standard mounts, and can be particularly handy at positioning multiple screens or to clean up your desk space.  Many monitors can be mounted using a VESA standard mount but be aware not all monitors support mounts.

If you are planning to use a custom mount, take a look at the monitor specs and ensure they list VESA mount compatibility and take note of the screw spacing’s.  Most monitors will support 75 x 75mm or 100x100mm mounts.

This article are covered a lot of ground, and yet I have only touched on the most important technologies and specifications and have used heavily simplified explanations of some of the technologies.  If there are particular areas of interest to you, such as say high frame rate gaming, I suggest you look for more specific and in depth articles that relate.  Hopefully I have provided a reasonable grounding in the basics to help you find and place those articles in context.  I have included a few resources below, but as always, google and a critical mind are your best resources (and perhaps our sales staff).

High PPI Scaling Improvements for Desktop Applications and “Mixed Mode” PPI Scaling in the Windows 10 Anniversary Update|||

