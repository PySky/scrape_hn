We’re going to talk about divide-and-conquer in this article. I’m very interested in this topic. I hope you will too. It takes me much of time to finish the assignments. I highly recommend you to take assignments seriously and try to solve 2 advanced problems.

Steps to do with Divide and conquer:

Otherwise, the greatest index i, where A[i] < k.

Otherwise (k < A[low]), the result is low — 1.

We will solve this problem by using divide and conquer algorithm. We will do step by step to solve it.

The runtime of binary search is O(logn).

This is very interesting section. We want to multiply large-integer numbers. How can we do that? Beside that problem, multiplying polynomials are applying for error-correcting codes, generate functions, convolution in signal processing…

We have 2 n-digit numbers: x and y (radix r = 2, 10).

We represent x and y into 2 forms that:

To calculate Big-O of recursive algorithms. We will general the formula and solve that in general cases.

The proof of this formula is in [2]. We will focus on problem solving in this article. :)

MergeSort likes the name, break-down and merge. The concept is very simple:

The key-point here is merging strategy. Just loop thought 2 sub-array, pick the smaller element, put it into a third-array.

Note: There is an interesting problem below that required us to tweak the Merge strategy. By tweaking it, you will full-fill understand the MergeSort.

The concept of QuickSort is choosing a pivot, rearranging array that every elements on the left pivot are smaller than pivot, every elements on the right pivot are bigger than pivot.

If we choose A[1] = 6 is a pivot, we need to re-arrange A into :

The QuickSort algorithm is implemented into 2 steps:

The pseudocode for this 2 steps:

As you see, l is left index, r is right index.

Partition(A, l, r) function is containing choosing pivot, and rearrange A from l(left-index) to r(right-index) into A[left] ≤ A[pivot] ≤ A[right] and returning the position(index) of A[pivot].

To choose pivot, we have many strategies. If we know what types of data we have, we will have better choice of pivot. There are common choices of pivot:

The pseudocode for re-arranging array with A[0] as pivot:

x will be the value of pivot.

We want to re-arrange A[l…r] into A[left] ≤ A[pivot] ≤ A[right] with

We will use the last example to show how we can transform A = [6, 4, 2, 3, 9, 8, 9, 4, 7, 6, 1] into [1, 4, 2, 3, 4, 6, 6, 9, 7, 8, 9].

Make a assumption that we have A[left] has only A[l] element, so j = 0.

We loop i from l+1 to r. At each step, we have to guarantee that A[left…j] ≤ A[pivot] ≤ A[j+1…r]. There are 2 cases:

If you run that algorithm manually, we will have A =[6, 4, 2, 3, 4, 6, 1, 9, 7, 8, 9].

So we have array: A[l] + A[1…j] + A[j+1…r] now. The last step is swap A[j] and A[0] so that we will have array: A[0…j-1] + A[pivot] + a[j+1…r].

So we got: A = [1, 4, 2, 3, 4, 6, 6, 9, 7, 8, 9].

To implement randomized pivot, it’s very simple by doing:

The Big-O of Randomized pivot QuickSort is O(nlogn) in average running time. The worst case running time is O(n²). This Big-O is a bit tricky. You can read the proof in [3].

Note: The worst case of QuickSort is O(n²) but in the practice, QuickSort gave us better performance than MergeSort on average.

You can see the visualization of QuickSort here. We can observe that if the data has many equal elements, QuickSort takes long time to finish. To optimize, we should have different partition strategies:

Instead of re-arranging A into A[left] ≤ A[pivot] ≤ A[right]. We will turn A into: A[left] ≤ A[m1…m2] ≤ A[right] with A[i] == A[pivot] (m1 ≤ i ≤ m2).

So at each step, we have less A[left], A[right] items to sort.

In the exercises, we will have the implement details for this algorithm.

The best way to fully understand these sorting algorithms and divide and conquer technique is to solve interesting problems. Let’s solve it together.

In this problem, you will implement the binary search algorithm that allows searching very efficiently (even huge) lists, provided that the list is sorted.

Input Format. The first line of the input contains an integer n and a sequence a0 < a1 < . . . < a(n-1) of n pairwise distinct positive integers in increasing order. The next line contains an integer k and k positive integers b0, b1, . . . , b(k-1).

Constraints. 1 ≤ n, k ≤ 10⁵; 1 ≤ai ≤ 10⁹ for all 0 ≤i<n; 1≤bj ≤10⁹ for all 0≤j<k;

Output Format. For all 0 ≤ i ≤ k-1, output an index 0≤j≤n-1 such that aj = bi or -1 if there is no such index.

Explanation:

 In this sample, we are given an increasing sequence a0 = 1, a1 = 5, a2 = 8, a3 = 12, a4 = 13 of length five and five keys to search: 8, 1, 23, 1, 11. We see that a2 = 8 and a0 = 1, but the keys 23 and 11 do not appear in the sequence a. For this reason, we output a sequence 2, 0, 1, 0, 1.

We just follow the BinarySearch pseudocode above and implement BinarySearch algorithm. Finally, we just loop through searching keys b0, b1, …,bk and run binary_search(a, bi).

Majority rule is a decision rule that selects the alternative which has a majority, that is, more than half the votes.

Given a sequence of elements a1, a2, . . . , an, you would like to check whether it contains an element that appears more than n/2 times. A naive way to do this is the following.

The running time of this algorithm is quadratic. Your goal is to use the divide-and-conquer technique to design an O(n log n) algorithm.

Input Format. The first line contains an integer n, the next one contains a sequence of n non-negative integers a0, a1, . . . , an 1.

Output Format. Output 1 if the sequence contains an element that appears strictly more than n/2 times, and 0 otherwise.

Explanation:

 This sequence also does not have a majority element (note that the element 1 appears twice and hence is not a majority element).

As you might have already guessed, this problem can be solved by the divide-and-conquer algorithm in time O(nlogn). Indeed, if a sequence of length n contains a majority element, then the same element is also a majority element for one of its halves. Thus, to solve this problem you first split a given sequence into halves and make two recursive calls. Do you see how to combine the results of two recursive calls?

It is interesting to note that this problem can also be solved in O(n) time by a more advanced (non-divide and conquer) algorithm that just scans the given sequence twice.

This is a super-interesting problem if you solve it by using divide and conquer.

Firstly, we need to divide into subproblems. At each step, we divide sequence into 2 left_half and right_half sequences. The main job is writing merge strategy:

To determine the majority of sequence, we will represent left_half or right_half into array of 2 elements: A[majorities, others].

majorities = A[0] is containing all elements(same value)that has majority in this sequence. Called A_major_elements

others = A[1] is all elements that has no A_major_elements inside.

the count_merge function will return the M[majorities, others] bases on left_half and right_half.

To do that, we do:

We call this process is chunk_process:

In count_merge function, we just need to choose majority basing on chunk_left and chunk_right.

In the end, we will have a result array: [majorities, others]. We just check the majorities has length over n/2 to give the answer.

The goal in this problem is to redesign a given implementation of the randomized quick sort algorithm so that it works fast even on sequences containing many equal elements.

Task. To force the given implementation of the quick sort algorithm to efficiently process sequences with few unique elements, your goal is replace a 2-way partition with a 3-way partition. That is, your new partition procedure should partition the array into three parts: < x part, = x part, and > x part.

Input Format. The first line of the input contains an integer n. The next line contains a sequence of n integers a0, a1, . . . , a(n-1).

As we talk above, we need to optimize QuickSort for data that has many equal elements. So we will partition array into 3 array:

Our main job is implementing partition3 function to re-arrange array A and return position m1, m2.

We loop through all element i from l + 1 to r. At each step, we make sure that we re-arrange a[i] to right position.

For example, if a[i] ≤ pivot(a[l]), we relocate a[i] to a[begin…end](has same value to pivot). We continue to check if a[i] == pivot, we keep that position by doing nothing, if a[i] < pivot, we need to move a[i] before a[begin].

In the end, we just swap a[0](pivot) and a[begin] to get final step of partition(re-arranging) array a.

It seems to be tricky to understand but if you run it manually, it will be very clear under your hand(I promised).

An inversion of a sequence a0, a1,…, a(n-1) is a pair of indices 0 ≤i < j < n such that ai > aj. The number of inversions of a sequence in some sense measures how close the sequence is to being sorted. For example, a sorted (in non-descending order) sequence contains no inversions at all, while in a sequence sorted in descending order any two elements constitute an inversion (for a total of n(n 1)/2 inversions).

Task. The goal in this problem is to count the number of inversions of a given sequence.

Input Format. The first line contains an integer n, the next one contains a sequence of integers a0, a1,…, a(n-1).

Output Format. Output the number of inversions in the sequence.

Explanation:

The two inversions here are(1, 3)(a1 =3 > 2=a3) and (2, 3)(a2 =9 > 2=a3).

This problem can be solved by modifying the merge sort algorithm. For this, we change both the Merge and MergeSort procedures as follows:

Our goal is printing number of inversions ai > aj ( 0 ≤ i ≤ j ≤ n). We will divide array A into left_array and right_array with format: [count_inversions, sorted_elements].

In merge function, we can implement like MergeSort and we need to add count_inversions for step that has left_array[1][i] > right_array[1][i].

You are organizing an online lottery. To participate, a person bets on a single integer. You then draw several ranges of consecutive integers at random. A participant’s payoff then is proportional to the number of ranges that contain the participant’s number minus the number of ranges that does not contain it. You need an efficient algorithm for computing the payoffs for all participants. A naive way to do this is to simply scan, for all participants, the list of all ranges. However, you lottery is very popular: you have thousands of participants and thousands of ranges. For this reason, you cannot afford a slow naive algorithm.

Task. You are given a set of points on a line and a set of segments on a line. The goal is to compute, for each point, the number of segments that contain this point.

Input Format. The first line contains two non-negative integers s and p defining the number of segments and the number of points on a line, respectively. The next s lines contain two integers ai, bi defining the i-th segment [ai, bi]. The next line contains p integers defining points x1, x2, . . . , xp.

Output Format. Output p non-negative integers k0, k1, . . . , k(p-1) where ki is the number of segments which contain xi.

Explanation:

Here, we have two segments([0, 5], [7, 10]) and three points([1, 6, 11]). The first point lies only in the first segment while the remaining two points are outside of all the given segments.

As you might have already guessed, you goal is to first sort the given segments somehow (so, this is a sorting problem, not a divide-and-conquer problem).

This problem is very challenging. To solve this problem, we have to sort given segments by some strategies.

We will turn [ai, aj] and points [pk] into 3 arrays: [ai, LEFT], [aj, RIGHT], [pk, POINT] with LEFT = 1, POINT = 2, RIGHT = 3.

We try to sort [ai, LEFT] + [aj, RIGHT] + [pk, POINT]. To compare 2 elements [x, LEFT/RIGHT/POINT] and [y, LEFT/RIGHT/POINT], we compare x and y, if x == y, we compare LEFT/RIGHT/POINT basing on the value of LEFT = 1, POINT = 2, RIGHT = 3.

For example, we have segments: [0, 5], [-3, 2], [7, 10] and points: [1, 6]. We turn these into: [0, LEFT], [5, RIGHT], [-3, LEFT], [2, RIGHT], [1, POINT], [6, POINT]. Then we sort these items using RandomizedQuickSort that we did in problem 3, we will have a sorted array:

[-3, LEFT], [0, LEFT], [1, POINT], [2, RIGHT], [5, RIGHT], [6, POINT], [10, RIGHT].

To count the covering segments, we just need to count how many (“LEFT” — “RIGHT”) items appeared before “POINT” item.

To pass this problem, I have to submit 11 times with a lot of changing strategy. So, don’t give up, you’re better than you think!

In this problem, your goal is to find the closest pair of points among the given n points. This is a basic primitive in computational geometry having applications in, for example, graphics, computer vision, traffic-control systems.

Task. Given n points on a plane, find the smallest distance between a pair of two (different) points.

Input Format. The first line contains the number n of points. Each of the following n lines defines a point (xi, yi).

Output Format. Output the minimum distance. The absolute value of the difference between the answer of your program and the optimal value should be at most 1/10³. To ensure this, output your answer with at least four digits after the decimal point (otherwise your answer, while being computed correctly, can turn out to be wrong because of rounding issues).

Explanation: The smallest distance is √2. There are two pairs of points at this distance: ( 1, 1) and ( 2, 2); ( 2, 4) and ( 1, 3).

There is a chapter in [CLRS] discuss about this problem, I think this problem is hardest in this course. I usually encounter with Failed case #22/23: time limit exceeded. So, be sure that you read [CLRS] textbook, [section 33.4] about this problem first.

We need to pre-sort points by x coordinate and divide points into 2 arrays: left_points and right_points. Our goal is calculate min distance of left_points called min_left, min distance of right_points called min_right. And min distance between left_points and right_points called hybrid_min.

For small size of array(size < 3), we use compute min distance by brute-force. We try to compute left_min and right_min first. We call min distance of left_min and right_min is separated_min. Because left_points and right_points are sorted by x and we did compute separated_min, so instead of computing hybrid_min of all left_points and all right_points, we just care the points that has x coordinate within separated_min radius from the middle-line line_l = (left_points[last].x + right_points[first].x)/2.

We reduced number of points the has x coordinate between separated_min radius. We call these reduced points is reduced_total points. We can see that, to compute min distance of a point to all points in reduced_total points, we just need to compute 7 points in reduced_total points that have y coordinate within separated_min. It means the boundary of point x from reduced_total points is a rectangle with wide = 2 x separated_min, height = separated_min. So to do that, we need to sort reduced_total points by y_coordinate and loop through all sorted reduced_total points, compute min distance of 7-points-boundary. Then we can finally compute hybrid min distance.

It’s very difficult to get right direction of implementing this algorithms. Once you implement right, you will pass this problem. I did submit 17 times for this problems. So keep calm and keep submitting. :D

Merge sort and lower bound for comparison based sorting: Section 2.3 of [DPV08]|||

We’re going to talk about divide-and-conquer in this article. I’m very interested in this topic. I hope you will too. It takes me much of time to finish the assignments. I highly recommend you to…