Econophysics is an interdisciplinary research field, applying theories and methods originally developed by physicists in order to solve problems in economics, usually those including uncertainty or stochastic processes and nonlinear dynamics. Some of its application to the study of financial markets has also been termed statistical finance referring to its roots in statistical physics. For an accessible introduction and toy manufacturing model, requiring only first semester calculus, see .[1]

Physicists’ interest in the social sciences is not new; Daniel Bernoulli, as an example, was the originator of utility-based preferences. One of the founders of neoclassical economic theory, former Yale University Professor of Economics Irving Fisher, was originally trained under the renowned Yale physicist, Josiah Willard Gibbs.[2] Likewise, Jan Tinbergen, who won the first Nobel Prize in economics in 1969 for having developed and applied dynamic models for the analysis of economic processes, studied physics with Paul Ehrenfest at Leiden University. Most importantly, Jan Tinbergen has developed the Gravity Model of International Trade that has became the work horse of the international economics.

Econophysics was started in the mid-1990s by several physicists working in the subfield of statistical mechanics. Unsatisfied with the traditional explanations and approaches of economists - which usually prioritized simplified approaches for the sake of soluble theoretical models over agreement with empirical data - they applied tools and methods from physics, first to try to match financial data sets, and then to explain more general economic phenomena.

One driving force behind econophysics arising at this time was the sudden availability of large amounts of financial data, starting in the 1980s. It became apparent that traditional methods of analysis were insufficient - standard economic methods dealt with homogeneous agents and equilibrium, while many of the more interesting phenomena in financial markets fundamentally depended on heterogeneous agents and far-from-equilibrium situations.

The term "econophysics" was coined by H. Eugene Stanley, to describe the large number of papers written by physicists in the problems of (stock and other) markets, in a conference on statistical physics in Kolkata (erstwhile Calcutta) in 1995 and first appeared in its proceedings publication in Physica A 1996.[3][4] The inaugural meeting on Econophysics was organised 1998 in Budapest by János Kertész and Imre Kondor.

Currently, the almost regular meeting series on the topic include: APFA, ECONOPHYS-KOLKATA,[5] Econophysics Colloquium, ESHIA/ WEHIA.

In recent years network science, heavily reliant on analogies from statistical mechanics, has been applied to the study of productive systems. That is the case with the works done at the Santa Fe Institute in European Funded Research Projects as Forecasting Financial Crises and the Harvard-MIT Observatory of Economic Complexity

If "econophysics" is taken to denote the principle of applying statistical mechanics to economic analysis, as opposed to a particular literature or network, priority of innovation is probably due to Emmanuel Farjoun and Moshé Machover (1983). Their book Laws of Chaos: A Probabilistic Approach to Political Economy proposes dissolving (their words) the transformation problem in Marx's political economy by re-conceptualising the relevant quantities as random variables.[6]

If, on the other side, "econophysics" is taken to denote the application of physics to economics, one can already consider the works of Léon Walras and Vilfredo Pareto as part of it. Indeed, as shown by Bruna Ingrao and Giorgio Israel, general equilibrium theory in economics is based on the physical concept of mechanical equilibrium.

Econophysics has nothing to do with the "physical quantities approach" to economics, advocated by Ian Steedman and others associated with Neo-Ricardianism. Notable econophysicists are Jean-Philippe Bouchaud, Bikas K Chakrabarti, J. Doyne Farmer, Dirk Helbing, János Kertész, Francis Longstaff, Rosario N. Mantegna, Matteo Marsili, Joseph L. McCauley, Enrico Scalas, Didier Sornette, H. Eugene Stanley, Victor Yakovenko and Yi-Cheng Zhang. Particularly noteworthy among the formal courses on Econophysics is the one offered by the Physics Department of the Leiden University,[7][8][9] from where the first Nobel-laureate in economics Jan Tinbergen came. From September 2014 King's College has awarded the first position of Full Professor in Econophysics.

Basic tools of econophysics are probabilistic and statistical methods often taken from statistical physics.

Physics models that have been applied in economics include the kinetic theory of gas (called the Kinetic exchange models of markets [10]), percolation models, chaotic models developed to study cardiac arrest, and models with self-organizing criticality as well as other models developed for earthquake prediction.[11] Moreover, there have been attempts to use the mathematical theory of complexity and information theory, as developed by many scientists among whom are Murray Gell-Mann and Claude E. Shannon, respectively.

Since economic phenomena are the result of the interaction among many heterogeneous agents, there is an analogy with statistical mechanics, where many particles interact; but it must be taken into account that the properties of human beings and particles significantly differ. However, statistical mechanics has been shown to be a result of well-established tools used by economists in Potential games, as opposed to statistical mechanics being used a-priori to model economics phenomena.[12] In fact, the Quantal response equilibrium was shown to be a mean-field version of the Gibbs measure in the context of bounded-rational Potential games.

For Potential games, it has been shown that an emergence-producing equilibrium based on information via Shannon information entropy produces the same equilibrium measure (Gibbs measure from statistical mechanics) as a stochastic dynamical equation, both of which are based on bounded rationality models used by economists. The fluctuation-dissipation theorem connects the two to establish a concrete correspondence of "temperature", "entropy", "free potential/energy", and other physics notions to an economics system. The statistical mechanics model is not constructed a-priori - it is a result of a bounded rational assumption and modeling on existing neoclassical models. It has been used to prove the "inevitability of collusion" result of Huw Dixon in a case for which the neoclassical version of the model does not predict collusion. [13] [14] Here the demand is increasing, as with Veblen goods or stock buyers with the "hot hand" fallacy preferring to buy more successful stocks and sell those that are less successful. [15] It also yields a phase transition in a model of two interdependent markets, giving a different perspective to the Sonnenschein-Mantel-Debreu theorem.[16] [17]

Quantifiers derived from information theory were used in several papers by econophysicist Aurelio F. Bariviera and coauthors in order to assess the degree in the informational efficiency of stock markets. In a paper published in Physica A[18]

Zunino et al. use an innovative statistical tool in the financial literature: the complexity-entropy causality plane. This Cartesian representation establish an efficiency ranking of different markets and distinguish different bond market dynamics. Moreover, the authors conclude that the classification derived from the complexity-entropy causality plane is consistent with the qualifications assigned by major rating companies to the sovereign instruments. A similar study developed by Bariviera et al.[19] explore the relationship between credit ratings and informational efficiency of a sample of corporate bonds of US oil and energy companies using also the complexity–entropy causality plane. They find that this classification agrees with the credit ratings assigned by Moody's.

Another good example is random matrix theory, which can be used to identify the noise in financial correlation matrices. One paper has argued that this technique can improve the performance of portfolios, e.g., in applied in portfolio optimization.[20]

There are, however, various other tools from physics that have so far been used, such as fluid dynamics, classical mechanics and quantum mechanics (including so-called classical economy, quantum economy and quantum finance),[21] and the path integral formulation of statistical mechanics.[22]

The concept of economic complexity index, introduced by the MIT physicist Cesar A. Hidalgo and the Harvard economist Ricardo Hausmann and made available at MIT's Observatory of Economic Complexity, has been devised as a predictive tool for economic growth. According to the estimates of Hausmann and Hidalgo, the ECI is far more accurate in predicting GDP growth than the traditional governance measures of the World Bank.[23]

There are also analogies between finance theory and diffusion theory. For instance, the Black–Scholes equation for option pricing is a diffusion-advection equation (see however [24][25] for a critique of the Black-Scholes methodology). The Black-Scholes theory can be extended to provide an analytical theory of main factors in economic activities.[22]

Papers on econophysics have been published primarily in journals devoted to physics and statistical mechanics, rather than in leading economics journals. Mainstream economists have generally been unimpressed by this work.[26] Some Heterodox economists, including Mauro Gallegati, Steve Keen, Paul Ormerod, and Alan Kirman have shown more interest, but also criticized trends in econophysics.

In contrast, econophysics is having some impact on the more applied field of quantitative finance, whose scope and aims significantly differ from those of economic theory. Various econophysicists have introduced models for price fluctuations in financial markets or original points of view on established models.[24][27][28] Also several scaling laws have been found in various economic data.[29][30][31]

Presently, one of the main results of econophysics comprise the explanation of the "fat tails" in the distribution of many kinds of financial data as a universal self-similar scaling property (i.e. scale invariant over many orders of magnitude in the data),[32] arising from the tendency of individual market competitors, or of aggregates of them, to exploit systematically and optimally the prevailing "microtrends" (e.g., rising or falling prices). These "fat tails" are not only mathematically important, because they comprise the risks, which may be on the one hand, very small such that one may tend to neglect them, but which - on the other hand - are not neglegible at all, i.e. they can never be made exponentially tiny, but instead follow a measurable algebraically decreasing power law, for example with a failure probability of only where x is an increasingly large variable in the tail region of the distribution considered (i.e. a price statistics with much more than 108 data). I.e., the events considered are not simply "outliers" but must really be taken into account and cannot be "insured away".[33]  It appears that it also plays a role that near a change of the tendency (e.g. from falling to rising prices) there are typical "panic reactions" of the selling or buying agents with algebraically increasing bargain rapidities and volumes.[33]  The "fat tails" are also observed in commodity markets.

As in quantum field theory the "fat tails" can be obtained by complicated "nonperturbative" methods, mainly by numerical ones, since they contain the deviations from the usual Gaussian approximations, e.g. the Black-Scholes theory. Fat tails can, however, also be due to other phenomena, such as a random number of terms in the central-limit theorem, or any number of other, non-econophysics models. Due to the difficulty in testing such models, they have received less attention in traditional economic analysis.

Another result[17] shows the existence of a phase transition in a bounded-rational interdependent two-market model with a longer-term investing agent and speculators who equilibrate the markets more quickly. The emergence of market preference is shown to occur. When the longer-term investor is absent, speculators spontaneously break a market exchange symmetry as they become more rational (below a critical temperature), with diverging spatial-volatility/susceptibility, and crowd their preferences into one of the two markets. This spontaneous symmetry breaking shows how one of two equilibria is chosen for a non-concave potential, which gives a statistical mechanics perspective to the existence of multiple equilibria in the spirit of the Sonnenschein-Mantel-Debreu theorem. Spatial volatility does not diverge when the longer-term investor is present, showing the longer-term investor creates a more stable situation.|||

