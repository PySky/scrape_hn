This book is both ambitious and courageous. It is ambitious because it seeks to extract general principles from the accumulating mountain of data about brain function, and it is courageous because the principles discovered are not expressed only in the imprecise realm of mere words. Instead, Sterling and Laughlin interpret physiological findings from a wide range of organisms in terms of a single unifying framework: Shannon’s mathematical theory of information, in which information is a well-defined quantity measured in bits.



From the outset, Sterling and Laughlin make it quite plain that this not a book of speculation about brains, but it is a book which shows how definite facts can be used extract general principles of brain function. In the search for these general principles, Sterling and Laughlin cast their investigative net wide, covering sensory and motor systems in species which represent a diverse range of evolutionary experiments.



By comparing these systems in the bacterium Escherichia coli, the single celled Paramecium caudatum, the nematode worm Caenorhabditis elegans, the fruit fly Drosophila melanogaster, and a variety of mammals (including humans), the authors show that:



1) even though the biochemical or neuronal signalling systems vary greatly within each species according to the particular demands placed on each sensory system (e.g. vision versus olfaction),



2) the processing within each type of sensory system (e.g. vision) is similar when considered across different species.



For example, they show that the information processing steps in neural networks that support vision are different from those that support audition within the human brain, but the information processing steps in neural networks that support vision in humans are very similar to those that support vision in flies.



Rather than noting this as an intriguing evolutionary coincidence, Sterling and Laughlin ar- gue convincingly that these findings are the result of an interaction between universal physical constraints and species-specific constraints on information processing. These constraints dictate that the energy cost of each additional bit of information rises extremely steeply, resulting in rapidly diminishing informational returns on each extra Joule of energy expended. And because energy cost translates fairly directly into Darwinian fitness, the importance of these constraints is self-evidently paramount.



The principles discovered are made clear at the outset, and these principles are re-discovered many times within the book as different species and sensory systems are examined. In this regard, the book resembles Darwin’s great work, On the Origin of Species. Sterling and Laughlin do not just propose a vague but plausible idea in the hope that others might believe it. They propose a series of testable hypotheses (principles), formulated in mathematically precise language, and support them with a detailed analysis of hard evidence drawn from a virtual archipelago of diverse sources. This book deserves to have an enormous impact on neuroscience (and the various ’brain sciences’), because (in the best traditions of science) it provides a framework for condensing mountains of physiological data into a neat theoretical (information-shaped) molehill.



Sterling and Laughlin do not claim that the set of 10 principles they discover are either complete nor infallible, but they make a convincing case that these principles deserve to be taken seriously. These principles are not listed here because they require substantial context for their worth to be appreciated. The fact that the principles cannot be stated in isolation reflects the authors’ ability to simplify, but not to over-simplify, what is essentially a complex problem.



Like most books on the brain, this one explains how particular mechanisms execute particular functions, but, unlike most books, it also makes frequent use of the word "why". According to Sterling and Laughlin, it is not enough (for example) to understand the physical mechanisms which tells us how a photon changes the voltage of a photoreceptor by some amount. A complete theory of vision should also tell us why the mechanism is the way it is, why its voltage changed by that amount, and why not twice nor half that amount.



This emphasis on why the brain operates as it does has a strong tradition uniquely associated with the computational approach to brain function espoused in books by Marr (Vision, 1981), Rieke et al (Spikes, 1997), Land and Nilsson (Animal Eyes, 2003), Dayan and Abbott (Theoretical Neuroscience, 2005), Bialek (Biophysics: Searching for Principles, 2012). So the approach is not new, but it is rarely adopted, nor expressed as cogently as it is in this book; a book which will still be read long after books which describe only how neurophysiological mechanisms work have been forgotten.



Whilst the authors’ ambition is laudable, some aspects of the execution could be better. This book relies critically on the reader having a firm grasp of Shannon’s formal definition of information. Even though a few pages are dedicated to this, a tutorial account would allow less numerate readers to appreciate the many results which depend on understanding information theory. On a similar note, certain key technical terms are not explained (e.g. Nyquist limit, Fourier transform, and point spread function). Addressing these problems would have greatly improved the book’s accessibility. Having said that, the effort involved in researching topics via Google (as readers are enjoined to do in the Preface) would be well rewarded with a clearer understanding of the book.



In conclusion, the authors clearly believe neuroscience suffers from two related problems: too much data and too little theory. They claim that, “the best we can do with Data Mountain really is just to set a few pitons up the south face”. But I think they have achieved much more than this. Sterling and Laughlin have firmly established a base camp, and have hewn a path which will allow scientists of sufficient skill and fortitude to conquer Data Mountain.



--

Note: In order that you can gauge if I am qualified to comment on this book, my name is

Dr JV Stone, a lecturer in the Department of Psychology, University of Sheffield, England.

I have published books and papers on vision, computational neuroscience and information theory.

--|||

Principles of Neural Design (MIT Press) [Peter Sterling, Simon Laughlin] on Amazon.com. *FREE* shipping on qualifying offers. Neuroscience research has exploded, with more than fifty thousand neuroscientists applying increasingly advanced methods. A mountain of new facts and mechanisms has emerged. And yet a principled framework to organize this knowledge has been missing. In this book