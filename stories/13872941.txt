In one of the previous posts, I discussed about HTTP and where it stands at this point. This is one is going to be specifically about the caching.

As users, we easily get frustrated by the buffering videos, the images that take seconds to load, pages that got stuck because the content is being loaded. Loading the resources from some cache is much faster than fetching the same from the originating server. It reduces latency, speeds up the loading of resources, decreases the load on server, cuts down the bandwidth costs etc.

What is web cache? It is something that sits somewhere between the client and the server, continuously looking at the requests and their responses, looking for any responses that can be cached. So that there is less time consumed when the same request is made again.

Before we get into further details, let me give you an overview of the terms that will be used, further in the article

Web cache can be shared or private depending upon the location where it exists. Below is the list of caching locations

You might have noticed that when you click the back button in your browser it takes less time to load the page than the time that it took during the first load; this is the browser cache in play. Browser cache is the most common location for caching and browsers usually reserve some space for it.

A browser cache is limited to just one user and unlike other caches, it can store the “private” responses. More on it later.

Unlike browser cache which serves a single user, proxy caches may serve hundreds of different users accessing the same content. They are usually implemented on a broader level by ISPs or any other independent entities for example.

Reverse proxy cache or surrogate cache is implemented close to the origin servers in order to reduce the load on server. Unlike proxy caches which are implemented by ISPs etc to reduce the bandwidth usage in a network, surrogates or reverse proxy caches are implemented near to the origin servers by the server administrators to reduce the load on server.

Although you can control the reverse proxy caches (since it is implemented by you on your server) you can not avoid or control browser and proxy caches. And if your website is not configured to use these caches properly, it will still be cached using whatever the defaults are set on these caches.

So, how do we control the web cache? Whenever the server emits some response, it is accompanied with some HTTP headers to guide the caches whether and how to cache this response. Content provider is the one that has to make sure to return proper HTTP headers to force the caches on how to cache the content.

Before HTTP/1.1 and introduction of , there was header which is simply a timestamp telling the caches how long should some content be considered fresh. Possible value to this header is absolute expiry date; where date has to be in GMT. Below is the sample header

It should be noted that the date cannot be more than a year and if the date format is wrong, content will be considered stale. Also, the clock on cache has to be in sync with the clock on server, otherwise the desired results might not be achieved.

Although, header is still valid and is supported widely by the caches, preference should be given to HTTP/1.1 successor of it i.e. .

Another one from the old, pre HTTP/1.1 days, is . Everything that it could do is now possible using the cache-control header given below. However, one thing I would like to point out about it is, you might see being used here and there in hopes of stopping the response from being cached. It might not necessarily work; as HTTP specification discusses it in the request headers and there is no mention of it in the response headers. Rather header should be used to control the caching.

Cache-Control specifies how long and in what manner should the content be cached. This family of headers was introduced in HTTP/1.1 to overcome the limitations of the header.

Value for the header is composite i.e. it can have multiple directive/values. Let’s look at the possible values that this header may contain.

Setting the cache to means that the content will not be cached in any of the proxies and it will only be cached by the client (i.e. browser)

Having said that, don’t let it fool you in to thinking that setting this header will make your data any secure; you still have to use SSL for that purpose.

If set to , apart from being cached by the client, it can also be cached by the proxies; serving many other users

specifies that the content is not to be cached by any of the caches

indicates that the cache can be maintained but the cached content is to be re-validated (using for example) from the server before being served. That is, there is still a request to server but for validation and not to download the cached content.

specifies the number of seconds for which the content will be cached. For example, if the looks like below:

it would mean that the content is publicly cacheable and will be considered stale after 60 seconds

here prefix stands for shared. This directive specifically targets the shared caches. Like it also gets the number of seconds for which something is to be cached. If present, it will override and headers for shared caching.

it might happen sometimes that if you have network problems and the content cannot be retrieved from the server, browser may serve stale content without validation. avoids that. If this directive is present, it means that stale content cannot be served in any case and the data must be re-validated from the server before serving.

is similar to but it specifies the same for shared or proxy caches. In other words is to as is to . But why did they not call it ?. I have no idea why, if you have any clue please leave a comment below.

You can combine these directives in different ways to achieve different caching behaviors, however and are mutually exclusive.

If you specify both and , will be given precedence over .

For , for any unauthenticated requests cache is considered and for any authenticated ones cache is considered .

Up until now we only discussed how the content is cached and how long the cached content is to be considered fresh but we did not discuss how the client does the validation from the server. Below we discuss the headers used for this purpose.

Etag or “entity tag” was introduced in HTTP/1.1 specs. Etag is just a unique identifier that the server attaches with some resource. This ETag is later on used by the client to make conditional HTTP requests stating "give me this resource if ETag is not same as the ETag that I have" and the content is downloaded only if the etags do not match.

Method by which ETag is generated is not specified in the HTTP docs and usually some collision-resistant hash function is used to assign etags to each version of a resource. There could be two types of etags i.e. strong and weak

A strong validating ETag means that two resources are exactly same and there is no difference between them at all. While a weak ETag means that two resources are although not strictly same but could be considered same. Weak etags might be useful for dynamic content, for example.

Now you know what etags are but how does the browser make this request? by making a request to server while sending the available Etag in header.

Consider the scenario, you opened a web page which loaded a logo image with caching period of 60 seconds and ETag of . After about 30 minutes you reload the page, browser will notice that the logo which was fresh for 60 seconds is now stale; it will trigger a request to server, sending the ETag of the stale logo image in header

Server will then compare this ETag with the ETag of the current version of resource. If both etags are matched, server will send back the response of which will tell the client that the copy that it has is still good and it will be considered fresh for another 60 seconds. If both the etags do not match i.e. the logo has likely changed and client will be sent the new logo which it will use to replace the stale logo that it has.

Server might include the header indicating the date and time at which some content was last modified on.

When the content gets stale, client will make a conditional request including the last modified date that it has inside the header called to server to get the updated date; if it matches the date that the client has, date for the content is updated to be considered fresh for another seconds. If the received date does not match the one that the client has, content is reloaded from the server and replaced with the content that client has.

You might be questioning now, what if the cached content has both the and assigned to it? Well, in that case both are to be used i.e. there will not be any re-downloading of the resource if and only if matches the newly retrieved one and so does the date. If either the does not match or the is greater than the one from the server, content has to be downloaded again.

Now that we have got everything covered, let us put everything in perspective and see how you can use this information.

Before we get into the possible caching strategies , let me add the fact that most of the servers including Apache and Nginx allow you to implement your caching policy through the server so that you don’t have to juggle with headers in your code.

For example, if you are using Apache and you have your static content placed at , you can put below file in the directory to make all the content in it be cached for an year using below

You can further use directive to add conditionals and use different caching strategy for different kinds of files e.g.

Or if you don’t want to use the file you can modify Apache’s configuration file . Same goes for Nginx, you can add the caching information in the location or server block.

There is no golden rule or set standards about how your caching policy should look like, each of the application is different and you have to look and find what suits your application the best. However, just to give you a rough idea

And that about wraps it up. If you have any comments or feedback, feel free to leave a comment below.|||

