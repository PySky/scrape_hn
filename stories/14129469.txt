Now every big companies like Facebook,Apple and Google are running machine learning algorithms on their respective servers by collecting the data from users’ devices. They use this data to train their algorithms and gives you predictions over the cloud. This kind of training and predictions are  normally are present from Gboard to prediction next word, to search in your email app.

This means that user-privacy is not as great as compared to data being on the device. Also its time-consuming as the movement of data from device to cloud and updating could take time. So to address these problems, Google is experimenting with a new method of AI training called Federated Learning. Federated Learning enables mobile phones to collaboratively learn a shared prediction model while keeping all the training data on device, decoupling the ability to do machine learning from the need to store the data in the cloud. This means that instead of collecting user data in one place on Google’s servers and training algorithms with it, the learning process happens directly on the device using your mobile’s cpu/gpu.

Google mentioned in its blog post that:

Federated Learning allows for smarter models, lower latency, and less power consumption, all while ensuring privacy. And this approach has another immediate benefit: in addition to providing an update to the shared model, the improved model on your phone can also be used immediately, powering experiences personalized by the way you use your phone. We’re currently testing Federated Learning in Gboard on Android, the Google Keyboard. When Gboard shows a suggested query, your phone locally stores information about the current context and whether you clicked the suggestion. Federated Learning processes that history on-device to suggest improvements to the next iteration of Gboard’s query suggestion model.

In a summary, your device downloads the current model, improves it by learning from data on your phone, and then summarizes the changes as a small focused update. Only this update to the model is sent to the cloud, using encrypted communication, where it is immediately averaged with other user updates to improve the shared model  and issues an update to the app for all its users.

These kind of attempts are already made by Apple previously and companies trying to give importance to user-privacy and also making better AI with minimizing the data collection from users.

To comment on this article and other content,  please visit our The Box Internet Facebook page.|||

