“They got caught in the middle of everything,” says Taser’s cofounder and CEO, Rick Smith, who was in the outskirts of the city at the time and stayed up until the early hours to make sure his employees were safe. “It was pretty scary.” By the time it was over, the citywide siege had claimed the lives of at least 130 people. The effects of the attack were tangible the following week at Milipol, a police trade show held biennially outside the city. Smith had come to Milipol to display his company’s line of electroshock weapons and body cameras, but talk of the attacks with his European customers fueled curious questions about future products. When will officers be able to stream video from their body cameras back to base as a crisis is unfolding, like a police-only version of Facebook Live? And could that footage be automatically analyzed for anomalies, behaviors, and faces–sort of like RoboCop? As it turned out, Taser teams back in Scottsdale, Arizona, and Seattle, Washington had already begun to tackle those questions. “There’s a ton of interest in getting better real-time information,” says Smith. And “real-time analytics are going to be very interesting.” A terror attack like Paris would be one case where live streaming and real-time video analytics could prove helpful, says Smith. With facial recognition software, the camera could scan the faces of passersby for persons of interest: an automated wanted poster distributed instantly to the camera of every beat cop in a city. “An obvious use case would be searching for a known cop killer” on the street, says Smith. “We can’t expect an officer to not get that alert if there’s official information on this guy.” Smith has commandeered an exploding market for police body cameras, ignited by a renewed demand for accountability in police-community relations. Some 6,000 of the U.S.’s 18,000 police agencies are thought to be using the devices, which have been hailed by both police and civil-rights advocates as an impartial window into controversial interactions, and as a tool to help prevent violent encounters. In the wake of Ferguson, President Obama’s Justice Dept. doled out $43 million in grants to help agencies buy the devices and the software services and storage they require. But the cameras are also being touted as an investigatory, data-gathering tool for law enforcement. Bolstered by a growing raft of additional high-tech features, the cameras could allow for a new form of high-definition surveillance, one conducted with few safeguards and little oversight. The scope is exceedingly broad, too: researchers at Georgetown have estimated that the faces of half of the U.S.’s adult population—117 million people, many of them people who have never committed a crime—have already been captured in a searchable federal, state, or local database. Among those concerned about the implications are the Justice Department, which in 2014 warned that combining cameras with “facial recognition systems and other new technologies like live feed and auto recording . . . may pose serious risks to public privacy.” It urged agencies that explore these technologies to “proceed very cautiously.”

Taser, known for its stun guns and increasingly, its dominance of the body camera market, initially raised the idea of cameras that can recognize suspects in 2009. Last month, the company took another step in that direction when it announced it had acquired Dextro, a New York City-based machine vision startup. Taser says Dextro’s expertise in artificial intelligence and its software will first be used to help police cope with growing mountains of recorded video: Algorithms that can detect objects and scenes in videos can automatically tag and flag footage for evidence collection, or help blur faces so that footage can be disclosed to the public. An automated wanted poster distributed instantly to the camera of every beat cop in a city. But applying these tools to already-recorded footage is only the beginning, says Smith. Body cameras equipped with live-streaming capabilities will allow police supervisors, “from a command center, [to] be able to see on a map where officers are, and be able to pick certain ones and say, ‘Okay, I’m actually going to start streaming that camera here live.’ Law enforcement officials would then be able to forward that footage to the officers who need it most.” “Particularly, in these kinds of events like the Boston Marathon, or the Paris attacks, people aren’t able to start accessing that information until later,” adds Smith. “We think that we can bring that to more and more real time. That video could also be quickly analyzed by software that scans for faces, objects, and heated encounters. Crucial information could be instantly sent to officers’ smartphones; eventually, a pair of augmented-reality glasses could display that data in an officer’s field of vision. Taser says it intends to roll out some of the Dextro-powered new features by the end of the year, and that at first, its face-detecting algorithms will be used only to blur them for redaction, not to identify them or match them to other faces. In an email, Steve Tuttle, Taser vice president for communications, said the company is not currently developing facial identification features, but that if it did, “before deploying any such technology, we would carefully vet any safety and privacy concerns,” he wrote. “We’re open to exploring any AI capabilities that can help make communities safer.”

The Perils And Promise Of Face Recognition An increasing number of police officers around the U.S. already use cruiser-mounted license plate readers to track passing cars, and in some cases, face recognition smartphone apps that can photograph and immediately identify unknown people officers stop on the street. A recent letter by 50 civil rights groups said “the technology is rapidly being interconnected with everyday police activities,” but that “the safeguards to ensure this technology is being used fairly and responsibly appear to be virtually nonexistent.” Because laws governing the use of biometrics are rare, individuals police encounter can often be photographed and have their faces run through face-matching databases without their consent. Taser isn’t the only company to imagine linking face and object recognition with body cameras. According to a November study by researchers at Johns Hopkins University and sponsored by the U.S. Department of Justice, at least nine of 38 manufacturers already allow facial recognition or have included an option for the software to be used later. Two vendors tout the ability of cameras to capture license plate numbers, which can provide current and historical vehicle locations, a technology that is already becoming common on patrol cars. One vendor boasts that its software can help officers detect concealed firearms. And a number of companies—including IBM, 3M, NEC, and Unisys, as well as a range of startups staffed by machine-vision researchers—offer software that can do facial matching and other analytics on video streams in real time. ‘If body cams themselves undermine people’s willingness to talk to cops, then imagine what it would be like if body cameras with live streaming or face recognition were implemented?’ Making body cameras “smart” raises a barrage of new questions. Shankar Narayan, the legislative director of the Washington State ACLU, contends that in spite of the possible safety promises of live streaming, facial recognition, and other new features, adding them to up-close, high-definition body camera video highlights a tension around the new gear. While body cameras are being sold to the public as an accountability tool, they will also inevitably be used by the police as a high-tech method for gathering evidence. “If we’re talking about police accountability, which is the reason body cameras are being justified, we can’t in the same breath turn around and say, ‘By the way, we should use these for generalized surveillance.'” New capabilities for the cameras could, paradoxically, risk undoing the confidence and trust in the community that cameras are meant to inspire, adds Narayan. Citizens may be more reluctant to speak to police—and report crimes—if they know they’re being recorded. “It seems to me that if body cams themselves undermine people’s willingness to talk to cops, then imagine what it would be like if body cameras with live streaming or face recognition were implemented?”

From a November 2016 National Institute of Justice-funded report on police body cameras. Smith defends video analysis as part of an “inexorable move of technology forward” for law enforcement. Facial recognition is already routinely employed on platforms run by Facebook, Google, and Apple, and increasingly retail stores, offices, banks, and airports use the software to recognize people who are wanted by police. All modern smartphones and more advanced consumer cameras are capable of streaming video, as witnessed, for example, by the video that Diamond Reynolds streamed on Facebook Live after her boyfriend, Philando Castile, was fatally shot by a Minnesota cop during a traffic stop in 2016. “Her first reaction was to pull out her phone and start livestreaming video,” says Smith. “A few years ago, that would be bizarre, but today it’s normal.” He frames the worries about privacy that body cameras raise in terms of advancements elsewhere. “Do we want to live in a world where everyone’s observed by everybody else? You know what? We are. I don’t think we’re going to make it illegal to have smartphones and cameras.” Police contend that video analytics software is crucial for helping quickly distill intelligence out of mountains of footage and photo evidence. After the 2013 Boston Marathon bombing, for example, law enforcement scrambled to process a torrent of images sent in by the public. That process has since been transformed by algorithms, says Patrick Doyle, a former New Jersey State Trooper who works for Unisys. “If you were looking for a certain picture, and we put that picture into our video management system, and it could look for that—even if we just gave it rough parameters, and say, hey, we’re looking for someone six feet tall, and if it could scan all the video or snippets that were sent in—it is possible now, rather rudimentary, but we’d be able to cull through,” he says. “Otherwise it would be too much for us.” David Luan, the founder of Dextro and Taser’s new head of AI, touts his software’s ability to automatically tag stored video, and flag suspicious behavior after the fact. “We can parse through all the body-worn camera footage and pick out specific moments when a car might have been visible, or when a house might have been visible, or when a gun that’s large enough to be detected is present on-screen,” he says.

Proponents of video analytics say that the technology could also help reduce uncertainty and preconceptions in officers during heated encounters. Smith mentions the cop who shot Philando Castile. If the officer had known immediately that Castile had a gun license but no violent criminal record, Smith suggests, perhaps he wouldn’t have drawn his weapon so quickly. Video analysis software could serve as an automatic “early warning system,” helping to flag officers who exhibit a tendency to, for instance, resort to excessive force or aggressive language in their encounters with the public. Agencies are already seeking ways to better track data about officers in order to identify risky patterns of behavior. Recognizing faces is a harder problem for software, experts say, especially the faces captured by conventional surveillance cameras. (The London Metropolitan Police, for instance, still relies on a team of human “super-recognizers” to identify suspects in photos and videos.) But body cameras offer more intimate views, and video quality and machine learning techniques are improving rapidly. Combined with existing U.S. face databases, body cameras could be used, in theory, to search for people, in near real-time, for a range of suspects, from violent felons to visitors who overstay their visas. According to Bill Schrier, a 30-year veteran of government technology and the former chief information officer at the Seattle Police Department, once the technology has advanced enough, fusing face recognition with body cameras would likely be permissible for a wider range of wanted suspects than murderers. “Most reasonable people don’t want potentially dangerous felons or sex offenders walking around in public and would, I think, support such use” in those cases. But facial recognition, he says, should not be used to catch people wanted for “misdemeanors such as unpaid traffic tickets or pot smoking.” More extensive use would “seriously undermine faith in government, and start us down the road to a police state.” Smith agrees with civil libertarians that the privacy questions surrounding video analytics “need to be answered.” In an email, Tuttle, the Taser vice president, told me, “We are committed to engaging with our customers, communities, and thought leaders in the privacy space to ensure the application of analytics to body-worn cameras is executed in a clear, open, ethical, and transparent manner.” Still, Smith is quick to defend video analytics as part of a inevitable push by law enforcement towards “big data” and so-called predictive policing—one that will become ever more irresistible as torrents of footage and data pile up.

In that context, Smith argues, bans against face recognition software would be unproductive. “As that technology becomes more widespread, it’s helpful to think in terms of how they’re going to be deployed, rather than, ‘I don’t want to do it.'” Some uses for facial recognition on body cameras “would be noncontroversial,” like a missing persons search, an Amber Alert, or a dangerous fugitive, says Jake Laperruque, a privacy fellow at The Constitution Project, a Washington, D.C.-based think tank that compiles bipartisan proposals on civil liberties issues. “But at the same time you have to prevent some of those Orwellian-style abuses that can be very real in terms of what’s capable in the near future—you have to have hard rules and limits.” According to a December report Laperruque coauthored with civil rights advocates and former law enforcement officials, the privacy risks of video “tagging” technologies “are immense.” Amid a massive tech upgrade meant to improve accountability, body cameras are being limited by police policies and privacy concerns. Scanning, storing, and analyzing the face of an unknown suspect after a police stop—an increasingly common practice—is one legal issue, but scanning those of passersby without stopping them is another. Shahid Buttar, a constitutional lawyer at the Electronic Frontier Foundation, has warned that constant video footage from body-worn cameras could enhance the ability of the police to monitor anyone who passes in front of a camera lens “without the individual basis for suspicion constitutionally required to justify a police search.” In essence, simply walking past a police officer could legally become an encounter. Similarly, searching a crowd for active terror suspects might be considered acceptable, but tracking individuals at, say, a protest, would violate U.S. constitutional rights. “That’s where some of the most worrisome aspects come in,” says Laperruque. “An officer comes in having monitored a protest, or a surveillance unit standing outside a mosque, they turn in the body camera, they log the footage; on that stored footage every person who appears on it has a faceprint.” That, he says, “is a type of pervasive surveillance, not only just of legitimate and non-illicit activities, but also activities that are the bedrock of the First Amendment.”

In May, the U.S. Government Accountability Office said the FBI needs to “better ensure privacy and accuracy” in its implementation of facial recognition. The concern isn’t an idle one. Laperruque points to the New York Police Department (NYPD) surveillance program that targeted Muslims, which ended in 2014. (In November, a judge rejected a settlement of a lawsuit against the NYPD over the program, on the grounds that it didn’t provide enough oversight of the department.) Last year, emails obtained by Vice News showed that the Department of Homeland Security monitored the activities of prominent Black Lives Matter organizers and “constructed a geospatial map to follow the protests,” motivated by concern “about potential ‘anarchist violence.’” Real-time face recognition could also make officers more aggressive toward certain suspects, argues Andrew G. Ferguson, a law professor at the University of the District of Columbia. “Body-worn cameras with facial recognition technology will alter police tactics,” he told Motherboard. “It, like much of the impact of big data policing, will encourage more aggressive conduct with suspects with prior records or histories of violence, and likely encourage less aggressive interactions with people without prior criminal conduct.” So far, facial recognition has raised alarms not just for its ability to recognize people’s faces but for its inability: The faces of certain races and ethnic groups have proved difficult for some facial recognition algorithms, raising the risk of false positives that reinscribe existing biases in the criminal justice system. In a report published in May, the U.S. Government Accountability Office said the FBI needs to “better ensure privacy and accuracy” in its implementation of facial recognition technology. Since 2010, the agency’s Criminal Justice Information Services Division has spent an estimated $55 million on developing face recognition systems to assist the work of a full-time staff of human image examiners. Amid global security concerns, face recognition technology is advancing quickly, and many see its use with body cameras as a matter of not if but when. At a gathering of security professionals at the Biometrics Institute Asia Pacific Conference last May, 63% of those surveyed said that enabling law enforcement and security officers to identify known or suspected criminals or terrorists is the most appropriate use for biometrics in wearable video cameras. Meanwhile, some in the biometrics industry have cultivated close ties to the Trump administration: Michael Dougherty, a Trump official who handled the Homeland Security Department transition, previously lobbied policymakers as the president of the Secure Identity & Biometrics Association. Lora Ries, another transition team member, is a former lobbyist for a facial recognition firm. Another, John Sanders, sits on the board of Evolv, a security firm that markets a technology that combines surveillance footage, facial recognition, and other data. Trump’s controversial travel ban called for, among other things, the swift completion of a “biometric entry-exit tracking system” for all visitors to the U.S.

For those in the U.S., there are currently no federal laws governing how facial recognition is used by law enforcement, and little public discussion about it. A few departments have sought to sought to be more transparent, including Seattle, New Hampshire, and the Parker, Colorado Police Department, which have sought to be more public and have embraced input from civil rights groups. But many large departments do not publicly disclose their use of surveillance technologies like facial recognition. This week, for instance, lawmakers in New York City introduced a bill requiring the police to disclose what surveillance technologies it is using and how it is guarding against “constitutional” risks. At a news conference on Wednesday, Police Commissioner James O’Neill sharply criticized the effort, citing security concerns. “This bill would not be helpful to anyone in New York City,” he said. At Taser, automatically tagging and analyzing body camera footage fits with one of Smith’s bigger ambitions: to upgrade the aging systems that police use for records management, and eventually, to use algorithms to automate record keeping and do away with “the notepads and sticky paper” of police work. Bureaucratic tasks and paperwork take up an inordinate amount of police officers’ time, says Smith. Enter the body camera. “If you’ve got a sensor recording everything, there’s no need to sit down and write about it.” “I think being a police officer in 10 years should feel sort of organic, where the technology is supporting the officer when they’re out on patrol, and they’re automatically getting alerts about information that they need to know, and all the information that they’re gathering can be categorized and organized behind the scenes, so they don’t have to spend their time doing bureaucracy,” he says. “It’s a technology ecosystem in which we hope to play a big role.” Smith describes the company’s smartphone apps as a step toward that future, allowing officers to share evidence like photos, videos, and other data from their phones—a major advance on a clunky system that currently relies on in-car computers, CD-ROMs, and text messages. Taser’s shift from weapons to cameras to services is reflected in its growing Seattle-based body camera division, Axon: Last quarter, Axon revenues grew 154% year-on-year, compared with 25% for the weapons business. Smith sees an opportunity to develop a central nervous system for all of this police data, one that integrates with and improves upon aging approaches to police records. The vision is bigger than weapons, cameras, or apps: Taser wants to build an ecosystem for all police data, aimed at making police work more efficient and effective. “Think of it as the iTunes of police,” Smith says.

Doyle, the law enforcement adviser at Unisys, which sells its own systems for analyzing video and housing police data, agrees that digitizing policing could free up more officers to engage with the communities they serve. “For general crime, prevention used to be where we put all our money,” he says. “We got far away from that. We spend much too much time in the station house, pushing buttons and pushing paper. Technology can help us get back to preventability.” But Narayan of the ACLU worries that new technologies and growing piles of data could also draw valuable resources and attention away from other efforts at improving police-community relations, and from policing in general. “Work on police reform, building community-police trust, training, culture change—all of that stuff is absolutely critical,” he said. But “equipping enforcement with the newest technology doesn’t necessarily help communities be safer or be freer.” Find Alex Pasternack on Twitter or reach him by email.|||

Upgrades like face matching, live streams, and AI–part of an industry push–raise concerns about surveillance and the use of police video.