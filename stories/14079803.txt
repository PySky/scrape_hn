I have been a Linux user since about 15 years now, yet I still feel that many Linux problems that I’ve encountered are still present. I feel also that energy is put in the wrong places instead of investing in what may be better for the Linux and FLOSS community. Through this post, I will make small resume of what may be lacking and what should be fixed.

(Dustin Kirkland collected many ubuntu problems I experienced them myself http://blog.dustinkirkland.com/2017/04/thank-you-note-to-hackernews.html This is an article about what else still missing)``

The performance of the system:

When using an operating system, everyone wants it to be reactive, use minimum resources, don’t annoy you with random bugs and, also, be easy to use for novices while allowing advanced manipulations for experts. Linux can fulfill most of these needs. It can be very optimized, it can boot very fast, and we can find it running on the small integrated devices to the large data centers.

The graphical part in Linux is another story, even if the new X.org is a lot different from the old one, many old concepts are still here and that’s why Wayland appeared.

You may not see the problems of X until you want more security, an exotic device or feature support (force sensing multi-touch controls, external usb-c GPUs), or when you want to get good performance on some embedded devices like a Raspberry Pi.

Wayland is still getting into shape and may fix a large part of a Linux system. It is also made to get the most of your computer and simplify adding new features mostly related to the graphics, without having to go through a failure in another part of the system for unknown reasons.

Environment and ease of use:

Linux is mostly developed by pure developers with very very few people to collect users' needs. In the best case, users needs will be in the form of feature requests but not as a full experience scenario.

There is a job which called in french “Assistance à la maîtrise d’ouvrage AMOA/MOE”, (sorry I couldn’t find a matching job title in english. A "product owner" maybe?). One of the goals of the AMOA manager is to define the goals of a project, the experience of use and verify if they are well executed during the full use of the product.

People who do this are not coming from design schools (UX designers), development schools/universities (developers) nor business school (managers, MBA) but a some sort of a mix between them. This process prevents having products full of features no one uses, or inconsistencies in completing a task by a normal user.

Let’s take an example:

“A user is in a company with many computers. He wants from time to time to send a file to another one in the same network.”

An AMOA takes this need, and writes a document of how this should be done:

“In the file explorer “Nautilus” there is a new tab called FileDrop, if a user wants to send a file to someone in the same network, he does a drag into that tab ; a view containing the list of connected computers appears and then he drops the file into the target computer. The receiver gets a notification whether or not he accept the file.”

The manager takes this scenario, and gives tasks to developers to modify nautilus code, wireless driver code, daemon which waits for incoming files etc.

AFAIK (and I hope I am wrong), there is no position in Canonical or RedHat which bridges the gap between usage scenarios and managers/developers and which targets the Desktop environment.

Imagine what can be fixed in the Linux Desktop just by having someone who analyses usage scenarios. At least we won’t have mysterious system errors pop-ups like these:

Linux is the operating system (well, only the kernel I know), but you need also applications to do something right? Believe it or not, many famous projects like LibreOffice or Inkscape or Gimp don’t have direct funding from companies who include them in the distributions. Google may fund them more through Google Summer of Code projects (~5000$ per accepted idea per project). This doesn’t mean that developers from these companies don’t contribute to these projects from time to time or some lead developer of these projects are also a RedHat/Canonical employee.

Applications themselves have sometimes very bad design choices, Gimp developers don’t want to update Gimp to a more usable user interface with a single window until recently, has tons of features no one was aware of (like the content-aware fill feature, a plugin made it available for gimp 2 years before Photoshop showed its own), inkscape plugin system don’t allow easy interaction between the plugin and the application, LibreOffice performances are very low (some years ago, LibreOffice impress crashed by a tiny 4KB png image I used as a background pattern).

Things are changing, LibreOffice moved to cairo rendering, but cairo itself is now an outdated technology according to the new rendering techniques using the GPU (2015+).

To render those fancy OpenGL transitions I’ve seen in the last FOSDEM in Brussels, LibreOffice Impress renders to a raster image using cairo (CPU) which is then transmitted to the GPU as a texture and then you got your fancy transition after a small freeze at each slide. Why not use the GPU directly for everything? Cairo rendering doesn’t do that and there is not a single developer working on it at this moment.

To compare with recent GPU accelerated rendering algorithms, this is a 1273 pages pdf with 2.7 million glyphs working right in your browser with no freezes. (Careful if you have a very old computer, 60+ MB download):

Why evince the default pdf viewer for Linux can't render a PDF with similar performance while a javascript code inside a chrome tab can do it through WebGL?

Tools like LibreOffice, Inkscape, or others have missed the internet 2.0 era which could have boosted their development at many orders of magnitude.

When using LibreOffice or Inkscape you need from time to time to use fonts, templates, backgrounds for Impress, textures, etc.. Should LibreOffice or inkscape developers create them? Of course Not! Every successful platform doesn’t have its developers do everything, but other people do it for them. Android Play Store, Apple AppStore etc. Now, this applies even to single applications. They allow designers to expose templates or any other artwork either for free or for a price and everybody is winning here. Don’t forget, those designers should upload their artwork using a simple interface, not after installing svn, git, touching pure code, compiling...

Canonical recently stated that it will focus on IoT and Cloud either than Unity8 and Phone. This is a very wise but tough decision that should have been done some years ago (after missing the first deadlines). When Canonical wanted to enter the mobile area, it may thought that many pieces are already developed and things should be easy. At that time, Wayland was still at its beginning and X11 was not a way to go mobile (Android uses the Linux Kernel only, the graphical part and upward is something else). Wayland didn’t have a specific focus on mobile (or convergence) and Canonical wanted to move fast so Mir was created and developed until the recent shutdown.

Now that Mir and Unity8 are dead, and the mobile landscape is crowded with no more place for anyone else except Apple and Google. Canonical made a wise decision to work on IoT before it gets crowded and secure a bigger place in the Cloud.

So in my humble opinion, FLOSS companies should take into consideration what the situation would be in the future before taking decisions. A wise decision now is not after 3 years and after discovering that the development is taking very long.

Focus on the development should be put into what may be the winning technology in 5 years from now, and where there still more room for a new player. In 2 years there may be no room even for regular smartphones except with big foldable screens becoming tablets or with augmented reality glasses.

FLOSS software should fix their current problems which are more related to defining the goals other than just pure development. Search for what it may put them in a leading position instead of just catching up on what other companies have already conquered and secured. IoT is still an open place for newcomers, Linux for IoT doesn’t have the problems as Linux for mobile (battery, graphics drivers, applications, performance, user base, ...).

So what to do now ?

Maybe Artificial Intelligence? The deep learning revolution has started since 2012, Google as an example bought Deepmind just 2 years later. Linux companies should always keep an eye on what’s happening in scientific conferences to know if there is something they can take quickly from research and use it in a product. Facial recognition, Speech recognition, Text-to-Speech and Virtual assistants are now easy to create for a company as the new research is here to explain how to do it. Linux should take a part in the Artificial Intelligence revolution while there is still a place. This also needs collecting a lot of user data, but that’s a topic for another upcoming article.|||

