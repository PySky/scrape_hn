In this example we will build a predictive model to predict house price (price is a number from some defined range, so it will be regression task). For example, you want to sell a house and you don’t know the price which you can take — it can’t be too low or too high. To find house price you usually try to find similar properties in your neighborhood and based on gathered data you will try to assess your house price. We will do something similar, but with Machine Learning methods! OK, let’s start! We will use Boston Housing dataset, which you can download from here. However, I made one trick on original dataset for you, which help you understand ML better, I splitted it into train and test samples — you can get is from my github. We will use train samples (data_train.csv file) for model learning and test samples (data_test.csv) for predictions. I divided data into two sets to show you how you can use trained model — for predicting the unknown. If you are interested in the meaning of each column in data, you can check it here. For model training we will use MLJAR, because it has easy web interface (if you don’t have an account, please signup and get free credits for start). Let’s start a new project. Make sure that you select Regression as a task. It is important, because different algorithms are used for regression and different for classification.

OK, please add train and test datasets. During adding test dataset it is important to tick that: This dataset will be used only for predictions (we will not use true SalesPrice from this dataset, we will predict it!).

After that, we need to specify columns usage. MLJAR trys to guess which column it should use. Please set ‘Target’ as column usage for SalePrice for train dataset. For test dataset please set ‘Dont use it’ as column usage for SalePrice. For each dataset we need to ‘Accept attribute usage’ at the top.

We are ready to define ML experiment. As input we will use ‘train’ data. Please left preprocessing as default. For learning algorithm we will use Extreme Gradient Boosting (xgboost) — it is super powerful, you will see! In tuning details, please select metric to be optimized: Root Mean Square Error. And click Start!

Wow! But wait, what is Root Mean Square Error (RMSE), why I need this? Good question. During training phase your model wants to predict values as similar as possible to target values. To track how good it is doing we need some measure — it is called cost function. In our example, for cost function we selected RMSE. When we go into Result page, we will see a lot of models and each of them has different RMSE value (Score column).

Is it ok? that we use one algorithm and it produces different scores? Absolutely, because when you click on each algorithm you will observe that they have different parameters — the so-called hyper-parameters. So with different algorithm parameters you end up with different models. That’s why MLJAR checks for you many different parameters and you obtain the best model (the most useful). The best model in our case, will be a model with the lowest score — so please sort models by clicking on the column. We trained a set of model, selected the best one. So what? We need to use our model! That’s why I left test samples, to show you how to use trained model. In our test datasets there are true values but we will not use them, let’s assume that they don’t exist. So we have 100 houses in our test data and we want to know price for them. To compute predictions please go to Predict view. There are 4 steps there to get predictions: Step 1 — please select dataset that you want to use as input, in our case it is ‘test’. Step 2 — please select algorithm that you want to use for computing predictions, in our case we will use algorithm with the smallest score value. Step 4 — please wait a while for predictions and download the file with model responses.

Fantastic! You have just used ML model, so it is good time to compare predicted prices, with the true one — this can be done, because we have true SalePrice in test set, in real life, we don’t have such values, thus predictions can be checked only manually (somehow). OK, let’s compare them visually. In one column there is model’s prediction and ‘SalePrice’ is a true value, in the picture are presented first few data samples (houses). You can see that, in some cases prediction is very accurate. For example for house with Id=1, the true price is 208500$ and the predicted value is 208352$, so the difference of only 148$ on over 200k$ property— quite good! However, there are also houses which predicted value is few thousand wrong. Don’t worry about this. This is common in ML that model sometimes goes wrong. There might be many reasons why: not enough data — too few samples to generalize well on the data messy data — very often there are mistakes in the data problem with model — too simple or too complex model That’s why computing cost function is important to measure how accurate are our predictions.|||

Are you going to sell your house and you want to know what it the right price for it? We will guess the house price with ML — how? Please read :) In the last post you learn some basic terms from ML…