##Goal: Train a RNN (Recurrent Neural Network) to generate valid HTML and CSS templates for websites based on character by character training. ##Sample Sites: http://149.56.108.43/RNN/main/

I was inspired to try this by: https://www.youtube.com/watch?v=iX5V1WpxxkY&t=2881s

Excellent course for neural nets in general.

##Idea behind RNN: Unlike a vanilla neural net that takes a input vector and returns an output vector, a RNN feeds the output vector back upon itself to minimize a cost function across multiple training examples.

Learn more by starting here: http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/

This sums up the basic idea:

Note the "post-input training inputs" from the layers output aka unfolding as refered to in above article.

##Traning Data Gathered ~5000 html website templates from http://www.free-css.com/ and another template site (I can't find again as I write this) via script (mostly curl). Had to be a little tricky with http://www.free-css.com/ as downloads are redirected by javascript link. Avoided this by breaking out a bash loop and opening chrome tabs and killing processes post javascript.

HTML and CSS was stripped from directories, appended with a tagger marker and concatenated into one training file. Once concatencated all non-ascii characters were stripped out.

I trained on AWS p2.xlarge instances with GPUs (NVIDIA K80 GPUs). Even with the GPUs I had to break full ~5000 website dataset into half to complete training in a reasonble amount of time (~6 hours per model). I had one model for HTML and one for CSS.

Used AMI image: ami-c79b7eac (See https://github.com/brotchie/torch-ubuntu-gpu-ec2-install) Also install dependencies specified by torch-rnn

##Post-Processing #HTML Doc Cutting For each template I generated more text than was generally in a html file and cut the file to proper length based on appened starting tag, "".

#CSS Insertion I wanted to be sure that all the generated templates were able to reference a CSS file for styling, thus post generation I inserted a CSS style link into each document. I also drop references to css/style.css as not to cause conflicts.

#Image Insertion The generated HTML/CSS had vaild img tags and used past image links to generate "image like links" but they would not be able to link to any actully images. I went through and replaced each link with a link to a vaild image randomly pulled from the training set images.

#Commenting The AI tended not to close comments which lead the HTML/CSS to not display at all after the failure to close. I stripped out comments to prevent this.

#Single Quote Replacement The AI tended to not close quotes properly which lead to following HTML to be unusable. Replaceing all single quotes with double quotes greatly eliminated this.

#HTML Min Length The AI somethings produces very short HTML files. Anything less then 1200 chars is discarded.

##Results After training for 50 Epoch the rnn can produce mostly vaild html and css. The style is older and looks dated. I am unsure if this is due to the training set or because it can only pick up on simpler patterns. See Sample for two complete templates.

Scale network to 512 neurons per layer and 3 layers to capture more subtle features

Write Script to insure closure of script tags (real issue now with rendering)|||

Contribute to HTMLAI-RNN development by creating an account on GitHub.