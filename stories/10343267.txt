Sun Microsystems introduced containers more than ten years ago, but containers have recently become the hottest trend in data center virtualization. Ten years ago, hypervisor based virtualization, especially VMware, was being rapidly adopted by IT customers and Linux was encroaching on UNIX distributions from Sun, IBM and other vendors. In the past two years, Google’s Container Engine and the Kubernetes project have brought containers into sharp focus. Google has experience building and running container-based distributed systems in its own data centers.

Virtual machines simulate physical computers using software. A VM can run any operating system and the same physical server can run VMs with different OS’s at the same time. Physical resources (CPU, RAM, storage and network) can be explicitly allocated to VMs. VMs are ideal for consolidating legacy applications that run on disparate OS’s onto a smaller number of physical servers.

Containers are a lighter, faster and more flexible type of virtualization. Containers use operating system-level virtualization where applications are isolated in terms of configuration and dependencies but share the same OS kernel. Containers avoid the overhead of running full operating system instances. Containers, which can boot in less than one second, have almost no performance overhead and consume less storage compared to VMs.

While VMs are suited to supporting a wide range of legacy applications, containers are ideal for new applications where all components can run on the same OS. Vendors of container solutions are heavily focused on application development. Docker, in particular, emphasizes the use of containers to create standard units for software development, including everything needed for an application (source code, runtime binaries, libraries, etc.). Docker provides tools to build, locate, ship and run containerized applications and provides a REST API to manage containers. Obviously, dominance in application development environments today may lead to dominance in production environments tomorrow.

Applications today are being written in a service oriented way. One of the main challenges for modern development environments, where there can be any number of microservices, is resolving service dependencies. Containers can be used as a way of packaging and transporting application environments, including their dependencies. Otto, Mitchell Hashimoto’s successor to Vagrant, for example, provides a way of describing application dependencies and microservices. An industry standard dependency description language for containers could be a logical next step.

CoreOS, which integrates with Docker, is a production-oriented server operating system where all applications run in containers. Inspired by The Datacenter as a Computer, CoreOS uses Linux kernel control groups (cgroups) to provide resource management (CPU, memory, disk I/O and network I/O). In order to make full use of hardware, there is a need to schedule applications on a cluster of physical servers. CoreOS provides cluster management with Fleet, which treats a CoreOS cluster as a single system. Based on the Apache Mesos project, Mesosphere Datacenter Operating System (DCOS) also organizes groups of physical servers as a single logical computer.

A historical area of concern for production use of containers on Linux has been security isolation. Each container has a file system, a network stack and process space but, in theory, a kernel exploit originating in a container can allow arbitrary code to run on the host. It is possible to run containers as unprivileged users, but they cannot access hardware directly. Joyent Triton claims to provide a more secure solution for production containers because it is derived from Sun’s Solaris operating system via OpenSolaris and SmartOS. In addition to being more secure, SmartOS provides Zones (originally another term for Solaris Containers) and supports the ZFS filesystem, as well as DTrace, which is a dynamic troubleshooting and analysis tool first introduced in Solaris 10. Joyent Triton runs Ubuntu, CentOS and SmartOS containers and, like CoreOS and Mesosphere, integrates with Docker.

The performance of applications running in VMs or in containers depends heavily on the ability of the storage solution to deliver IOPS, bandwidth and low latency. IT customers are familiar with the fact that consolidating workloads using hypervisor-based virtualization concentrates disk I/O on a small number of physical servers. Containers enable higher workload density than VMs and can concentrate disk I/O even more. Since hardware resources are not generally pre-allocated to containers, container performance can become unpredictable due to the I/O blender effect, as well as to the noisy neighbor problem.

Flocker by ClusterHQ directly attacks the storage provisioning and management problem. Cloud deployments avoid single points of failure, which rules out traditional SAN and NAS storage systems, which are typically used with VMs. Flocker is a container data management system that allows the use of local storage but also enables portability. Flocker moves storage assets together with associated containers and integrates with software defined storage solutions, such as Hedvig to enable important features like QoS.

Software defined networking and network orchestration are requirements for the production use of containers. Weave, for example, is a virtual Layer 2 Ethernet switch for containers developed by Weaveworks. CoreOS Flannel implements a private mesh network between nodes within a cluster. Docker’s SDN plugin connects containers to virtual networks across any number of machines and maintains the visibility of containers on the network if they are moved across hosts. Integration of networking with container orchestration frameworks is a developing area.

The container orchestration picture is fragmented. No single solution or vendor covers container management, cluster management, scheduling, service discovery, dependency resolution and management of CPU, RAM, storage and networking. Various combinations are possible, such as Docker on CoreOS with Flocker and Weave, but there is no standard. Docker has critical mass in terms of its community and in terms of containerized application images available through Docker hubs. Kubernetes is specifically an open source orchestration system for Docker containers, but there are other contenders in container orchestration.

VM orchestration frameworks, such as OpenStack, are embracing containers alongside VMs. OpenStack, which manages the entire hardware infrastructure of a cloud deployment up to the virtual machine, can also host containers, e.g., OpenStack integrates with Docker. Since OpenStack manages compute, storage and networking, companies working in these areas as extensions of container management solutions are implicitly competing with OpenStack.

Despite being known primarily for hypervisor based virtualization, VMware’s introduction of Photon, an opensource Linux distribution optimized for containers, and of Lightwave, a container identity and access management technology, show that the company intends to compete in the container space. Pivotal, which is a spin-out and joint venture of EMC Corporation and of its subsidiary VMware, uses containers in its Cloud Foundry based products and solutions. The IBM Bluemix PaaS solution, for example, is based on Cloud Foundry. VMware, Pivotal and IBM (along with Google, Docker, CoreOS, Joyent, Mesosphere, Weaveworks and others) are supporters of the Cloud Native Computing Foundation. The CNCF could play an important role in establishing standards related to containers in the future.

In 2007, I described virtualization as a consequence of Moore’s Law. The promise of hypervisor based virtualization was to reduce hardware footprints as processor core density continued to increase, as well as to enable higher average server utilization. But many IT customers have struggled to realize net cost reductions after migrating to hypervisor-based virtualization. Containers allow more efficient use of hardware compared to VMs. Unlike VMs, the server and storage hardware infrastructure for container deployments is typically commodity hardware. Since the capital and operating expenses of container based development and deployment are lower, the eventual dominance of containers is inevitable.

[All trademarks and registered trademarks are the property of their respective owners.]|||

