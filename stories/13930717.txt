For a lot of us, automated data processing is often done by transforming and summarizing data that either starts in a spreadsheet or is going to wind up in a spreadsheet.

This notebook is a tutorial on CSV file processing in Python. It doesn't cover the details of installing Python or Jupyter notebooks. You'll have to find that separately. Look at Intro to Python CSV Processing for Actual Beginners for details.

Ideally, you've got your own Jupyter Notebook page running. You can follow along here, and create a notebook that reads and writes CSV files.

What we want to do is read a CSV file, do transformations on the data, and write new CSV output. In order to do that, we'll need a file.

Here's a few lines of data you can copy and paste into a text file.

With this file, you can follow along nicely. The sample data I started with was even larger, but this seems like enough data to get started with.

To get a file from outside Python to inside Python there's a two-step dance.

We'll wrap all of this into a context that makes sure that the OS resources are quietly released when we're done using them.

It looks like this:

The function takes a filename as an argument. It makes all the necessary OS connections to read the data. We've wrapped this in a with statement to create a processing context and save the working file object in a variable named input_file.

The body of the with statement is indented. This touches on two important details of syntax in Python.

Inside the with context we used to perform the method of the object. There's a dot to connect the object name with its method name. There are 's in case we want to provide any argument values. This method will slurp up all the data from the external file. The resulting text is used to create another variable, data.

The screen shot includes In [4]:. Because there's a number in the []'s, it means I clicked to run the block of code. Your number may not be 4. You can try different things, also. Play around. You can't hurt anything.

"Okay," you say. "How do I see what happened?"

Good question. To see the value of the data variable, it's a really small line of code. Like this:

We wrote a really short expression (one word: ) to see the value of the object named data. I clicked to run the tiny little block of code. And there it is. Text. Lots of it.

"What's that ?" you might ask.

That's the Linux line-ending character. Some tools will show each line separately. Text editors are good at this. Some tools just show the characters. If you look at the page where you originally built the file, the characters don't clutter up the display. They're there. The editor is clever about using them to format the output.

The function creates prettier output. The characters are used to format the output for us.

The object is just a big pile of text. It's awkwardly large. We'd rather have each line as a separate little piece of information.

We want to iterate through the lines of data. We'll use Python's for statement to do this. Think of this as meaning "for all" because it handles all of the items in a sequence one at a time.

The with-statement context should look familiar.

The for statement consumes each individual line of text from the object. One at a time, each line is assigned to the variable, then, the indented statement(s) are executed. In this case, there's only one indented statement, the function.

Hint. We can indent many statements to do many things for each line of data.

Another Hint. Statements must be complete on a single line.

What we need to do now is decompose the data into the original CSV columns. For that, we'll need some help.

Here's some additional software that we'll need to parse the columns of data properly:

Command number 8 will introduce a library module into our working environment. The module is named csv and it has classes and functions that parse CSV-format files.

In a script file, we try to organize all the imports so that they're near the front of the file. In the Jupyter notebook, this isn't really required.

We'll use the function to create an object that will iterate through columns of data instead of simple, unstructured text.

Here's the code we'll need:

This is starting to look pretty complex. This is a nested set of Russian matryoshka dolls.

The reader is built using the function. We provide an open file, and we get back an object that iterates through data that is properly decomposed into rows and columns.

The for statement uses the iterable assigned to the variable. Each individual row of data is assigned to the variable. When we printed them, we saw each row is now surrounded by 's.

What does this syntax mean?

It means that we have a sequence of items. When reading CSV files, each data item is an individually quoted string value, separated by commas. Other kinds of data are possible here, but we're going to stick with CSV reading; that tends to impose some restrictions.

We can work with an individual column using syntax like to refer to the second column, the size.

Let's play around with a single row for second. Here's how indexing works to pick a specific item from a sequence of items:

When we use we get the first item from the sequence. When we use we get the fourth item.

Here's a way to leverage picking things apart like this. Let's interleave some literal text with the values we read from the CSV file:

What have we done?

Note the very first line of output.

The headings aren't too helpful. We'd like to ignore them.

The heading line isn't helping us much, is it?

We can filter that out by using the if statement. We can create a condition expression and provide some processing to be used only when that condition is true.

A condition can be computed using any of the available comparison operators. We'll show an example using "==", but there are all of the usual culprits: >, <, <=, >= and !=. (Your keyboard has characters like ≤, ≥, and ≠; Python doesn't use these right now.)

Note. We use to mean "test for being equal." We use to mean assign a value to a variable. is a question. is a statement of something to do.

The condition we're interested in is when . That's a heading line. The extra processing we'd like to do is skip that line.

We've written a condition of . If this condition is true, we'd like to continue the for processing, ignoring all the rest of the statements in the indented body. We've rejected the line with in column 1. All the other lines pass through and get printed.

It's a pain in the neck to work with the file sizes as strings of characters. A number is more useful. Python has a variety of functions to make string values into useful numbers. We'll look at , but there's also , and even .

Since an actual number looks like a string of characters, it's a little hard to see exactly what's going on. First, we'll format the output. Then we'll see how numbers work with this.

We'll use a expression to do the fancy formatting. The template is a string with place-holders. The values are interpolated into the replaement fields in the string. Here's the example:

We've made a dramatic change to the statement. Instead of printing a bunch of items, we've formatted a string and printed that. The formatting operation starts with a template; the values are interpolated into that template.

The template is this string object . More on the details in a second.

The template string has a method, that does the interpolation work and creates a new output string.

When we provide values to the method, the 's in the template are replaced. There are a bunch of replacement field rules. We've used just a few variations.

Here's the overall pattern for a replacement field:

The field names are all omitted. Without names, the argument values are used in the order they're provided.

If we provide names, it's common to see fields identified by position. We might say to select field in position 1 to be interpolated here in the string.

The format specifications are mostly a number (which is the number of positions to use) and to insert a string value into the output.

We've spread the name out by using to take up at least 48 positions. For the size, the uses at least 9 positions. The date and time don't change size, so we just used rather than count up the characters. We even injected a literal "T" into the output. It looks more ISO-official, doesn't it?

Now let's make two more changes. We want to convert the size to a proper number object. Then we can do math on it, like divide by 1024 to convert to kilobytes (kb) or divide by to get megabytes (mb).

When we switch to a number, we'll also have to change the formatting to properly display that number.

What's changed? We've computed a new variable, , using the expression . The function will convert its argument value to an integer. No matter what the argument is: floating-point value, complex number, fraction, string. Almost anything.

We changed the format specification to . This has a size, . It has a to insert commas into big numbers. And it has a data type of for decimal. Finally, we have changed the argument list to be . We've used the integer variable instead of the old string value of the expression.

How cool is that? We now have right-aligned numbers, with commas! All we did was convert string to integer, and then use the proper formatting options.

Strings can be compared for equality. However, they can't be summed to compute an overall size. And when we compare two strings, we'll see an something that might be astonishing.

This is the lexical ordering issue. The string values are sorted into alphabetical order. comes before alphabetically.

On the other hand, the integers are sorted into the expected numeric order: 11 is greater than 2.

This is why we want to convert the string to a number.

We'll need to to the same thing for the date and time value.

To make this more useful, we need to convert the date and time strings into something we can compare, also. This is a little more tricky than integer conversion because of the variety of ways days and times can be formatted.

First, we'll need to use the datetime module. This has all the tools needed for working with dates and times in all of their glorious inconsistent formats.

The general approach to handling datetime is this:

The reason we want to do this is to simplify comparing two files modification times. If we keep dates separate from times, it's hard to put these three times into order:

With some thinking, we can get them into order. Mentally, we have to check dates as well as times to get the order correct. Creating a combined object makes that concept into a concrete combined time-stamp value.

Here's some little examples of how the three step conversion works.

We've defined a date that looks like dates in our CSV file: year-month-day and put that into a variable, .

We've used a function with the improbably long name of to do string parsing of time ("string parse time"). We provide the string data and a template for understanding the string. The template uses for 4-digit years, for a month number, and for day of the month.

The result is an object which includes the parsed date. We use the method to extract just the date from that object. (Think of the object the comes back as a kind of buffet table of information. We don't want the whole table.)

The Out[20] line shows the Python understanding. It's a object, with the given year, month, and day. Success!

We've defined a time that looks like dates in our CSV file: hour:minute:second and put that into a variable, .

We've use the function to do string parsing of time. We provide the string and we provide a template for understanding the string. The template uses for hours, for minutes, and for seconds.

The result is an object which includes the parsed time. We use the method to extract just the time from that object.

The Out[21] line shows the Python understanding. It's a object, with the given hour, minute, and second. Success!

Here's how we can parse and combine:

We've shown the two functions to create the date portion and the time portion of the overall datetime object. Then we used the function to assemble a complete datetime object from the pieces.

This parallels the way we converted size from string to integer. Okay. It's a lot longer. But it follows the essential template. We can define a new function to handle this. But that's for a later presentation. For now, we'll focus on extracting useful data from the CSV file.

We've extracted a date and assigned it to the variable. This is computed from , using the expected date format. We've extracted a time and assigned it to the variable. This comes from . We combined these to a single datetime object, and called this .

We've also changed the format template. To format the datetime object we've used . This applies that datetime's internal formatting rule to the data. This rule provides Linux-like date-time values.

We've turned the string of digits into an integer that we can work with. We've turned two strings of digits and punctuation into a single datetime object that we can work with.

Now that we have usable data, what are some things we can do?

Filter by size? for example, finds files over 1M. We can use to find files under 500K.

Filter by date? will find files modified after the start of 2016.

Within a date range? finds files modified within the confines of 2016.

"Why can't I use commas in the numbers?" It's difficult for programming languages to deal with too much punctuation. You can use _'s in the numbers. will work in Python 3.6. It won't work in older Python variants.

"Why are the dates so complex?" We can use slightly more clever imports to make the dates slightly simpler. Instead of simply using , we can use to make the names shorter. I'm not sure this is the best way to learn, however, so I suggest sticking with the full, formal name for a while.

Here's the other side of the coin. We read a CSV file. Now we want to write a CSV file. Maybe with a subset of file names. Maybe with the dates cleaned up. This is similar to reading a CSV file.

Here's the template for reading and writing CSV files.

We've expanded the with context to include two open files.

Indented inside this with statement is the processing we want to do on our two open files. There are four steps.

When the for statement is done, the with statement is also done. The files are properly closed and turned over to the OS.

This demo shows the basics of getting data from a CSV file, doing mappings from the input data to more useful internal data. It shows how to filter lines in a really simple way (by rejecting them.) And it shows how to write the resulting file.|||

introduction-python-csv - Introduction to using Python to process CSV files.