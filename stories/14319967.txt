One of the great things about Python is how easy it is to hit the ground running. The standard library is vast, and for every common problem people have, someone has written and published a library that you can download and install with  . Often there is one right way to do things. Want to make HTTP requests?  . Want a database adapter, ORM, and migration system (but not using Django or some other integrated framework)? Use  and  . And so on…

But when it comes to even the simplest kind of caching, I see code like this everywhere:

What’s going on here? We’ve got five lines devoted to the grunt work of caching and one line devoted to the actual thing we want to do. How could we improve this?

If you really inspect those lines, there are three things you need to know:

1. The function I want to cache is:

2. The cache backend I want to use to do it is:

3. The value of the function only changes when  changes

Two years ago, I wrote quickcache so that I could cache functions the way I wanted to. With quickcache, the above looks like this:

The first parameter to  is a list of names of arguments to vary on, and you can use intuitive –notation to access those arguments’ properties as well.

Now, I should point out, I wrote this with Django’s   library in mind, but you can use any backend as long as it is wrapped to present a very simple interface:

There’s often a tradeoff between caching in process memory and caching in a shared cache like memcached or redis. If you store it in process memory, then it is blazing fast to retrieve again in the same process, but on a multi-worker web service, for example, other forked processes would not get the same benefit. If you store it in a shared cache, then other processes can benefit from it, but if you access it multiple times in short succession, for example within the same web request, then each time requires a round trip to memcached/redis, which adds up in a way that caching in local memory doesn’t.

Why not use both?

At Dimagi, that is what we do, and    supports a special configuration that makes this easy with Django out of the box, and some simple tools you can use to replicate it with your own cache backend as well.

comes with the concept of a TieredCache—simply a cache that combines two or more caches and outsources the s, s, and s to them. On a   it’ll try the first, then the second. On a   it’ll set in both. And on a   it’ll delete from both. If you’re not using Django, you can use this helper to configure it using your own cache backends.

If you are using Django, it’s even easier. For a cache that stores in the shared cache for five minutes and in local memory for 10 seconds, you could use the following:

At Dimagi, we also find ourselves writing code like this:

That way,   was cached by default, but you could also force it to skip the cache, after which it would update the cache.

This also comes out of the box with  ,, whether you use the generic or Django variants. To get exactly the same behavior, you can use:

Of course, each time you use quickcache, you may want to use it with different defaults.

Each argument to  or   can be passed in at one of three stages, later values overriding defaults. Usually, you’ll define a singleton   that you use everywhere. For example,

Then you don’t have to define quickcache every time. Just import it from this file. When you do use it, you can override the defaults. For example, here I override timeout and set skip_arg for the first time:

You can also bake in extra args at any time between when you call   and when you use it. For example, if you’re going to be using  repeatedly in a file, you can inherit the defaults from your main   object, and change just  :

Then the previous example could just be

For either flavor, the arguments you can set are , , and two advanced args that let you mess with the internals, (if you’re really dying to override some internals), and (if you want to fine-grained control over the way certain warnings are logged).

For only, you can also set the argument. For only, you can set the and arguments.

Using string values for and a list of strings for works nine out of 10 times, but when you really want control, you can pass a function to either. The function should have the same arguments as the function you’re decorating. Your function should return the value to vary on; your skip_arg function should return when you want to skip the cache.

A caching utility becomes nearly useless if it doesn’t let you easily clear a particular cache value. has a nice interface for doing this as well.

For us at Dimagi, has been a dream come true. We use it all the time. It is hard to imagine what building web applications in Python would be like without it; I’ve largely blocked those memories out. It’s so nice to use, simple, and powerful that it feels wrong to keep it all to ourselves.

That’s why we’ve decided to spend a little extra time to isolate the Django dependencies, eliminate any dependency on the CommCare HQ codebase, and publish it on pypi.

Sometimes there’s a right way to do it in Python. Want to cache values at the function level? .|||

