In application hosting scenarios, it is common to have data that must be available to all application instances. Often, this data is stored in a database (e.g. AWS RDS), or some other centralized repository (e.g. AWS S3). However, situations arise where third-party software expects data to be on the filesystem, or where application instances generate files which must be immediately available to all other application instances.

In these situations, a shared filesystem may be the easiest (or perhaps only) way to ensure multiple application instances have simultaneous access to the same data. The situation becomes more complex when the application instances may be distributed across multiple containers (AWS ECS services), as well as multiple hosts (AWS ECS instances).

Fortunately, with AWS ECS (Docker), CloudFormation, and EFS, it is very easy to share a filesystem across all application instances that may be running as ECS services or tasks.

EFS is AWS’ implementation of NFS which shares filesystems across TCP/IP networks. The NFS server hosts the filesystem and provides NFS clients access over the network as if the filesystem were mounted locally. Naturally, there are major performance considerations, but on a local area network with NFS client file caching, the performance is often acceptable.

Once an EFS filesystem has been provisioned, it can be mounted directly. However, ECS instances in a cluster are generally provisioned and managed automatically with CloudFormation templates and EC2 auto-scaling groups. The process to mount the EFS filesystem must be added to the CloudFormation template.

AWS provides a convenient way to prepare new EC2 instances by allowing “UserData” to be specified which may contain arbitrary scripts and other customizations. In CloudFormation, a template may contain a “UserData” section that is passed to a new EC2 instance at time of provisioning. The specific CloudFormation template created to manage ECS instances in an ECS cluster can be updated to include a script which automates the EFS mounting process.

The script to mount EFS itself is quite straightforward:

The “UserData” section of a CloudFormation template is also fairly simple, although there are some YAML complexities at work. (For concision, the comments in the Bash script were omitted.):

Notes on YAML in this section:

Other notes on this section:

Once an ECS host actually has the EFS filesystem mounted, it is easy to pass it on to an ECS service or task using the “Volumes” feature. Docker will make a part of an ECS instance’s local filesystem available to the Docker container at an arbitrary mount point.

This can be accomplished by specifying and naming the portion of the ECS instance’s filesystem in the “Volumes” ( on CLI) section of a task definition, and then mapping that volume to a mount point within the Docker container in the “Containers” ( on CLI) section of a task definition.

Example JSON input for the Volumes section:

Example JSON input for the Containers section:

To provide the JSON to the AWS CLI, it generally needs to be properly escaped on the command line, or referenced as a file with the option (which requires a fully formed document, like this).

All that’s left to do is configure a service or run a task that uses this new task definition. The Docker container will have full access to the contents of the mounted EFS filesystem directories, allowing the data on the filesystem to be available to all containers across all ECS instances.

Getting all of this set up can be a little tricky the first time through. Here are some ideas and good points to start debugging:|||

How to automatically mount an AWS EFS volume for sharing data across AWS ECS instances to support Docker containers with multiple application instances.