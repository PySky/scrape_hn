Comparison between Mull and Klee and finding possible ways of collaboration between these two tools has been our long-standing goal: Mull#121: Research is needed: compare Mull with Klee. This post is a report about the first experiment that we did with Mull and Klee:

TL;DR This is a long post which requires following the code examples and the screenshots. Here are the results if you want to skip the content:

Now please get ready for a long reading.

Here is a source code which is a system under test of Tutorial Two. To make the code more readable for a further analysis the braces are added so that:

We follow the advice from the tutorial to use to teach Klee that we only want to work with zero-terminated strings otherwise Klee produces the test cases with errors that we don’t want to deal with within a scope of this post:

When we run Klee on this code, we get the following result:

This is an example of the first auto-generated test:

This is what we create manually out of this auto-generated test:

We follow this procedure for all of the 14 tests and get the following test suite:

The legend below helps to interpret the numbers of this report.

When we ran Mull on these 14 tests generated by Klee we expected to have 100% mutation score for this test suite because we thought that Klee would have all possible inputs created for the function so that all mutants would be killed by those 14 tests.

Instead, we see that mutation score is 74%: we see that 4 mutants survived which means that these 4 mutations “did not cause any tests to fail” according to the legend above.

Let’s consider mutation #1. Indeed if we manually replace with and run the test suite manually, we see that no tests fail. If we spend a bit more time analyzing this code and especially step through it with a debugger we can quickly come to a hypothesis that we are just missing some tests: Klee only generated those 14 tests for the string while mutation #1 seems to be lacking a test which involves an input of one-symbol string .

Let’s run Klee again on the same code but with input “h” instead of “hello”:

When we add these tests to the test suite and run Mull again, we get a different report:

We see that newly generated test cases killed 2 of 4 mutations that we had at the step 4a. At this point, we have the tests that Klee generated for “hello” and “h” inputs. Let’s consider the third obvious case: empty string , maybe it will kill either or both of these remaining 2 mutants.

We see that tests generated for “” input didn’t change the mutation score and we still have the same 2 mutations from step 4b - they are still not killed by any of 36 tests.

At this point we are running out of options: it is not clear what input we can give Klee to generate tests so that we could have 100% mutation score. With a great redundancy of 36 tests we still have 2 mutants that survive.

After doing a simple research on mutation #1 and mutation #2 and using debugger to step through their sections of code, the following tests are enough to kill both mutations.

A careful reader may ask: why didn’t we use Klee to generate the inputs for a string that has repeating symbols to kill the mutation #1? Indeed, we used Klee to generate another 10 tests for the input “hhh” but none of those tests killed this mutation.

Observation 1. After step 4a with 4 mutations we went with step 4b where Klee generated 13 tests for input which killed 2 mutations of 4. Instead, only one test can be written which kills those 2 mutations. This test can be derived from looking at those mutations and stepping through their critical code with a debugger.

Observation 2. Step 4b killed 2 mutations. Out of all 13 generated tests for input, only this test actually killed both mutations:

The function does not match “^” symbol on all inputs:

but it does match “$” symbol:

For the same reason as in Example 1, the function does match this line:

But does not match on this line:

The major results and conclusions can be found in TL;DR at the beginning of this post. Here are a few more:

We are wondering why Klee didn’t generate the test cases to kill the last two mutations. We assume that probably this goes about some details of Klee configuration that we are not aware of. Maybe using some other solver backend instead of we could have these needed tests generated. One thing we are definitely missing in Klee’s toolchain is an option to auto-generate human-readable tests so that a human could inspect Klee’s products much easier. For this post we had to use manually for about 50 times and do this job of a test case generation manually which was tedious and of course error-prone. We think that for C and C++ languages Google Test would be a great default option for this feature. Of course, we also mean a bulk generation of a whole test suite for a whole folder as well as one test case generation for a one file. We are not aware if Klee would allow us to make both inputs symbolic so that it executed both and input string parameters so that we did not have to substitute “hello” -> “h” -> “” -> “hhh” inputs manually by hands. However, this goes beyond a scope of this post and a content of Tutorial Two.

This is a final report with redundancy of the tests auto-generated for , and strings and two tests that we wrote to kill the last two mutations.

Full 4 reports can be downloaded here: Klee-Tutorial-Two.zip.

This post is only a beginning of our research on possible collaboration between these two tools: Mull and Klee with their two quite different approaches to a software as a matter: mutation analysis and symbolic execution.

We would be happy to learn about your experience with mutation testing or Klee and symbolic execution. Feel free to drop me a line.|||

