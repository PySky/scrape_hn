DataDog is an awesome SaaS monitoring platform. We have 100+ developers leveraging the platform to collect their metrics, create dashboards and send alerts.

As with anything, if you don’t maintain and clean your tools, after a while things can become a little messy. Dashboards start to get named wildly different things with no standards. Alerts aren’t deleted for decommissioned services. Team names change and alerts are suddenly pointing to a the wrong Slack channel.

Something has to be done to improve the situation. Setting up some standards or rules around DataDog usage can help, but this is a fine line you need to walk between freedom and standardization. Be too strict or harsh on people and they no longer find the tool nice to use, instead thinking of it as pain in the ass.

Take too much freedom away, and you get “shadow IT” situations with people using their own tools or going their own way.

With this in mind, I decided on a few goals:

There were a few options around for managing DataDog from code:

I ended up deciding to go with Terraform mainly due to these two reasons:

This will cover the basics to give you an introduction to Terraform. Once you have a read, head back over to this post for some more in-depth usage.

With the workflow in mind, I setup the following repository structure:

With this structure, you would run the commands from inside the applications directory:

The file will get stored in the applications directory - which means each application will have its own state file.

The reason for this is “separation of concerns” or reducing your “blast radius”. If you have 100 apps and someone makes a mistake, you don’t want Terraform to nuke the rest of the 100 apps and screw up their configuration or state.

Now we have our repository structure, let’s zoom into a specific application, for example mssql

The is the standard file name for Terraform variables. We will want to use these variables all over the rest of our configuration

The is the standard file name for Terraform input variable deceleration. This is where we define what variables are allowed to be passed into our , creating the resources.

When you run Terraform, it will automatically find the file and use all the variables it knows about.

Terraform will then prompt you to input variables that it isn’t aware of. You can also set Terraform variables using environment variables or pass them in at the command line. More details on variables in Terraform can be found here.

The is where the actual Terraform resources go.

This file will contain:

You can find the DataDog Terraform Provider documentation here.

Here is the full file:

The few main concepts for the file:

Now we have our files setup, we can run Terraform.

Terraform will now tell you what actions will be taken against DataDog.

If you are happy with what it is going to do:

With that, you should now have your monitors created in DataDog.

If you don’t want to have to pass in the variables in each time, you can set the following environment variables:

DataDog provides many types of possible monitors you can create including , , etc.

Creating monitors for all of them via Terraform requires knowing the query behind the monitor. These queries match up with the DataDog Monitor API.

Here are a few examples:

Terraform is an awesome way to automate your infrastructure and services out of code. Using Terraform to provision DataDog makes it easy to standardize, re-use and update your monitors quickly and easily.

The most important part of using Terraform is the upfront planning. This entails splitting resources into logical groups so the blast radius is small if something does explode.

I created a datadog-terraform-example repository with the code from this blog to get you started.|||

Using Terraform to automate creation of and standardize DataDog monitors