I’ve been working on performance analysis recently, and a large part of that is scraping log files to capture interesting events and chart them.

I’m continually surprised by the things that you can do using plain old bash and his friends, but this latest one took the cake for me.

Did you know that Linux includes a utility named ? Me neither. Can you guess what it does? Yup, that’s right – it does the equivalent of a database join across plain text files.

Let me clarify that with a real-world example – one of the datasets I’ve been analyzing counts the number of messages sent and received in a format roughly like this:



 Complicating matters is that sent and received messages are parsed out separately, so we also have a separate file that looks like this:



 But what we really want is something like this:



 Here are snips from the two files:

I had stumbled across the command and thought it would be a good way to combine the two files.

Doing a simple join with no parameters gives this:

As you can see, we’re missing some of the measurements. This is because by default does an inner join of the two files (the intersection, in set theory).

That’s OK, but not really what we want. We really need to be able to reflect each value from both datasets, and for that we need an outer join, or union.

It turns out that can do that too, although the syntax is a bit more complicated:

A brief run-down of the parameters is probably in order:



 As you can probably see, you can also get fancy and do things like left outer joins and right outer joins, depending on the parameters passed.

Of course, you could easily import these text files into a “real” database and generate reports that way. But, you can accomplish a surprising amount of data manipulation and reporting with Linux’s built-in utilities and plain old text files.|||

Data manipulation with plain text files