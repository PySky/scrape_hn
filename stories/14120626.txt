To scrape web pages with Go, we can use goquery library which brings a syntax and features similar to jQuery. We will also see how to use jsonscraper to perform some simple concurrent scraping using only JSON configuration files.

To get started, first install it using command.

We will use HackerNews website in this example.

This is how structure of our program will look.

We imported formatting and logging libraries, and goquery. 

 In we use constructor which parses web page and returns and error, if occurred. 

 



To get HTML of any selection, we simply use which will construct HTML and return it as string.

For getting plain text of selection, there is . 

 So how do we get Hacker News title ? If we go to the page source, and look closely, we will see that it is inside of tag which has class.

That same tag, also has link inside of it. To get its attribute, , there are methods and which returns default string if attribute is not found.

Every submission has a link which has class. To iterate over each selection, use which accepts callback function .



 

 All code used in this section is available on Go Playground.

To perform simple concurrent scrapes and to get results in JSON file, we can use jsonscraper without writing any code. This program is written in Go and contributions are welcome.

We need to have configuration files, and use them as input arguments to the program.

For example, here is configuration for scraping data similar to the previous section:

Once the program is invoked with results will be saved in file.

For more details and how to write config files check out documentation.|||

