These notes form a concise introductory course on probabilistic graphical models Probabilistic graphical models are a subfield of machine learning that studies how to describe and reason about the world in terms of probabilities. . They are based on Stanford CS228, taught by Stefano Ermon, and are written by Volodymyr Kuleshov, with the help of many students and course staff. The notes are still under construction! Although we have written up most of the material, you will probably find several typos. If you do, please let us know, or submit a pull request with your fixes to our Github repository. You too may help make these notes better by submitting your improvements to us via Github.

This course starts by introducing probabilistic graphical models from the very basics and concludes by explaining from first principles the variational auto-encoder, an important probabilistic model that is also one of the most influential recent results in deep learning.|||

Lecture notes for Stanford cs228.