It’s a given that today’s companies must keep new products and services coming—and respond quickly to continually shifting customer demands. To maintain this competitive pace, managers need to improve the productivity of their knowledge professionals. But while many have expected new technologies like companywide computer networks to boost performance, the real promise lies elsewhere. Changing the ways professionals work, not installing new computers, is the best way to leverage this intellectual capital.

Yet managers have been loath to tackle this kind of productivity improvement. For good reason, companies in high-tech and other creatively driven businesses often avoid direct exhortations to be more productive. Professionals such as engineers, scientists, lawyers, programmers, and journalists already work hard, perhaps 50 to 60 hours a week. To demand more of them is counterproductive because, unlike many manufacturing or service workers, these professionals have options. When pushed, they may withhold their best ideas or simply leave the company.

Although managers know that some professionals excel, few people, including the “stars” themselves, can describe exactly how they do it. But we believe that defining the difference between top performers and average workers is essential for improving professional productivity. For the past seven years, our research has focused on the engineers and computer scientists at AT&T’s prestigious Bell Laboratories. This study has led to a successful training program based on the work strategies of star performers. The program has dramatically improved productivity, as evaluated by both managers and engineers.

In fields like computer programming, an eight-to-one difference between the productivity of stars and average workers has been reported. As one of the Bell Labs executives observed, “Ten to fifteen percent of our scientists and engineers are stars, while the vast majority are simply good, solid middle performers.” When asked why this is so, most managers come up with a variety of plausible explanations. Top performers, they say, have higher IQs. Or they’re better problem solvers, or driven by an enormous will to win. In other words, stars are better people in some fundamental sense, while middle performers lack the inborn traits that are necessary for more than solid plodding.

Since such traits are exceedingly difficult to change, a job-training program to become a “better person” sounds hopeless. Our research, however, has revealed a basic flaw in this reasoning. None of the above explanations for the difference between stars and middle performers stands up to empirical testing. Based on a wide range of cognitive and social measures, from standard tests for IQ to personality inventories, there’s little meaningful difference in the innate abilities of star performers and average workers.

Rather, the real differences turn up in the strategic ways top performers do their jobs. While it’s impossible to get in the door of Bell Labs without technical competence and high-level reasoning abilities, these cognitive skills don’t guarantee success. But specific work strategies like taking initiative and networking make for star performance and are trainable. When companies promote such strategies systematically, individual professionals not only improve but also pass along the benefits to their colleagues and the company’s bottom line.

Let’s consider the first major hurdle to a training program: defining productivity for a particular job. Some software companies, for example, use lines of computer code as their productivity measure, based on the assumption that good programmers generate more lines than others. This measure, however, ignores the fact that 4 lines of elegant computer code are better than 100 lines that accomplish the same objective. In addition, few professionals do the exact same job. Two computer-code testers may have the same job title, yet one may test 50 small computer programs in a single day, while the other spends as long as 3 weeks testing 1 large program.

Peter Drucker has discussed the apparently impossible task of understanding the productivity of knowledge professionals. In particular, he has pointed to the difficulties of analyzing the process that produces high-quality results in knowledge work. The best we can do, Drucker says, is ask, “What works?” Implicit in this question is the reality that the work of knowledge professionals happens inside their heads. And managers can’t directly observe, let alone accurately evaluate, these mental processes or strategies.

That leaves asking workers to disclose their mental secrets. This is no simple task, however. First of all, many people have a hard time describing what goes on in their minds when they work or even determining whether or not they’ve been productive (see the insert “How Do Professionals Define Their Productivity?”). Second, researchers can fall for nonsensical productivity recipes if their methods aren’t sufficiently focused.

In the early 1980s, for example, much ado was made about peak performance. Many researchers interviewed Olympic champions, who dutifully recounted this typical daily regimen: they woke at dawn, stretched out, ate their Wheaties, spent an hour visualizing their success, and practiced their sport for three hours. After enough champions had described the same regimen, a spate of books hit the market on how to become a peak performer in sports, sales, or management.

But what about the Olympic contenders who didn’t win? Chances are these athletes also woke at dawn, stretched out, ate their Wheaties, spent an hour visualizing success, and practiced their sport for three hours. In other words, it’s not enough to ask the stars what works; researchers must compare the regimens of star performers to those of the also-rans and then target the differences.

In fact, no one has come up with a generally accepted definition of productivity in any knowledge profession, let alone across these professions. In our research at Bell Labs, rather than grappling with a broad definition of productivity, we focused on the practical ways managers can distinguish stars from middle performers. And when it came time to evaluate the training program, we asked managers to tell us what practical changes, such as spotting and fixing problems or pleasing customers, they expected to observe in the engineers whose performances had improved.

When we began our study in 1986, the Bell Labs Switching Systems Business Unit (SSBU) was feeling the pinch of competition from companies like Northern Telecom. Before the breakup of AT&T’s Bell system, the Labs felt as much like a university research center as a corporate entity. Top-flight engineers went there for a combination of reasons: the opportunity to work on leading-edge telecommunications projects, the outstanding reputation of Bell Labs as an applied R&D think tank, and the job security that came with working for AT&T.

But Bell Labs executives watched market share drop sharply during the 1980s, and these managers soon realized that recruiting the best and brightest computer engineers and scientists wasn’t enough. As it turned out, academic talent was not a good predictor of on-the-job productivity. As in other companies, applied R&D at Bell Labs now means fast, cost-effective product cycles. And job security is tied to value-added contribution, not scholarly performance.

Consider the actual work of an engineer at Bell Labs. The SSBU creates and develops the switches that control telephone systems around the world. These switches entail substantial computer hardware and millions of lines of software code. SSBU engineers spend considerable time simply maintaining the lines of code that run a switch. The jobs of SSBU engineers also call for creativity. For example, engineers write software programs for switching systems in response to customer requests for services like caller ID, which displays an incoming caller’s name and phone number on a telephone set before the call is answered.

These engineers usually work in teams because the scale of the work is beyond any one person. It can take anywhere from 5 engineers to 150 to complete a software application, in 6 months or as long as 2 years. According to one experienced engineer, “No one engineer can understand the entire switch or have all the knowledge needed to do his or her job.” Individual productivity at the SSBU, then, depends on the ability to channel one’s expertise, creativity, and insight into work with other professionals—a formidable job assignment, even for the smartest knowledge worker.

To specify how a star engineer does his or her work, we developed an expert model, but we turned the usual approach on its head. Expert models were invented by artificial intelligence researchers in an effort to get computers to mimic the skills of human beings. Researchers have created such models by interviewing expert welders, for example, and asking them to explain in concrete detail how they go about their job. Researchers then used the interview data to construct a computer program that reproduced the experts’ skills in the form of a robotic welder. But based on our interviews with the SSBU experts—in this case, star performers in software development—the expert model for engineers was one people could use, not computers.

First we had to identify the experts. Initially, we relied on managers to point out star performers. We looked for those who had received the highest performance ratings and merit awards. We also asked managers, “If you were starting a new company and could hire only ten knowledge professionals from your present staff, whom would you hire?” There was surprising consensus among managers about who these software engineers were.

Yet once we started interviewing the engineers themselves, the picture grew murkier. As we discovered, managers sometimes overlook important components of star performance, like who originates an idea and who helps colleagues the most when it comes to solving critical problems. Being closer to the action, however, knowledge professionals certainly consider these skills when rating their peers.

In addition, the engineers believed that the Bell Labs performance evaluation system was flawed because it turned up too many false negatives, that is, people who were outstanding performers but for reasons of work style or modesty received low ratings from managers. (Later on, we found only a 50% agreement between peer and manager ratings.) The experts selected for our study, therefore, had to be highly valued performers in both their managers’ and peers’ eyes.

We asked each of the expert engineers to define productivity, how they knew when they were productive, and what exactly it was that they did to be productive. For example, one expert told us that networking was crucial to getting his job done. We then asked him how he went about networking with other experts. He explained that networking was a barter system in which an engineer needed to earn his or her own way. From his perspective, that meant first becoming a technical expert in a particularly sought-after area, then letting people know of your expertise, then making yourself available to others. Once an engineer has developed his or her bargaining chips, it’s possible to gain access to the rest of this knowledge network. But once in the network, you have to maintain a balance of trade to stay in.

After we met with the experts in groups, they came to a consensus about the two categories—cognitive skills and work strategies—that influence high productivity. Since all Bell Labs engineers score at the top in IQ tests, cognitive abilities neither guarantee success nor differentiate stars from middle performers. However, the Bell engineers identified nine work strategies that do make a difference: taking initiative, networking, self-management, teamwork effectiveness, leadership, followership, perspective, show-and-tell, and organizational savvy (see the chart “An Expert Model for Engineers”).

Moreover, the engineers ranked the work strategies in order of importance. Taking initiative is the core strategy in this expert model. An engineer must be able to take initiative upon arriving at Bell Labs or develop the ability for doing so soon after. In a competitive technical environment, it’s just not possible to survive otherwise. Yet taking initiative is also one of the most elusive strategies and therefore difficult to quantify. As one engineer explained, “I go into my supervisor’s office for a performance evaluation, and she tells me that I should take more initiative. I say to myself that I’m already taking initiative, so what exactly is it that she wants me to do?”

Clearly, any training program for improving the productivity of professionals must first target taking initiative. During our discussions with the Bell Labs experts, one proposed creating practical checklists to detail each workstrategy. The “Checklist for Taking Initiative” outlines a sample of specific actions and behaviors that define this core strategy.

The second layer of the expert model includes work strategies like networking and self-management. Although the Bell Labs engineers thought these were critical for high productivity, they acknowledged that they could be acquired at a slower pace. The third and final layer contains show-and-tell and organizational savvy, which these star performers considered “icing on the cake.” Professionals who develop these work strategies have a leg up for managerial promotions, but giving riveting presentations and playing the correct political games aren’t essential to getting the technical job done.

At the same time that we were defining the expert model with star engineers, we were also interviewing middle performers at the Bell Labs SSBU. When we first compared the interviews, it appeared that stars and middle performers gave similar answers. For example, both groups identified taking initiative as a useful work strategy. But closer inspection revealed that the answers of stars and average engineers differed in two critical ways: how they ranked the strategies in importance and how they described them.

To begin with, middle performers inverted the expert model’s ranking of the nine work strategies. According to these engineers, show-and-tell and organizational savvy were the core strategies and were largely responsible for high performance ratings from managers. It’s easy to understand why these nonexpert engineers came to this conclusion. One of the few times senior managers see knowledge professionals in action is when they give presentations. And in some cases, mediocre professionals with a flair for showmanship are rewarded by top management. But in general, executives use such public presentations to infer the skills and strategies that produce good technical work. Picking up on only the superficial aspect, the Bell Labs middle performers were overly focused on impression management rather than critical strategies like networking.

As for describing the work strategies, the differences between stars and middle performers were even more striking. One middle performer at the SSBU, for instance, told us of gathering and organizing source materials, including documents and software tools, for a project he was beginning with his group. Another described writing a memo to his supervisor about a software bug. Both engineers believed they showed a great deal of initiative in taking it upon themselves to do this work.

Yet when we described these examples to the Bell Labs experts, they were critical. They thought these engineers were barely doing their jobs, let alone taking initiative. For example, one expert explained that by the time a software bug is documented, it is often impossible for the software developers to re-create the problem in order to fix it. For the experts, fixing a bug yourself or preparing for a project is what’s expected of you in your job. Real initiative means going above and beyond the call of duty. In addition, such actions must help other people besides yourself and involve taking some risks.

Discussions about networking surfaced equally revealing differences, since both stars and middle performers said networks of knowledgeable people are critical for highly productive technical work. For example, a middle performer at Bell Labs talked about being stumped by a technical problem. He painstakingly called various technical gurus and then waited, wasting valuable time while calls went unreturned and e-mail messages unanswered. Star performers, however, rarely face such situations because they do the work of building reliable networks before they actually need them. When they call someone for advice, stars almost always get a faster answer.

In fact, we found similar differences between stars and middle performers in their definitions of all the work strategies. In particular, some middle-performing engineers clearly lacked perspective. One engineer described the many hours he had spent mastering a software tool for organizing files, which ended up delaying the delivery of a customer’s product. From an expert’s perspective, of course, the customer comes first. Although star performers agreed that upgrading their knowledge of current software tools is useful, they also emphasized the need to set priorities. And these experts stressed the need to “shift gears” between the narrow focus required for certain tasks and a broad view of how their project may fit into a larger one.

Not surprisingly, knowledge workers don’t like off-the-shelf productivity training programs. Our discussions with engineers at Bell Labs and elsewhere show that these people like to make their own choices. Such professionals readily admit that they could do their jobs better, but they’re also wary, as at least one Bell Labs participant put it, of “becoming a clone.”

Knowledge professionals value the real experts on productivity in their laboratory or law firm, not trainers who breeze in, teach a day-long workshop, and then breeze out. Therefore, once the Bell Labs SSBU training program got underway, respected engineers led the training sessions. In fact, the process of developing the expert model became the foundation for the training program itself. The Bell Labs experts we interviewed reported increases in their own productivity because they had picked up valuable tips from listening to their star colleagues.

The expert model also has a clear advantage over a system like mentoring. While many professionals are experts about their own productivity, no single star performer knows everything. Unlike a mentoring program in which one senior professional advises a junior staff member or a group of new workers, an expert model pools the strategies of many stars. And a training program based on such a model makes those strategies explicit.

In the spring of 1989, top managers at Bell Labs agreed to a pilot training program for the SSBU. Sixteen engineers chosen by managers participated in two groups that met once a week over the course of ten weeks. These groups included a mix of stars and middle performers but were weighted more heavily with stars, since we wanted them to become trainers later. After the initial pilot sessions, we reversed the ratio of stars to middle performers in the groups.

The training program’s primary task was to make the critical work strategies concrete, accessible, and learnable. Each week of the pilot program focused on one of the nine strategies, and the last week was used for a wrap-up. But despite this neat schedule, the first engineers to participate revised the curriculum as they went along, testing ideas out in real time, keeping what worked, and discarding what didn’t.

For example, the engineers developed a teamwork exercise based on work-related issues at the SSBU. The group formed a mock task force to focus on a pressing company issue like whether or not the software development process should be standardized. Participants decided to spend part of each remaining session in this mock task force. A few weeks into the exercise, however, one engineer complained that while this was more realistic than most training activities, it still had no real impact on her day-to-day work or that of the company. Within a week, top managers at Bell Labs told the pilot group that they would read and respond to a written report from this no longer “mock” task force. Suddenly, this particular teamwork exercise became more compelling than anything the group had done before.

By the end of the pilot program, the 16 engineers had created a detailed curriculum for each of the 9 work strategies. Each piece of that curriculum included frank discussion, work-related exercises, ratings on the work strategy checklists, and homework that required participants to practice while they learned. As the insert “A Day in the Life of Productivity Trainers” indicates, a Bell Labs workshop session involved not only specific case studies and exercises but also active disagreement among all participants.

Eventually, the Bell Labs training program was streamlined to six weeks, with the sessions facilitated by expert engineers who had previously participated. Yet continually reshaping the curriculum in response to critical events on the job is still the current program’s most important feature.

For example, during one of the later sessions, top management issued a memo on company quality initiatives. Engineers at the SSBU thought the memo blamed them for poor quality. So participants in the training program decided to respond directly to the memo as part of that session’s work. Up to that point, it was quite unusual for engineers to take such a step because most believed that top managers would not appreciate, let alone respond to, a direct approach. But as it turned out, the engineers got a quick and constructive response. Top managers sent e-mail messages and talked to some of the participants about their concerns.

In addition, if professionals try to analyze their own productivity, they need a clear idea of how others, especially managers, view their performance. Bell Labs trainees received feedback from peers, managers, customers, and fellow participants. They also rated themselves on the work strategy checklists and filled out several other self-evaluations. With such a range of feedback, most participating engineers knew what their strengths were and where they most needed to improve by the end of the program.

Since 1989, more than 600 of the 5,000 engineers at the Bell Labs SSBU have participated in what is now called the Productivity Enhancement Group (PEG). Since these engineers were scattered across many projects and departments, it’s difficult to demonstrate the program’s effectiveness through measures like fewer person hours spent on a particular project. In their self-evaluations, however, participants reported a 10% increase in productivity immediately after the sessions ended, which grew to 20% after 6 months and 25% after a full year. This steady upward curve is the opposite of what follows most training programs. Typically, effectiveness is greatest on the last day of the program and falls to zero after a year.

But even if PEG participants reported substantial productivity increases, this doesn’t prove that the performance of these engineers actually changed. The corporate goal for PEG was not, for example, taking initiative for initiative’s sake but adding value to the company. Therefore, we met with managers again, asking them, “What would you look for as indices of increased productivity in a person who worked for you?” The chart “What Managers Thought: The Real Test of Productivity” shows that the productivity of PEG participants improved twice as much as nonparticipants over an eight-month period. According to the SSBU managers, these engineers improved in seven areas, including spotting and fixing problems, getting work done on time with high quality, pleasing customers, and working well with other departments. And star performers were not alone in benefiting from PEG training. Star and middle performers improved at similar rates.

We also compared our manager surveys with the company’s standard performance ratings, which are routinely collected at Bell Labs and are the basis for salary adjustments and promotions. We looked at these ratings before participants began PEG and then eight months after they had finished the program. Interestingly enough, the performance ratings of PEG participants improved at twice the rate of nonparticipants, mirroring the results of our manager surveys.

In addition, PEG had an especially strong impact on women and minority engineers (see the insert “Women and Minorities at Bell Labs”). In traditional organizations, these groups are often excluded from the expert loop. But creating an expert model that demystifies certain productivity secrets, particularly the importance of key work strategies and how to acquire them, makes the loop explicit and accessible to all.

Ultimately, of course, such productivity increases for individual professionals fall to the company’s bottom line. If the total compensation package for a knowledge professional is about $62,500 (salary plus fringe benefits), the ROI is $625 each year for every 1% productivity increase. Thus a 10% increase yields $6,250 for each participant, while a 25% productivity increase would pay back $15,625, and so on.

But these ROI numbers don’t include the more indirect productivity benefits. PEG participants improved dramatically in the ways they assisted colleagues. These engineers also built stronger ties to customers. While such positive changes are hard to measure, they are essential to a highly productive work team.

Some managers still wonder whether high productivity is due only to individual work style and motivation. In many cases, they’re searching for a justification for their own style. “Clean desk” people want to believe that being organized leads to higher productivity. “Sloppy desk” managers, however, view their style as evidence of the creativity that translates into high performance.

But we’ve found no such relationship. Rather, training programs like PEG can help professionals discover the strengths and weaknesses of their individual work styles. Managers gain little by foisting a time-management system, complete with scheduling book and to-do priority tabs, on someone who prefers to keep such information in his or her head. Helping this worker to develop a better strategy for storing information mentally and setting priorities makes more sense.

Motivation, however, is another matter. At Bell Labs, most of the engineers we worked with were eager for productivity tips. They knew their success was tied to high performance, and they saw how easily the work piled up. Since the PEG sessions focused on developing individual work strategies, motivated professionals benefited by improving their own productivity.

But when workers aren’t motivated to improve, a program like PEG is of little help. In surveys done outside of Bell Labs, we’ve found that about one-third of knowledge workers don’t feel tied to their company’s destiny, nor do they feel that their productivity and good ideas are sufficiently rewarded. For example, teamwork is often touted by corporate headquarters as critical to both individual and company success; however, an employee’s ability to work with others often has little to do with annual performance ratings or rewards. Many professionals know this and are right to resent it.

Yet such resentment can lead to serious drops in productivity. A company with unproductive and actively resentful professionals, then, may need to address additional organizational issues, such as revising the reward system or treating its professionals as individuals with individual needs.

Clearly, it’s not possible to turn every average worker into a star. Despite PEG or any other training program, there are differences among professionals, just as there are among athletes who follow the same training regimen. It’s probably not even desirable or cost-effective to put all professionals through a training program, since not everyone enjoys or is compelled by intense workshop sessions.

However, the PEG participants at Bell Labs have not only improved their own productivity but also positively affected the productivity of nonparticipating coworkers. The checklists and other materials derived from the expert model have been photocopied, passed around, and incorporated into the everyday functioning of the SSBU. Once such informal dissemination happens on a wide scale, formal training is no longer necessary.

Developing an expert model can provide a powerful platform for leveraging intellectual capital in many professions. The PEG program at the Bell Labs SSBU, however, isn’t a blueprint for another company, even a research laboratory with a similar environment. The mix of work strategies may differ from profession to profession; a marketing department, for example, may find that show-and-tell is a core strategy for star performance, along with taking initiative. Yet, regardless of profession, top managers need to focus on people when they address productivity improvement. In the new knowledge economy, it’s the performance of knowledge professionals, not just complex technologies, that will make or break a business.|||

Any training program for improving the productivity of professionals must first target taking initiative.