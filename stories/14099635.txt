From my experience in the software development community, not many programmers are mindful of the power they hold — developers have the ability to take an idea and bring it into reality — changing the way people interact with their passions, their art, and each other.

All programmers have the power to shift the path that humanity walks in the future. In yielding that power, they need to be considerate of the positive and negative implications their creations will have. I believe that mindfulness is becoming increasingly crucial, and increasingly pushed aside, as new technology emerges — like artificial intelligence and machine learning, virtual reality and biotech.

I feel it is necessary to introduce this technology in the context of how we think of free will. The concept of free will has changed over the course of humanity. Early on, humanity was carrying out God’s will. Over time, many humans found power in solely making their own decisions. Today, we are now making another shift in our decision making, this time to algorithms. An example of this is in medicine. We trust a machine’s diagnosis over a human with years of practice and study. A model recently beat doctors at predicting heart attacks. I often wonder how much of our decision making will be shifted to ML algorithms. I often worry, too, because people who lack programming experience often look at technology as this black box that just works. Software developers are more aware of the vulnerability of every program — every program has edge cases that haven’t been handled.

As models become more accurate, their process of determining an answer become difficult to explain. Deep learning models’ process of determining an answer is quite an enigma. These models are now being studied with the same approach that neuroscientists study the brain. The implications can be unimportant in some cases, but imagine a deep learning model that decides who to put into prison — accurate, but unable to explain its reasoning.

The model only knows the data that it’s trained on — and could find patterns in the data that don’t represent any real phenomenon that we experience. Another example is a ML algorithm that decides who to give a loan to. Even if it is based on all of the financial records of all banks, there are histories of discrimination that will be embedded in the logic of the algorithm.

Virtual reality technology is, by nature, immersive technology. In order to create a sensation of some virtual world, your senses must be fooled.

Right now, you are receiving a ton of sensory input and your brain is deciding what is most important to pay attention to. According to your brain, the light emitted from your computer screen is more important than how your feet feel on the floor, or how the seat you’re sitting on feels on your bottom, or how your clothes feel on your skin, or the tightness in your jaw, etc. VR is a similar experience to the one you’re experiencing now. The difference is that VR gives a developer the ability to control the sensory input that you receive.

This in addition to the user research done at social media companies like Facebook, who know how to control human attention very well, is a dangerous combination. And unfortunately, in my experience, the software developers that I’ve come across don’t have this consideration when they’re writing code or working for a company.

The technology exists today that allows a string of DNA to have a portion of it replaced with a new strand of DNA. This has potentially amazing implications, imagine: being able to remove a disease from our bodies. However, a tool’s potential for positive impact also has an equal and opposite potential for malice. Imagine: editing a human’s DNA to give them super intelligence. This would create a genetic inequality between humans.|||

From my experience in the software development community, not many programmers are mindful of the power they hold — developers have the ability to take an idea and bring it into reality — changing…