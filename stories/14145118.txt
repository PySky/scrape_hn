The same tools that handle the speech recognition features in Google Assistant can now be used by a larger audience. The Google Cloud Speech API, which went into open beta in the summer of 2016, is now generally available for all third-party developers.

Google says that the Cloud Speech API can recognize over 80 languages and variants. Developers can, among other things, create products and services using those tools to transcribe the text of users who speak into a microphone. In fact, you can do a quick demo of that feature over on the Google Speech API page.

In addition, the API allows developers to enable voice commands for apps and services, along with transcribing audio files. Google says that since the open beta for the API started last year, thousands of customers have used it, and their access to the open beta allowed Google to add many improvements. That includes better transcription accuracy for longer audio files, faster processing time, and the support of more file formats such as WAV, Opus, and Speex.

Google offered some examples of how the Cloud Speech API has been implemented by businesses. One of them, Japan’s Clarion, uses it for in-car navigation and entertainment systems. It says that, combined with the use of the Google Places API, it allows customers to get to their destinations safely. The Houston, Texas-based InteractiveTel also uses the Cloud Speech API to get almost real-time transcriptions of their dealers’ chats with customers. The company says these transcriptions have helped them to increase sales.|||

The Google Cloud Speech API, the speech recognition tools that are used in Google Assistant, is now open for all third-party developers.