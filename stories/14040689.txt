Readability by the same program Your program has stored your data somehow as bytes in the memory. But it might be arbitrarily scattered across different registers, with pointers going back and forth between its smaller pieces [edit: As commented, physically the data is more likely in main memory than a data register, but that does not take away the pointer problem]. Just think of a linked integer list. Each list element might be stored at a totally different place and all that holds the list together are the pointers from one element to the next. If you were to take that data as is and tried to copy it on another machine running the same program, you would run into problems: First and foremost, the register adresses your data is stored in on one machine might already be used for something completely different on another machine (someone is browsing stack exchange and the browser ate all that memory already). So if you simply override those registers, good bye browser. Thus, you would need to re-arrange the pointers in the structure to fit the addresses you have free on the second machine. The same problem arises when you try to re-load the data on the same machine at a later time. What if some external component points into your structure or your structure has pointers to external data, you did not transmit? Segfaults everywhere! This would become a debugging nightmare. Let's say you manage to allocate just the right addresses on another machine, for your data to fit into. If your data is processed by a separate program on that machine (different language), that program might have a totally different basic understanding of data. Say you have C++ objects with pointers, but your target language does not even support pointers on that level. Again, you end up with no clean way to address that data in the second program. You end up with some binary data in memory, but then, you need to write extra code that wraps around the data and somehow translates it into something that your target language can work with. Sounds like deserialization, just that your starting point now is strange object scattered around your main memory, that is different for different source languages, instead of a file with a well-defined structure. Same thing, of course, if you try to directly interpret the binary file that includes pointers - you need to write parsers for every possible way another language might represent data in-memory. Two of the most prominent modern serialization languages for web based serialization (xml, json) are easily understandable by a human. Instead of a binary pile of goo, the actual structure and content of data is clear even without a program to read the data. This has multiple advantages: easier debugging -> if there is a problem in your service pipeline, you just look at the data that comes out of one service and check if it makes sense (as a first step); you also directly see if the data looks like you think it should, when you write your export interface in the first place. archivability: if you have your data as a pure binary goo pile, and you loose the program that is meant to interpret it, you loose the data (or you will have to spent quite some time to actually find something in there); if your serialized data is human readible, you can easily use it as an archive or program your own importer for a new program the declarative nature of the data serialized in such a way, also means, it is totally independent of the computer system and its hardware; you could load it into a totally differently constructed quantum computer or infect an alien A.I. with alternative facts so it accidentally flies into the next sun (Emmerich if you read this, a reference would be nice, if you use that idea for the next 4th July movie)|||

