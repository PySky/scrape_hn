Wikipedia contains a list of cognitive biases. (There are around 170). Psychologists often conduct experiments to discover and understand phenomena like these. Typically, experimenters take great effort to control the environment so that the only real variable is the one of interest. That is the point of an experiment, obviously, and it is excellent for understanding causality. On the other hand, experiments aren’t so good for understanding relative importance.

What I mean is that, although you may find a causal effect in a laboratory, that effect may not be very important in your life. Let me explain in detail.

Academics, like most other people, tend to like good stories. Research presentations often revolve around the story of a phenomenon or a problem. The presenter sets up the plot with a main conflict, or challenge: it could be a problem the research means to solve, a topic to clarify. Then, the research is explained and proposed as a resolution to the conflict. This makes for more interesting presentations, and they are easily digestible.

The strength of the storytelling format for research presentations is the same as the weakness: impact. The audience pays more attention, and enjoys the experience more, which are good things. On the other hand, the topic of the presentation also seems more important. This may be a good thing, for a few really, truly important topics. For cognitive biases, I think it’s not such a good thing. It may be that the storytelling format leads us to attribute more importance to these biases than we should.

While I love his books, Malcolm Gladwell provides a good example of this. He weaves wonderful stories that are immersive and informative. Truly, he is a master storyteller. After I read his books (and similar books) I’m usually enthused about what I’ve discovered. Over time, the enthusiasm fades and all that is left are the nuggets of practical, applicable wisdom from the books. What I’ve found is that, often there aren’t any. That’s right, most of what I’ve learned from these books has ended up being of very little practical value. I am much like a person excited to lose weight with a new approach, only to find over several months that the new approach has fatal drawbacks.

Typically, when experiments are described (especially in social psychology), the main question is causality. The standard criteria for causality include a notion of “statistical significance.” In almost all cases, this relies on a statistical method called hypothesis testing. This may be familiar to you if you’ve ever worked with “null hypotheses” and “alternative hypotheses.” I won’t go into any more technical detail, but the key is that most research uses a cutoff value for significance (mainly p>0.05).

Once some effect has cleared the threshold for statistical significance, it gets a lot of credibility. Usually it sticks in people’s brains (even if it doesn’t translate into behavioral changes). But clearing the statistical threshold isn’t really that meaningful in the context of real life.

Remember, as I mentioned, experiments are run in tightly controlled environments. The goal is to isolate an effect, and so context is removed. Put the context back though, and you may find that the effect is overwhelmed by it. This is why magnitude is important. In particular, the magnitude relative to common contexts in which the effect may arise.

You may wonder why I’ve spend the time to write this essay. That is a fair question. Mainly, I want to help people remove intellectual clutter.

I feel inundated by knowledge, advice, news, and ideas. As the internet has developed, it has blessed the lives of billions of people with new information and abilities to connect. At the same time, there is now a gigantic burden of sifting through what we read and see to find the important stuff. This can be so difficult. I hope to provide a tool for the chore: practical significance.

Since we all like simple rules-of-thumb, I will provide a replacement for the statistical rule of thumb, complete with a threshold. I’ll call it Bell’s Rule for Practical Significance, and it is the following: impact > 1 year. The idea is that a phenomenon, effect, idea, or strategy is practically significant if someone employs it and continues to perceive an impact for more than a year. Why a year? I think it’s long enough to establish a truly robust effect, but short enough that it isn’t such an onerous burden. In theory, of course, the ideal threshold is an impact of indefinite duration, but a rule-of-thumb based on such a threshold would be useless.

My threshold is arbitrary, yes, but it’s easy to remember and it provides a starting point for thinking about practical significance.

If I search my memory, a few very important phenomena come to mind that pass Bell’s Rule.

There are possibly more, but these definitely pass the rule: impact > 1 year.

Now, let me emphasize that applying Bell’s Rule For Practical Significane cleans things up a lot. I’m a PhD student, and I’ve read tons of popular social psychology books. I learn about new effects almost weekly. I’ve learned about hundreds of these effects in total, but we have basically 5 that really matter, in my mind. (Ironically, I’m doing this all in hindsight, so number 3 may apply. :)

If you stuck with this article, thanks for reading. I hope it can help you hone in on the stuff that matters.|||

Wikipedia contains a list of cognitive biases. (There are around 170). Psychologists often conduct experiments to discover and understand phenomena like these. Typically, experimenters take great…