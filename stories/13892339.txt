The Guardian has withdrawn all its online advertising from Google and YouTube after it emerged that its ads were being inadvertently placed next to extremist material. 



Ads for the Guardian’s membership scheme are understood to have been placed alongside a range of extremist material after an agency acting on the media group’s behalf used Google’s AdX ad exchange.

David Pemsel, the Guardian’s chief executive, wrote to Google to say that it was “completely unacceptable” for its advertising to be misused in this way.

He said the Guardian would be withdrawing its advertising until Google can “provide guarantees that this ad misplacement via Google and YouTube will not happen in the future”.

The content included YouTube videos of American white nationalists, a hate preacher banned in the UK and a controversial Islamist preacher.

The use of programmatic trading, which automates the process of buying and selling advertising online , is becoming increasingly controversial amid concerns that it both hurts media revenues and supports extremist material.

Earlier this week, the Department for Culture, Media and Sport held a private ministerial meeting with news publishers and technology platforms to discuss the issue of fake news and the programmatic environment which supports it.

The Guardian’s problem is understood to have arisen through the use of AdX, Google’s DoubleClick Ad Exchange Service, which uses programmatic trading.

In his letter to Matt Brittin, Google’s European president, Pemsel referred to the fact the Guardian’s membership scheme was partly launched to diversify revenues away from an ad market increasingly dominated by technology groups. Google, with YouTube and its DoubleClick ad service, as well as Facebook account for close to 85% of digital ad spend.

“The decision by the Guardian to blacklist YouTube will have financial implications for the Guardian in terms of the recruitment of members to fund our journalism,” wrote Pemsel.



“Given the dominance of Google, DoubleClick and YouTube in the digital economy, many brands feel that it is essential to place advertising on your platform. It is therefore vital that Google, DoubleClick and YouTube uphold the highest standards in terms of openness, transparency, and measures to avoid advertising fraud and misplacement in the future. It is very clear that this is not the case at the moment.”

Pemsel urged other brands to blacklist the Google-owned companies until “guarantees that advertising placed on YouTube will not sit next to extremist content in the future” can be provided.

At the Guardian’s Changing Media Summit this week, Johnny Hornby, founder of the ad group The&Partnership, said of the current market: “Far too little is being done to make a dent in the billions our clients are losing to fraudsters – let alone the reputational damage caused by the inadequate brand safety policies of major platforms like Google, YouTube and Facebook.

“It should be within our gift as the clients who invest the money, and as the media agencies who recommend where to spend it, to simply agree to withdraw media spend from environments where we cannot guarantee safety for our clients’ brands.”

Following the Guardian action, Google and YouTube promised to make significant changes to its policies to deal with the problem. A spokesman said: “We have strict guidelines that define where Google ads should appear, and in the vast majority of cases, our policies work as intended, protecting users and advertisers from harmful or inappropriate content.

“We accept that we don’t always get it right, and that sometimes, ads appear where they should not. We’re committed to doing better, and will make changes to our policies and brand controls for advertisers.”|||

Ads for membership scheme were inadvertently placed by Google next to extremist material