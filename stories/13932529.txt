Since 2014 Insight has helped 180+ of the brightest software engineers and academic programmers transition into top Data Engineering roles and we’ve learned a lot about how to make the transition efficient. We’ve received many requests over the last two years from people wanting to learn what they can do to improve their data engineering skills and chances of getting into the Fellows Program so we wanted to share some of our thoughts here.

At Insight, Fellows learn to think as a data engineer and are exposed to many open source distributed tools used in the industry through building a scalable data platform. Below you will find suggestions and resources that have helped our Fellows prepare for this transition.

One of the best ways to begin understanding data engineering is to familiarize yourself with real-world challenges by learning from data engineers in the industry.

We also highly recommend Big Data, the book from Apache Storm and Lambda Architecture creator, Nathan Marz. Our Fellows have found it really helpful and the first two chapters are available free online.

Action Item: Read -at least- the first two chapters of Nathan Marz’s book on Big Data.

Once you’re familiar with the challenges of a data engineer, the next step is to get acquainted with the components of a data pipeline and the technologies used to handle large, real-time data sets:

During the program, our Fellows take a deep dive into some of these technologies, but it is very helpful to spend some time exploring a few of these tools at a high-level to understand how they fit into data engineering ecosystem.

One of the hurdles in learning data engineering is setting up a distributed cluster to develop on. Amazon provides a free-tier which can be used to learn the distributed technologies, rather than just using your local system.

During the session, Insight fellows commonly use AWS to run more complex applications on distributed clusters.

While it is good to know the basics of some popular technologies, it is better to know the underlying computer science fundamentals behind them. For example, it is better to know that many modern NoSQL databases are implementations of a distributed hash table, and understand why these are used.

As a data engineer, you will most likely be part of a team of software engineers and data scientists working on shared projects and code bases. Using software development best practices will help you to become an efficient team member.

Many of you are familiar with Python, Java or perhaps C++ but you’ll find that learning a new language may be to your advantage. Data engineering tools, such as Hadoop, Spark and graph libraries are written in Java and Scala. Some tools have a Python wrapper, so it’s good to be familiar with Python, but the newest updates often occur in the native language first.

Bonus Item: Get a sense of Scala with some of the problems in 99 Scala Problems, or re-write one of your favorite algorithms in Scala. You may also enjoy Twitter’s Scala School as a reference.

If you’ve familiarized yourself with all the materials above here are some extra useful topics you should continue with.

Here are some of the primary news sources read by people in tech. We recommend starting to skim these resources every few days:|||

Interested in getting hands-on experience with tools like Kafka, Spark, etc. on Amazon Web Services and transition to data engineering? The Insight Data Engineering Fellows Program is a free 7-week…