I’ve been doing a research on how to do graceful shutdown of HTTP services in Kubernetes. Surprisingly, I found contradictory opinions on the topic, so I decided to do my own testing. Read on if you are interested in the results.

Before diving into different shutdown approaches, let’s see what the official Kubernetes documentation says about the topic[2]. Here is an excerpt from the doc (I’ve skipped the points that I consider irrelevant):

Reading this, it looks like there is possibility for new requests to come in after a is received (between 6 and 7). This means that if the process just listens for and exits upon reception, some requests will not be served.

That was not clear enough, so I started researching. The first post[1] I stumbled upon suggest the following flow:

This approach suggests that the process should notify that it is exiting, by failing its readiness probe. It seems weird to expect that a process is aware of the underlying infrastructure it is running on. Even more, reading the comments adds more to the confusion. There is one comment that states it is not needed to notify that your process is exiting, but indeed there are some requests that will get routed to the container after being sent. Strange, indeed. Let’s keep digging.

I found a Stackoverflow question[3] regarding graceful shutdown, with the following answer.

More research just yielded more results that suggest both approaches, making the things even more unclear. At this point I decided I’ll have to do some experiments myself.

The first thing I wanted to check is whether requests are routed to the container after -ing it. I ended up spinning up a local cluster using minikube[6] and deploying test Go program (called ) that counts all received requests after getting . It was exposed via a service and an ingress.

I ran a test with (the Apache HTTP server benchmarking tool), and while the test was running I deleted the pod which was serving the requests.

And this is the output of the test program:

Turns out that it is indeed possible to get requests after receiving shutdown signal. For the 15 seconds wait period before stopping the HTTP server, more than 2000 requests were served.

However, I did not find any correlation between the duration that the program waited before actually exiting and the number of requests. Next in my tests was playing with the readiness probes. I enhanced the test program, so it starts returning once the termination signal is received. This did not change the behavior either.

The test above concerts the case where a single pod is deleted using on a single node Kubernetes setup. It is a good idea to test what would happen in a multi-node Kubernetes setup, when one of the nodes is terminated. This may yield different results regarding the time needed to stop routing requests to shutdown pods.

Here are some obvious and not so obvious takeaways from my experiments

If you have any experience with the topic, please share it in the comments section below, so this confusion is driven away once and for all.|||

I’ve been doing a research on how to do graceful shutdown of HTTP services in Kubernetes. Surprisingly, I found contradictory opinions on the topic, so I decided to do my own testing. Read on if you…