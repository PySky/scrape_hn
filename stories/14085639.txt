The algorithm society has arrived. It has arrived with big data analytics, computational decision-making, as well as unintelligible and non-transparent information processes (cf. Pasquale, 2015). It is a society where data is at the core, articulated simply as ‘data’ or ‘big data’ - almost as uniform commodities despite their irregular and diverse appearances. Further, it is a society driven forward by the promises and hopes for a smarter data-driven future.

“As the variety and sources of data grow, an ‘algorithm economy’ is emerging where an increasing number and range of decisions and processes are made by computers crunching data using ‘if-then’ rules.” (Ctrl-Shift, 2015, p. 7). The processed data is used for predictive analyses, weather forecasts, exit polls, and tailored services for individuals - collectively known as big data analytics. Such an algorithm economy (and the algorithm society in general), and the way it works, presupposes an understanding of data as fact. That is, an understanding of data as objectively true commodities which can be collected, combined, shared, and sold. It is a conception of data which feeds into Floridi’s (2005) account of semantic information as well-formed, meaningful, and truthful data. Further, it is this conception of data as truthful and commodified along with the appertaining conception of information which foster the idea that:

This idea of the current and future potential of data analytics presupposes information and personal data as truthful, otherwise ‘richness, relevance and waste reduction’ would not be expected. Thus, it seems to be the general conception that if we just have enough data or information of the right kind then we can predict the future with high degrees of certainty.

However, something seems to be missing from this conception: misleadingness.

“People’s data, whether provided, observed, derived or inferred from usage, is playing an increasingly pivotal role in the creation and evolution of innovative new services, transforming our economy into a data driven economy.” (Deadman, 2015, p. 3). Observation, derivation, and inference are all based on interpretation and meaning. What some data or information means is dependent on the context. Thus, shifts in context can lead to shifts in meaning for the same datum or piece of information. It is in the relation between data/information, context, and meaning that different kinds of misleadingness can occur. Misleadingness - e.g. misinformation and disinformation - always arises as a consequence of the relation between content and context.

When some utterance or act is unintended misleading it is misinformation. For instance, if the content of an utterance is inaccurate unbeknownst to the utterer the utterance might become misleading dependent on what the receiver knows in advance. Or the content of the utterance might become inaccurate and misleading due to the context within which it is presented - i.e. the meaning shifts due to the context.

When some utterance or act is intentionally misleading it is disinformation. That is if the content of an utterance has the purpose to mislead someone - i.e. to make him obtain a false belief. If the misleading is successful and the disinformee is actually misled the disinformation is an instance of deception. The prototypical instance of disinformation is a lie, however, it need not be a lie in order to be disinformation. Utterances, acts, pictures, maps, etc. can all be instances of disinformation if they are intentionally misleading but only utterances can be lies as lies are always expressed through assertions. Thus, a picture cannot lie but it can disinform; an act cannot be a lie but it can be disinformation; etc.

The tricky part about misinformation and disinformation is that they are not success terms. This means that something can be misinformation or disinformation independent of whether someone is actually misled - it all depends on the intentions.

When an utterance or an act is algorithmically collected as a fact - i.e. as data in the objective and truthful interpretation - the context outside the digital platform and the intentions behind the utterance or act are not parts of the data collected. For instance, the fact that I buy a specific book online does not say anything about my intentions. Why I bought the book and who it is for is not reflected in the data. When my purchase is collected as a fact the underlying assumption is that I bought the book because I like it. However, if I bought the book for someone else the context changes and the data does not reflect my preferences. Thus, the data about the purchase becomes misleading.

The point is that context and meaning makes all the difference as to whether something is misleading or non-misleading. And the intentions which people have when they say, write, or do something determine whether something misleading is misinformation or disinformation. If the misleadingness is intentional it is disinformation and if the misleadingness is unintended it is misinformation.

In big data analytics and the algorithm economy where data is simply treated as facts important aspect are left out of the story. Intentions and meaning in context are not accounted for within the predictive analyses and tailored services. Thus, the analyses themselves risk being misleading and the services risk to miss the mark.

In crude terms some of the core components driving our society forward - i.e. the expected potential of big data analytics and the algorithm economy - are based on a set of false premises: big data analytics risk being disruptive rather than truth conducive.

About the author: 

Sille Obelitz Søe (PhD) has a post.doc. position at University of Copenhagen. Her work is situated within philosophy of information, more precisely the intersection between ordinary language philosophy, epistemology, and information studies. At the core of her research lies the concepts of information, misinformation, and disinformation and their pragmatic nature - with connections to big data, algorithms, and privacy.

References

Ctrl-Shift, (2015). The data driven economy: Toward sustainable growth. Report commissioned by Facebook.

Deadman, S. (2015). Stephen Deadman, Global Deputy Chief Privacy Officer, Facebook, in: Ctrl-Shift, (2015). The data driven economy: Toward sustainable growth. Report commissioned by Facebook.

Pasquale, F. (2015). The Black Box Society. The Secret Algorithms That Control Money and Information. Harvard University Press.|||

The algorithm society has arrived. It has arrived with big data analytics, computational decision-making, as well as unintelligible and non-transparent information processes (cf. Pasquale, 2015). It…