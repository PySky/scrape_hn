It might begin with the search bar but it ends with the user.

Keywords are a huge part of traditional SEO but most users don’t care about keywords, they simply want answers to queries they type into Google.

Every time a user types a query into Google, they are trying to accomplish something.  Whether that query is informational, transactional, or navigational, there’s always an end goal associated with a query.

And this is exactly what Google is trying to cater to.

Believe it or not, Google’s main aim is to ensure the best possible user experience by providing the right content, to the right user, at the right time.  In order to do this Google changes its algorithms around 500 to 600 times every year, which roughly means 1.5 changes a day, on average.

Well the short answer is, you can’t. But what you can do and what most of the SEO community has realized is that, as futile as it may be to keep up with the changes that Google implements, it’s much easier to align your goals with Google. This means trying to provide the user with the best experience possible by optimizing your content and your keywords for the real people behind the search queries.

The shift to user intent began in 2013 when Google rolled out the Google Hummingbird update. Unlike Google’s previous major algorithm updates (Penguin, Panda etc.) Hummingbird was actually a completely new search algorithm that Google started using, as opposed to updates to an existing algorithm.

Hummingbird was the first major update by Google which focused on the user. It was released with the intent to provide the best answers in response “conversational” user queries.  It meant that search was no longer geared towards matching the right keywords but instead finding the intent and the context behind the queries typed by the user.

Bill Slawski from SEObytheSea provides a good example of Hummingbird’s attempts to understand conversational queries

In this case, Bill looked at the query “What is the best place for Chicago Style Pizza”.

Previously, in response to this query, Google would have analyzed all the keywords in the query and provided results on the basis of relevance/ match.  However with Hummingbird, Google is able to infer that the term “place” could contextually mean two things:  ‘restaurant’ or ‘finish’.

Now comparing these two options with the other keywords in the query Google is able to discern, and is more confident that when the user types “place”, he/she intends to search for a restaurant in this context.

With the advent of Google voice search and Google Glass it is understandable that the major driving force behind Hummingbird was to better understand conversational queries. No longer were users limited to interacting with Google through their keyboard, with Google’s voice search users could simply ask Google their queries with the expectation that Google understands them and provides concise contextual answers.

Through the years since Hummingbird was first released the algorithm has undergone consistent updating which has led to the new age of Latent Semantic Indexing (LSI).

To better understand LSI lets first take a look at semantic search

Google defines semantics as “the branch of linguistics and logic concerned with meaning”

In our context semantic search essentially means improving search results by focusing on search intent to provide contextually relevant answers in response to a search query.

For example: Let’s say you go up to a friend and ask him “Have you seen the new Suits?” Now on the basis of the context of your query your friend infers that you don’t mean the clothing item suits rather the television show Suits, and answers accordingly. A search engine however would have had a hard time discerning the real intent behind this query.

However in a Post Hummingbird world, search engines are able to better understand user search intent by figuring out the contextual relationship between search entities to provide relevant results.

Essentially LSI is the process of analyzing a document to find the underlying contextual meaning/real meaning behind the document.

Co-citation and Co-occurrence are essentially two phenomenon interlocked with latent semantic indexing.  They help us understand LSI better and in turn we can leverage them to our own advantage.

It might be easier to understand co-citation with visual aids so here are a couple from the Kissmetrics blog

Two websites with similar content might be interlinked with each other in the eyes of Google even if the two websites don’t have external links linking out to each other. This occurs when two websites within a particular niche, link out to a common website also in the same niche. Google recognizes this association between the websites and thereby infers a connection between the two websites.

Without Co-occurrence there cannot be co-citation

Co-occurrence unlike co-citation goes beyond websites. Google uses co-occurrence to create connections between keywords and your website.  Google won’t assume synonymity between the keyword and your website; rather if your website frequently gets mentioned within the context of a keyword then Google will come to associate the two.

For instance let’s say you own a restaurant renowned for its chocolate cake, when Google notices that the brand name of your restaurant and the keyword “chocolate cake” are being mentioned often throughout the web, from satisfied customer reviews, in community forums etc. it associates the keyword “chocolate cake” with your brand/restaurant. Further Google might rank the website of your restaurant for “chocolate cake” related queries.

The thinking behind this is that since your brand name and the keyword are being mentioned together often, Google thinks that there must be some sort of contextual relevance between the two and hence associates that keyword with your brand.

It seems like Google’s intention with co-occurrence and co-citation is to make it easier for websites with little to no SEO to rank in the SERP’s. With the obvious caveat of having relevant content which satisfies user intent.

It might also be the reason why some web pages rank for certain queries even though the keywords in the query aren’t present in the anchor text, Meta description or even the body of the webpage.

Rand Fishkin from Moz highlighted this phenomenon in a video during the early years of co-citation

With Google constantly implementing and improving such a ground breaking algorithm, search marketers have to adapt their strategies to better serve the common goal that is user intent.

One of the reasons why LSI was introduced was to counter search marketers obsession with keywords and one of the oldest SEO practices, Keyword Stuffing.

“”Keyword stuffing” refers to the practice of loading a webpage with keywords or numbers in an attempt to manipulate a site’s ranking in Google search results. Often these keywords appear in a list or group, or out of context (not as natural prose). Filling pages with keywords or numbers results in a negative user experience, and can harm your site’s ranking.”



Keyword stuffing essentially involves deliberately mentioning your keyword, which you want to rank for, into your content so that Google ranks your page for that keyword.

However with LSI Google understands the context of content better and cares less about matching a specific keyword to the search query. Thereby ranking on the basis of contextual relevance and quality of content.

Basically Google will provide users with the pages which it feels are in the best position to answer the query of the user not the page with the most keywords matching the search query.

Remember you’re less likely to get penalized by Google for continually using your head keyword in your content especially if it makes sense to use it, however the problem arises while deliberately stuffing long tail keywords into your content.

For instance continually repeating a keyword like “New York” probably won’t get you penalized however incorporating a long tail keyword like “New York best cheap restaurant” will make your content look spammy and Google is more likely to red flag your website.

It would be a much better practice to include natural sounding phrases like “one of the best restaurants in New York” or “budget restaurants in New York”.

LSI keywords are keywords which are semantically linked to a particular keyword. In other words they are keywords which are related and can be used synonymously with that particular keyword.

Adding LSI keywords makes your content flow better, improving the quality of your content. It also makes it easier for Google to figure out what your website is about and in turn Google can rank you for relevant queries and direct the right kind of organic traffic towards your website.

There are a multitude of tools that’ll help with finding LSI keywords, here’s a few to help you get started:

So how do you find the right LSI keywords to integrate into your content strategy?

Most of these tools will generate LSI keywords on the basis of a particular algorithm so they will often include very broadly related and some completely unrelated and spammy/robotic looking keywords.

So it is vital to filter out these unrelated keywords and use only the ones that have some kind of contextual relevance to your focus keyword.

If you’re having difficulty finding relevant LSI keywords for your focus keyword, here’s a solution, just google it.

Brian Dean in this post highlights how you can use Google’s “Search related to” to find relevant LSI keywords for your content.

Keep it simple, Google your focus keyword and scroll down in the result page and you’ll find your LSI keywords. There might still be some irrelevant keywords included so be careful.

Now that you’ve got your LSI keywords it is important to integrate them into your content so it feels natural. Never try to force or shoehorn any keywords into your content, sprinkle LSI keywords wherever necessary and always aim to provide meaningful content for your readers.

Google is getting really good at discerning and ranking on the basis of user intent and with that in mind it makes sense to focus on user intent and optimize your content not just for search engines but most importantly for the actual real human beings, regardless of keyword presence.

However having said that targeting and optimizing for keywords isn’t completely dead. It’s still a valid strategy but with Google shifting its focus to catering to user intent, it means that this strategy is becoming less effective. Keywords are still vital in the SEO world but the way in which we use keywords is constantly evolving.|||

Google is focusing more on their users and search user intent, could it spell the end of traditional keyword based SEO. Read on to find out more.