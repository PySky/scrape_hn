SyNAPSE is a DARPA-funded program to develop electronic neuromorphic machine technology that scales to biological levels. More simply stated, it is an attempt to build a new kind of computer with similar form and function to the mammalian brain. Such artificial brains would be used to build robots whose intelligence matches that of mice and cats.

SyNAPSE is a backronym standing for Systems of Neuromorphic Adaptive Plastic Scalable Electronics. It started in 2008 and as of January 2013 has received $102.6 million in funding. It is scheduled to run until around 2016. The project is primarily contracted to IBM and HRL who in turn subcontract parts of the research to various US universities.

The ultimate aim is to build an electronic microprocessor system that matches a mammalian brain in function, size, and power consumption. It should recreate 10 billion neurons, 100 trillion synapses, consume one kilowatt (same as a small electric heater), and occupy less than two liters of space.

As of January 2013 the program is currently progressing through phase 2, the third of five phases. This involves, among other things, designing a multi-chip system capable of emulating 1 million neurons and 1 billion synapses. The initial program requirements were that no phase should last longer than 18 months. This means the million-neuron design should be complete by February 2013. Construction of the system will come in phase 3, to be completed around August 2014.

The following text is taken from the Broad Agency Announcement (BAA) published by DARPA in April 2008 (see the original document):

Over six decades, modern electronics has evolved through a series of major developments (e.g., transistors, integrated circuits, memories, microprocessors) leading to the programmable electronic machines that are ubiquitous today. Owing both to limitations in hardware and architecture, these machines are of limited utility in complex, real-world environments, which demand an intelligence that has not yet been captured in an algorithmic-computational paradigm. The SyNAPSE program seeks to break the programmable machine paradigm and define a new path forward for creating useful, intelligent machines.

The vision for the DARPA SyNAPSE program is the enabling of electronic neuromorphic machine technology that is scalable to biological levels. Programmable machines are limited not only by their computational capacity, but also by an architecture requiring human-derived algorithms to both describe and process information from their environment. In contrast, biological neural systems autonomously process information in complex environments by automatically learning relevant and probabilistically stable features and associations. Since real world systems are always many body problems with infinite combinatorial complexity, neuromorphic electronic machines would be preferable in a host of applications - but useful and practical implementations do not yet exist.

The key to achieving the vision of the SyNAPSE program will be an unprecedented multidisciplinary approach that can coordinate aggressive technology development activities in the following areas: 1) hardware; 2) architecture; 3) simulation; and 4) environment.

Realizing this ambitious goal will require the collaboration of numerous technical disciplines such as computational neuroscience, artificial neural networks, large-scale computation, neuromorphic VLSI, information science, cognitive science, materials science, unconventional nanometer-scale electronics, and CMOS design and fabrication.

No phase should last more than 18 months. The following targets were specified in 2008 before the project started. The targets for each phase may have changed in the meantime depending on the outcome of completed phases.

Feasibility study for nine months. Funding of at least $10.8m. Started November 2008, completed ~August 2009.

Architecture: Specify and validate by simulation the function of core microcircuit assemblies using measured synaptic properties. The chosen microcircuits must support the larger system architecture and demonstrate spike time encoding, spike time dependent plasticity, and competitive neural dynamics.

In August 2009 IBM and HRL received $16.1m and $10.7m respectively to carry out phase 1. The phase started ~November 2009 and completed ~July 2011.

As of January 2012 this is the current phase. Funding of $17.9m awarded to HRL in July 2011, and $21m awarded to IBM in August 2011.

Estimated to begin between late 2012 and late 2013.

The final deliverable metric is the fabrication of a multi-chip neural system of 108 neurons (100 million) and install this in a robot that performs at cat level. Estimated to begin between late 2013 and late 2015. Estimated completion date, late 2014 to late 2017.

IBM developed a massively parallel cortical simulator called C2. It ran on the Blue Gene/P supercomputer named Dawn (pictured right) at Lawrence Livermore National Laboratory. The supercomputer had 147,456 CPUs and 144 terabytes of main memory. The largest cortical simulation consisted of 1.6 billion neurons and 8.87 trillion synapses. This matches the scale of a cat cortex and 4.5% the scale of a human cortex. The simulation ran at 643 times slower than real time. The simulations incorporated single-compartment spiking neurons, STDP, and axonal delays. The simulation time step was 0.1 milliseconds.

The architecture and connectivity of the simulated network was biologically inspired (see image right). It included the visual cortex, attendant sections of the thalamus, and the reticular nucleus. Regions of the simulated cortex were constructed from thalamocortical modules. Each module had 10,000 cortical neurons, 334 thalamic neurons, and 130 reticular nucleus neurons. Within each module, cortical neurons were further subdivided into four layers (real mammalian brains have six layers). The ratio of excitatory to inhibitory neurons was also modelled on experimentally observed data. The largest model had 278 x 278 modules making a total of 1.6 billion neurons.

The SpikeStream was a framework to supply sensory stimulus information encoded in spikes. The spikes were encoded to represent geometric visual objects and auditory utterances of the alphabet.

The BrainCam was a framework that recorded the firing of all neurons and converted them to a movie for convenient visualisation - similar in concept to an EEG trace. A video (150 MB mpeg) is available showing how a stimulus in the shape of the letters "IBM" propagates. The speed and pattern of propagation matches observations made in animals. The simulations also reproduced alpha waves (8 to 12 Hz) and gamma waves (>30 Hz) as often seen in the mammalian cortex.

Future plans are to enrich the model with long-distance connectivity between cortical areas. Also, to increase resolution by reducing the size of each module from 10k neurons down to 100 neurons - to pair with latest experimental results. It is predicted that a 100% human scale, real-time simulation would require 4 petabytes of memory and a supercomputer running at >1 exaflops. This should be achieved by the year 2018 if general advances in supercomputer technology continue at the same rate as they have in recent decades.

Update: The C2 was superseded in 2012 by Compass, see details below.

Shortly after IBM announced their cat-scale brain simulation, Henry Markram of the Blue Brain Project published a very strong criticism of the claim. He called it "a mega public relations stunt - a clear case of scientific deception of the public". As Markram wrote in an open letter, these simulations do not come close to the complexity of an ant brain, let alone that of a cat brain.

Markram's first argument was that although the number of simulated neurons roughly equals that of a cat brain, the model used for each individual neuron was trivially simple. The neurons were modelled as single compartment "dots" completely lacking in biological realism. Genuine simulation of real neurons requires solving millions of times more equations than were used by IBM. Thus, not even a millionth of a cat brain was simulated.

The second argument was that such large-scale simulations of trivial neurons have been performed a number of years previously already. Indeed, Eugene Izihkevich (now CEO of Brain Corporation), carried out a 100-billion neuron simulation back in 2005. The non-peer reviewed paper published by IBM was thus nothing new or interesting.

The full letter from Henry Markram: IBM's claim is a hoax

In August 2011 IBM revealed that they had built a digital neurosynaptic core. The microprocessor implements 256 leaky integrate-and-fire neurons in CMOS hardware. The neurons are arranged in a 16x16 array. Each neuron is connected to others by 1,024 synapses, making a total of 262,144 synapses per core.

A 45 nm SOI manufacturing process was used. This was state of the art in retail laptop computers in 2008. The newest laptops ship with 22 nm processors as of August 2012. The entire core has 3.8 million transistors and fits inside 4.2 mm2. Each neuron occupies 35 μm x 95 μm Compare this to a real neuron body which is about 4 to 100 μm in diameter.

The core was mounted on a custom-built printed circuit board and connected to a personal computer via USB. This way it could be interfaced to various virtual and real environments. The core learned to recognise handwritten digits (see video) and could also play a game of pong (see video).

The core was completely deterministic. This is unlike previous analog neuromorphic hardware which is sensitive to construction variations and ambient temperatures. The chip had a ~1 kHz clock, corresponding to ~1 ms biological time step. Internally a ~1 mHz clock was also used for other processing.

Unlike the traditional Von Neumann computer architecture, the computation and memory units of this chip are tightly integrated. This speeds up highly parallel computation as well as reducing the power required. It is theoretically possible to build a large on-chip network of these cores, thus creating an ultra-low power "neural fabric" for a wide array of real-time applications. The ultimate aim is to build a human-scale system with 100 trillion synapses.

In June 2012 the SyNAPSE team presented a system that used the above described neuromorphic chip to capture the essential functional properties of the glomerular layer of the mammalian olfactory bulb. The neural circuits configured in the chip reflected connections among mitral cells, periglomerular cells, external tufted cells, and superficial short-axon cells within the olfactory bulb.

The circuits, consuming only 45 pJ of active power per spike with a power supply of 0.85 V, could be used as the first stage of processing in low-power artificial chemical sensing devices.

The so-called "brain wall", pictured here, is a visualisation tool built by IBM at their Almaden research center in California. It allows researchers to see an overview of neuron activation states in a large-scale neural network. Patterns of neural activity can be observed as they move across the network.

The 4x4 array of flat-screen monitors can display 262,144 neurons simultaneously. Each neuron is represented by one grey pixel. Larger networks might be visualised in future by grouping multiple neurons per pixel. The tool can be used to visualise supercomputer simulations as well as activity within a neurosynaptic core.

See a timelapse video of the brain wall construction.

HRL Labs announced in December 2011 that they have built a memristor array integrated on top of a CMOS chip. This was the first ever functioning demonstration of such a memristor array.

Due to the high circuit density and low power requirements, memristor technology is considered important for the continuation of Moore's Law. The HRL chip has a multi-bit fully-addressable memory storage capability with a density of up to 30 Gbits/cm2. Such density is unprecedented in microelectronics.

The simultaneous memory storage and logic processing capability of memristors makes them very suitable for neuromorphic computing. The memory and logic units are one and the same, much like the neural circuits of the brain.

HRL's hybrid crossbar/CMOS system can reliably store 1,600 pixel images using a new programming scheme. Ultimately the team plans to scale the chip to support emulation of millions of neurons and billions of synapses. The work to-date was jointly funded by the SyNAPSE program and the National Science Foundation (NSF).

In the future it is possible that this memristor technology can be used to implement variants of the neurosynaptic core described above. By using memristors, these cores could be reduced in size and energy consumption, thus making it more practical to build very large arrays of cores with sufficient numbers of neurons to match the human brain.

This neuromorphic architecture (pictured right) contains 766 spiking artificial neurons arranged in layers much like the heirarchy found in the human brain. Although it uses simple leaky integrate-and-fire (LIF) neurons and simple binary synapses, it is nevertheless capable of robust visual object recognition, motion detection, attention towards important objects, and motor control outputs. This has been proven by testing the network in simulation on a standard computer. The network utilizes burst-STDP and synaptic homeostatic renormalization - two relatively new ideas in the field of spiking neural networks.

The architecture has been designed with a view to deploying it on the digital neurosynaptic cores described above. IBM are currently (as of 2012) working on inter-core communication to build a large on-chip network of these cores. Once this hardware is available it can be used to deploy the neural network architecture described here. The 766-neuron circuit is only a "minimum framework" prototype. It is expected to be scaled up to thousands or hundreds-of-thousands of neurons as the hardware becomes available.

Paper: A Neuromorphic Architecture for Object Recognition and Motion Anticipation Using Burst-STDP - May 2012

TrueNorth is a novel modular, scalable, non-von Neumann, ultra-low power, cognitive computing architecture being developed by IBM as part of the SyNAPSE program. It consists of a scalable network of neurosynaptic cores, with each core containing neurons, dendrites, synapses, and axons.

Compass, also developed by IBM, is software that simulates the TrueNorth architecture. It enables testing of the architecture on a mainstream supercomputer before being built directly in specialised neuromorphic hardware. Besides being a multi-threaded, massively-parallel functional simulator, Compass is also a parallel compiler that can map a network of long-distance neural pathways in the macaque monkey brain to TrueNorth.

IBM and LBNL ran Compass on 96 Blue Gene/Q racks of the Lawrence Livermore National Lab Sequoia supercomputer. At the time Sequoia was the world's most powerful supercomputer (TOP500 ranking). The 96 racks comprised 1,572,864 processor cores and 1.5 petabytes of memory. The system was able to simulate a TrueNorth architecture to the scale of 2.084 billion neurosynaptic cores containing 53x1010 neurons and 1.37x1014 synapses. The neurons had an average spiking rate of 8.1 Hz, although they ran 1,542x slower than real time. The system demonstrated near-perfect weak scaling.

By comparison, the ultimate vision of the DARPA SyNAPSE program is to build a cognitive computing architecture with 1010 neurson and 1014 synapses. This approximates the number of neurons and synapses that are estimated to be present in the human brain.

Note that although the number of neurons and synapses in the TrueNorth model match those of a human brain, the model is not a biologically realistic simulation of the brain. Rather, IBM has simulated a novel modular, scalable, non-von Neumann, ultra-low power, cognitive computing architecture to a scale that is inspired by the number of synapses in the brain. Computation ("neurons"), memory ("synapses"), communication ("axons", "dendrites") are mathematically abstracted away from biological detail towards engineering goals of maximizing function (utility, applications), minimizing cost (power, area, delay), and minimizing design complexity of hardware implementation.

Compass has been used to demonstrate numerous applications of the TrueNorth architecture, such as optic flow, attention mechanisms, image and audio classification, multi-modal image audio classification, character recognition, robotic navigation, and spatio-temporal feature extraction. These applications will be published in the coming months.

IBM and Cornell University's neuromorphic computing lab are currently (as of January 2013) working on the second generation of neurosynaptic processors. The neurosynaptic cores, like the first generation, will emulate 256 neurons each. The inter-core communication, however, has been developed and the new processors are expected to contain around 4,000 cores each. This will make for a total of around 1 million neurons per processor. These new chips are expected to be announced in early 2013, possibly in February or March.

The following organisations are collaborating in the DARPA SyNAPSE program. The main two contractors are IBM and HRL. They, in turn, sub-contract out to various universities and companies.

All funding for the SyNAPSE program comes from DARPA. Total funding per fiscal year (FY) is as follows. Note that US government fiscal years begin on October 1 of the previous year. So FY 2013 runs from October 1, 2012 to September 30, 2013. The budgets are published in advance each year in February, so the FY 2014 budget is due to be published in February 2013.

From the above funds, awards were made to IBM and HRL as follows:

An award was also made to HP Labs for phase 0 of the project, but the amount is not known.|||

