Build an elastic (i.e. horizontally scalable) system that uses deep convolutional neural networks to perform face detection and recognition in the cloud.

Serverless compute platforms such as Amazon Web Services (AWS) lambda were intended to be used for web microservices and to asynchronously handle events generated by AWS services (S3, DynamoDB, etc.). However, AWS lambda allows users to upload arbitrary linux binaries along with their lambda functions. These binaries can be executed during a lambda invocation, effectively turning AWS lambda into a supercomputer that can be started on-demand in seconds and billed at a 100ms granularity.

We take advantage of this feature and run a full-blown deep convolutional neural network based face recognition tool (openface) on AWS lambda. The code in this repository gives you everything you need to deploy this system onto your AWS account and start detecting/recognizing faces in jpeg images! (with zero configuration or model tuning!)

In the AWS region , a normal user can run up to 600 lambda functions concurrently (as of April 10th, 2017). This enables our system to perform 600 face recognition operations at the same time! (and more parallelism is available if the system is deployed to additional AWS regions!) The ability to scale out horizontally with virtually no additional effort is a tremendous asset; for example, we can perform face recognition across every frame in a video or provide a scalable face recognition microservice as part of a larger application. The possibilities are endless!

install pip and virtualenv if necessary $ curl -O https://raw.github.com/pypa/pip/master/contrib/get-pip.py $ python get-pip.py $ pip install virtualenv clone the repo and install awscli and boto3 $ git clone https://github.com/excamera/AWSLambdaFace.git $ AWSLambdaFace $ virtualenv .venv $ .venv/bin/activate $ pip install -r requirements.txt setup the awscli (create an access key and enter details below) $ aws configure AWS Access Key ID []: ANWQ AWS Secret Access Key []: JawS Default region name []: us-east-1 Default output format [None]: download the binary blobs necessary for the face recognizer $ ./blobs/get_blobs.sh downloading... (lots of output) deploy the face recognition lambdas to your account $ ./install_lambdas.sh creating bucket uploading dependencies to s3 upload: blobs/deps.zip to s3://9a480eb7-be5b-4e15-81fe-4de41323907e/deps.zip upload: blobs/root-495M-2017-02-06.tar.gz to s3://9a480eb7-be5b-4e15-81fe-4de41323907e/root-495M-2017-02-06.tar.gz upload: blobs/lfw_face_vectors.csv.gz to s3://9a480eb7-be5b-4e15-81fe-4de41323907e/lfw_face_vectors.csv.gz adding role adding lambda adding lambda Done

To see how things work let's jump into a simple example. The following snippets will generate a model to recognize John Emmons' face, then use the model to check if John's face is in a photo.

Hi! My name is John Emmons; I am a computer science PhD student at Stanford University who works on problems at the intersection of computer system and machine learning (primarily computer vision).

If you like this work and want to learn more about it, feel free to drop me a line a mail@johnemmons.com. And if this work inspires you to do your own related work, please cite our research group! (see below)

This work was done as part of preparing a demonstration for ExCamera [pdf], which was presented at NSDI'17. I would like to thank all of the authors on the ExCamera paper for giving me inspiration for this project and for helping me with the system design aspects.

I would also like to give special thanks to Sadjad Fouladi and Deepak Narayanan for their invaluable comments while I wrote this README. And finally I want to give a shout-out to Luiz Gustavo de Souza for pointing out grammatical and spelling mistakes in the README.|||

AWSLambdaFace - Perform deep neural network based face detection and recognition in the cloud (via AWS lambda) with zero model configuration or tuning.