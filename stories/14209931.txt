Or she might not.  This could go wrong in many ways, but let’s say we’ve filtered out the non-useful facts and what we are left with is the golden nuggets of trade.  We’re still left with:

What’s in a name?  A rose by any other…

Why does he care?

What incentive does he have to tell the truth?

What incentive does he have to do a good job?

Is the fact within reliable?

Was it reliable then, is it reliable now, will it be reliable tomorrow?

Chief amongst our concerns is that the edges as collected might be unreliable.  I.e., what happens if my name is not Alice?   Or if I work next door to Broker A and just snuck in to use their terminals one night?  Or, any one of a thousand scenarios - the conclusion here is that while the fact might still be a fact, in that Bob said those words, it might not be an accurate or reliable representation of the real world.  If such happens, then the golden analysis above turns to fool’s gold.

The Source of Our Unreliability

The reasons that any given fact might be unreliable are legion – I once wrote down 99 of them.  We could dutifully promise to take more care, but this hasn’t worked well in the past.  We need better than marketing and empty campaign promises to make this work.  Luckily we’ve got some more clarity on why a fact isn’t reliable and how to fix it.  Four techniques will create a foundation for the facts:

1/ Skin in the game – every agent needs to be not only positively incentivized to work in this relationship building, but also positively corrected when things go wrong.  There needs to be what the engineers call a negative feedback loop – one of correcting capability.

2/ Quality control – if the above correction is dramatic, we need a way to show that the agent has done a good job.  Statements are in words and they can be both wide of the mark and misinterpreted.  To address this, we can set up-front minimum quality standards that are clear and applicable to both the makers of facts and to the users of the facts, or “relying parties,” and operate them diligently.

3/ Redundancy in sources – to get a single complete accurate fact is very expensive, but to get many small facts converging on the same approximate large truth is cheap.

4/ Authorities in sources – some facts are ‘owned’ by certain parties, and if we can get them on board in a secure context then we can improve the quality, at least in their facts.

These should be familiar, and will create a base of reliability but we need more.

To be useful to Carol, we need the facts to be not only reliable, but exportable.  That is, suitable for other people to rely on the facts in their own risk assessment.  We can do this in the first two basic ways as listed above:

Firstly, by setting liabilities for poor work, especially but not only by not following the standard of the second way.

Secondly, by setting up front and operating to a minimum quality standard that is clear and applicable to both the makers of facts, and to the “relying parties” of the facts.

Imposing liabilities for poor work needs to be done carefully because there are two general possibilities, being

–       the work and care that is done in creating the fact, which has one value, and

–       the damage that can result from relying on the fact, which damage has another value.

These two values are sometimes wildly different.

In general, it is harder to assess liabilities to the damage that can result in advance because it is implausible to predict to what use the facts are put.  This is what the cryptographers call the problem of Grandma’s house:  if I sign that Mallory is a good guy, and Grandma relies on my statement, but the result is that Grandma loses her house, who’s to blame?   One school has it that she fairly relied on me, so I have to pay her a house.  Another school has it that because I only reviewed Mallory’s passport, it is a process or administrative implication and no more, and back to passport-review school I go.

Which is it?

To cut the Gordian knot, we typically place such problems before a resolver of disputes, a person who can decide which of the interpretations apply.  This accepts that we are entirely uncertain how a given dispute will pan out, both I and Grandma, but we know that it will resolve one way or another.  So, and this uncertainty is the crux of the argument, I will probably do a better job than merited because my liabilities may go sky-high, and Grandma won’t put her house to the gamble of one claim, because her assets may go to rock bottom!

But, if my liabilities could go sky-high, why would I ever get involved?  It is for this reason that I need to be protected by a standard approach – one that is well thought out, agreed, documented and auditable.  Especially, that last step is what will convince an Arbitrator that I have done the job I was asked to do.

A good liabilities framework then is initially limited to the correctness of the facts.  However, in order to get any traction on relying on those facts, we at least need to improve the quality of the facts such that they are reliable – they meet a minimum bar to allow others to rely on them.

Hence, while the liability solution is initially necessary to address the liabilities incurred when one person relies on a fact produced by another, it has another side-effect - it improves the quality by encouraging the provider of the fact to take especial care up front, as if they are liable to another person not as yet identified for risks not as yet quantified.  For this reason, we need to protect the provider of the facts with a standard to follow, so that they are not on the hook for impossibly high liabilities from a simple process operation.

In the typical alternate approach, the provider of facts asserts zero liability, as that is the only business solution to unpredictable liabilities.  But, this is what we call a positive feedback loop, in which the provider gets paid for good and bad results, equally.  In a positive feedback loop, activity grows and grows until the machine destroys itself.  As there is no correction when the machine goes off the rails, a lack of liability also means a lack of accountability, and in that scenario, there is an unfortunate consequence:  the quality of the data shrinks to nothing.  In effect, the zero-liability solution causes a race to the bottom, and the provider prints unreliable statements without limit.|||

