I still visit my research lab quite often. Itâ€™s always nice to be in the zone where boundaries of knowledge are being pushed further and excitement is in the air. I like this ritual as this is a place where oneÂ canÂ discuss linux kernel code and philosophy of life all in a single sentence while we quietly sip our hipsterÂ coffee cups.

In theÂ lab, Abder is working these days on some cool hypercall stuff. The exact details of his work areÂ quite complex, but he calls his tool hypertrace. I think I am sold on the name already. Hypercalls are likeÂ syscalls, but instead of such calls going to a kernel, they are made from guest to the hypervisor with arguments and an identifier value (just like syscalls). The hypervisor then brokers the privileged operation for the guest.Â Pretty neat. Here is some kernel documentation on hypercalls.

So AbderÂ steered one recent discussionÂ towards internals of KVM and wanted to know the latency caused by a hypercall he was introducing for his experiments (as I said he is introducing new hypercall with an id â€“ for example 42). His analysis usecase was quite specific â€“ he wanted to trace the sequence to know the exact latency he was causing for a given duration. In addition the tracing overhead needs to be minimum and is for a short duration only. This is somewhat trivial. These 3 tracepoints are there in the kernel already and he could latch on to them. Essentially, he needs to look forÂ  argument ofÂ the tracepoint and it should be aÂ  (18), which would denote that a hypercall is coming up next. Then he could look at the next event and find the time-delta to get the latency. Even though it isÂ possible by traditional tracing such as LTTng and Ftrace to record events, AbderÂ was only interested in his specific hypercall ( = 42) along withÂ the that happened before (with = 18) and after that. This is not straightforward. Itâ€™s not possible to do such specificÂ tracingÂ with traditional tracers at a high speed and low overhead. This means the selection of events should not just be a simple filter, but should be stateful. Just when AbderÂ was about to embark on a journey of kprobes and kernel modules, I once more got the opportunityÂ of being Morpheus and saidÂ â€œWhat if I told youâ€¦â€œ

Jokes apart, here is a small demo of eBPF/BCCÂ script thatÂ allows us to hook onto the 3 aforementioned tracepoints in the Linux kernel and conditionally record the trace events:

The interface in BCC allows usÂ to use static tracepoints in the kernel. For example, wheneverÂ a occurs in the kernel, the first probe is executed and it records the eventÂ if the exit reason was . At the same time it updates a BPF hash map, which basically acts like a flag here for other events.Â I recommend you to check out Lesson 12 from the BCC Python Developer TutorialÂ if this seems interesting to you ðŸ™‚ In addition, perhaps the referenceÂ guideÂ lists the most importantÂ C and Python APIs for BCC.

To test the aboveÂ example out, we can introduce our own hypercall in the VMÂ using this small test program :

While the BPF program is running, if we do a hypercall, we get the following output :

So we see how in a few minutes we could precisely gather only those events that were of interestÂ to us â€“ saving us from the hassle of setting up other traces or kernel modules. eBPF/BCC based analysis allowed us to conditionally trace only a certain subsection of events instead of the huge flow of events that we would have had to analyze offline. KVM Â internals are like a dark dungeon and I feel as if I am embarking on a quest here. There are a lot more upcoming KVM related analysis we are doingÂ with eBPF/BCC. Stay tuned for updates!Â If you find any more interesting usecases for eBPF in the meantime, let me know. I would love to try them out! As always, comments, corrections and criticisms are welcome.|||

I still visit my research lab quite often. It's always nice to be in the zone where boundaries of knowledge are being pushed further and excitement is in the air. I like this ritual as this is a place where oneÂ canÂ discuss linux kernel code and philosophy of life all in a single sentence while weâ€¦