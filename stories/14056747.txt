April 4, 2017



Machine Learning and Social Norms



Algorithms, including those that can learn to predict from historical data, are making increasingly consequential decisions about the lives of individual citizens in domains as diverse as advertising, credit, employment, education, and criminal sentencing. This trend has been accompanied by increasing concern and alarm over potential erosions of privacy, fairness, transparency, and accountability. Recent research in machine learning seeks to quantify the extent to which such social norms can actually be embedded in these algorithms, and the tradeoffs presented with predictive accuracy and other measures of utility. Michael Kearns will describe some of these developments, with a focus on what it means for machine learning to be “fair.”



Kearns is a professor in the Computer and Information Science Department at the University of Pennsylvania, where he holds the National Center Chair. He has secondary appointments in the Department of Economics, and in the departments of Statistics and Operations, Information, and Decisions in the Wharton School. He is the founding director of the Warren Center for Network and Data Sciences and the founding co-director of Penn Engineering's Networked and Social Systems Engineering Program. He is chief scientist of MANA Partners, a trading, technology, and asset management firm.|||

April 4, 2017 Machine Learning and Social Norms Algorithms, including those that can learn to predict from historical data, are making increasingly consequen...