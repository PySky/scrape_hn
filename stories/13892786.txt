Adobe, one of the world’s largest and most powerful software companies, is trying something new: It’s applying machine learning and image recognition to graphic and web design. In an unnamed project, the company has created tools that automate designers’ tasks, like cropping photos and designing web pages. Should designers be worried?

The new project, which uses Adobe’s AI and machine learning program Sensei and integrates into the Adobe Experience Manager CMS, will debut at the company’s Sneaks competition later in March. While Adobe hasn’t committed to integrating it into any of its products, it’s one of the most ambitious attempts to marry machine learning and graphic design to date. There have been efforts to use AI in the design world before–for instance, Wix’s Advance Design Intelligence and automated projects like Mark Maker, but Adobe’s is notable because of the company’s sheer reach in the design world. Although it’s just a prototype, it’s one to watch closely.

The as-of-yet unnamed new product is designed, first and foremost, to make it easier to customize websites for users at large-enterprise customers. When I viewed a demo, for instance, machine learning and AI techniques were applied to editing the Food Network’s web pages.

Instead of a designer deciding on layout, colors, photos, and photo sizes, the software platform automatically analyzes all the input and recommends design elements to the user. Using image recognition techniques, basic photo editing like cropping is automated, and an AI makes design recommendations for the pages. Using photos already in the client’s database (and the metadata attached to those photos), the AI–which, again, is layered into Adobe’s CMS–makes recommendations on elements to include and customizations for the designer to make.

According to Cedric Huesler, a product management director for Adobe Marketing Cloud who worked on the project, the idea is offering what he calls “human-augmented” design. The AI offers recommendations, which designers can manually override.

“The problem, obviously, is personalization at scale,” Huesler tells Co.Design. “We can repeat the same process just by providing different inputs”–once implemented, the machine learning tool is designed to let large-enterprise users quickly generate customized content. In the case of large-enterprise customers like the Food Network, Adobe says, partial automation lets them create customized web and mobile experiences for customers more quickly and more affordably than they could otherwise.

The AI is meant to make design easier for large projects. It includes both image recognition components that automatically crop or otherwise edit photos, and more conventional components that rely on text metadata for design decisions.

Huesler points out that, in the Food Network example, content could be instantly customized for users. For example, users whose activity indicates they are lactose intolerant or gluten intolerant will see different recipes and images highlighted. The machine learning product won’t actually handle the heavy lifting of reimagining an interface and making complicated UI or UX decisions. But it can, for instance, help quickly determine what photos and text content are ported onto pages designed for very small user segments.|||

An experimental Adobe project brings machine learning and artificial intelligence to the graphic and web design worlds. That might not be a bad thing.