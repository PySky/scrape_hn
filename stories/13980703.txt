Need an easy, cheap, and powerful way to play with PostGIS? In the past few months I’ve settled into a cloud-based workflow that allows me both to inexpensively tinker with PostGIS and to run massive queries without tying up my local box. Let me tell you how to set it all up.

But first, why not run it locally?

If you don’t already have an account at Linode, go make one. In my personal tests, Linode handedly beats out Rackspace and Digital Ocean in performance, while being considerably less expensive. For example, a 4-core, 8GB instance at Digital Ocean is $80/mo, but the same thing at Linode is $40/mo, and the Linode is faster. Others have made similar comparisons to AWS.

Now spin up an instance. I generally like 8GB of RAM or more, but if you’re just tinkering you can do whatever you want. Deploy the Debian 8 image to your newly-created Linode. Boot your server, wait a couple minutes, then log in via SSH.

To install, run the following:

Now we need to create an image. Linode’s UI and imaging isn’t the best, so follow along closely.

That’s it! You now have an image you can quickly deploy all ready to run PostGIS (or anything in Docker, for that matter). Next time you create a Linode, deploy your new image instead of Debian 8.

I like to call the container “pg” ( ), and put its data in the folder “96” since sometimes I’ll switch versions ( ). Its port is opened on localhost ( ), so tools like can act like it’s local and I can connect directly via Navicat or similar from my local box.

To get the most out of Postgres, we should tweak its config. Open up in vim (or your favorite editor), and change the following (I’m assuming 8GB of RAM–adjust accordingly):

Once the config is saved, we can simply destroy the container and start it again with the same command:

PostgreSQL will be restarted with the new settings.

Obviously we want to load some cartography into PostGIS and run queries, so let’s download and import last month’s (2/17) precipitation data for the whole US:

For more explanation of , have a look at the docs or Boston GIS’s excellent cheatsheet.

Let’s find the average rainful within 200 miles of Dallas:

This workflow wouldn’t be complete if you had to start from scratch every time. I like to upload my database to S3 before deleting the server. Assuming you’ve already run , do something like this:

Next time you start up a server, just pull down your archive and pick up where you left off:|||

Need an easy, cheap, and powerful way to play with PostGIS?