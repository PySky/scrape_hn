FastECC provides O(N*log(N)) Reed-Solomon coder, running at 1.2 GB/s on i7-4770 in (2^20, 2^19) config, i.e. calculating 524288 parity blocks from 524288 data blocks. Version 0.1 implements only encoding, so it isn't yet ready for real use.

Almost all existing Reed-Solomon ECC implementations employ matrix multiplication and thus have O(N^2) speed behavior, i.e. they can produce N parity blocks in O(N^2) time, thus spending O(N) time per block. F.e. the fastest implementation I know, MultiPar2, can compute 1000 parity blocks at the speed ~50MB/s, but only at ~2 MB/s in its maximum configuration, 32000 parity blocks. And computations in GF(2^32), implemented in the same way, will build one million parity blocks at 50 KB/s.

The only exception is closed-source RSC32 by persicum with O(N*log(N)) speed, i.e. it spends O(log(N)) time per parity block. Its speed with million parity blocks is 100 MB/s, i.e. it computes one million of 4 KB parity blocks from one million of data blocks (processing 8 GB overall) in just 80 seconds. Note that all speeds mentioned here are measured on i7-4770, employing all features available in a particular program - including multi-threading, SIMD and x64 support.

FastECC is open-source library implementing O(N*log(N)) encoding algorithm. It computes million parity blocks at 1.2 GB/s. Future versions will implement decoding that's also , although 1.5-3 times slower than encoding. Current implementation is limited to 2^20 blocks, removing this limit is the main priority for future work aside of decoder implementation.

All O(N*log(N)) Reed-Solomon implementations I'm aware of, use fast transforms like FFT or FWT. FastECC employs Number-Theoretic Transform that is just an FFT over integer field or ring. Let's see how it works. Note that below by I mean any polynomial with order < N.

For any given set of N points, only one length-N polynomial may go through all these points. Let's consider N input words as values of some length-N polynomial at N fixed points, only one such polynomial may exist.

Typical Reed-Solomon encoding computes coefficients of this unique polynomial (so-called polynomial interpolation), evaluates the polynomial at M another fixed points (the ) and outputs these M words as the resulting parity data.

At the decoding stage, we may receive any subset of N values out of those N source data words and M computed parity words. But since they all belong to the original length-N polynomial, we may recover this polynomial from N known points and then compute its values at other points, in particular those N points assigned to original data, thus restoring them.

Usually, Reed-Solomon libraries implement encoding by multiplication with Vandermonde matrix (O(N^2) algo) and decoding by multiplication with the matrix inverse.

But with special choice of fixed points we can perform polynomial interpolation and evaluation at these points in O(N*log(N)) time, using NTT for evaluation and inverse NTT for interpolation. So, the fast encoding is as simple as:

Decoding is more involved. We have N words representing values of length-N polynomial at some N points. Since we can't choose these points, we can't just use iNTT to compute the polynomial coefficients. So it's a generic polynomial interpolation problem that can be solved in O(N*log(N)^2) time.

But this specific polynomial interpolation problem has faster solution. Indeed, decoder knows values of length-N polynomial f(x) at N points a[i], but lost its values at M erasure points e[i]. Let's build "erasure locator" polynomial and compute polynomial product . We have and l(e[i])=0, so by computing values l(a[i]) and then multiplying f(x) and l(x) in the value space we can build polynomial p(x) with order<N+M described by its values at N+M points , i.e. we have fully defined p(x).

Now we just need to perform polynomial long division f(x)=p(x)/l(x), that is O(N*log(N)) operation.

But there is even faster algorithm! Let's build derivative and evaluate it at each e[i]: since l(e[i])=0. Moreover, l'(e[i])!=0, so we can recover all the lost f(e[i]) values by simple scalar divisions: !!!

So, the entire algorithm is:

transform p' and l' into value space

When M<=N, first operation on p is iNTT(2N), third operation on p' is NTT(N) since we need to compute p'(x) values only at N points corresponding to original data, and rest is either O(N) or operations on l(x) that is performed only once, so overall decoding is 1.5-3 times slower than iNTT(N)+NTT(M) operations required for encoding.|||

FastECC - Reed-Solomon coder computing one million parity blocks at 1 GB/s. O(N*log(N)) algo employing Number-Theoretic Transform.