Consider the following Dockerfile:

Since go is a compiled language, we can make our image lightweight by basing it from scratch and simply copying in our binary along with a common ca certificates bundle and that's it!

This is what I did up until the very first keynote of DockerCon 2017 where multi-stage builds were introduced!

Before we go further, we need to identify a problem, if any, with the above Dockerfile that might motivate a move towards multi-stage builds.

Before we're able to copy a binary into our container, we obviously need to build it. This would most likely be done by our build tool. We would install our dependencies, build a compiled binary for our target platform, run our test suite, and finally take our tested, compiled binary and build our lightweight container image.

We can improve this workflow by doing all of the above inside of our container, instead of our build tool. This is desirable because now you can build, compile, test, and run all on the same target platform. This would prevent a developer from mistakenly building and testing their binary for a different target platform than what will ultimately end up inside our final container. This approach is also independent of a build tool and declaratively has our entire build process in one place. Our Dockerfile to accomplish this might look like this:



 

 This build uses the base image which results in an image size of . While this might be considered a lightweight image, it's nothing compared to the image that would have been produced had we used the first Dockerfile. This is where Docker's multi-stage builds can help us out.

Multi-stage builds were officially released April 18, 2017 during the opening keynote session of DockerCon 2017. It is part of the releases. To follow along in my demo, simply make sure that your Docker for Mac or Docker for Windows version is at least . At the time of writing this, this requires using the edge release instead of the stable release.

For this demo, we'll be working with an extremely basic go webservice (this is the code that was used in the above baselines):



 

 We'll also have an extremely basic test file:



 

 Alright so let's start with the ugly, there is zero documentation about multi-stage builds...yet. Even after scouring Docker's branches on GitHub, it seems as though the docs are only current up to version (I'll attempt to keep this post up to date to reflect the current status).

Alright so let's get started. Based on our above examples, here is how our Dockerfile looks after incorporating multi-stage builds:



 

 The first thing you'll notice is that we can specify build args that are global to all of our build stages. This allows us dynamically set our base image. We can also alias our different stages using the keyword. This becomes useful when copying artifacts from one stage to the next.

Besides that, everything looks similar except that is seems we have multiple Dockerfiles in one? Each traditional Dockerfile "block" represents a stage. Artifacts can be copied from one stage to the next but only the last stage will represent the final image.

This means that we can still follow the pattern of building and testing our application inside of Docker on the same target architecture while still having our final image be minimal and lightweight! ( is also based from ) After building this image, the final size is only .



 

 If you look closely, I did change one other thing. I am no longer basing my image from but from . After a constructive debate with a coworker, I agree with him that for the extra it adds, having the ability to use a package manager for debugging purposes adds a lot of value!

Want to start using multi-stage builds? Check out my example on GitHub and use is as a base to building more effective images for your applications.|||

