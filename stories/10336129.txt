If you’ve ever signed up, or even known anyone who has signed up, for LinkedIn, you’ve probably been on the receiving end of dozens of follow-up emails, inviting you to “expand your professional network.” These messages are virtually impossible to opt-out of. It’s a scummy use of dark UX patterns by a company that should know better. Now, LinkedIn is going to be paying for it as part of a class-action lawsuit, to the tune of $13 million.

Presented in San Jose’s U.S. District Court, the key issue in Perkins v. LinkedIn is spam. Namely, during the user sign-up process, LinkedIn claims that it “will not store your password or email anyone without your permission.” Despite this, LinkedIn sends automated follow-up email reminders on a new user’s behalf to any contacts harvested from his or her webmail accounts, which are presented in such a way as to appear as if they came directly from the user.

Under California law, the sitting judge has deemed this illegal. Consequently, if you were a member of LinkedIn’s “add connection” program between September 2011 and October 2014, you can submit a claim to get a payout.

The bad news is it probably won’t be for much. Each affected user is believed to only get about $10 as part of the class-action settlement. That number could have been higher–up to $750 per person if they’d proved LinkedIn’s actions caused mental anguish. Unfortunately, in its ruling, the court dismissed that provision.

Still, what this amounts to is a non-trivial penalty for a company using dark UX patterns to trick users into doing things they don’t really want to do. As Dark Patterns, an excellent resource on these kinds of tactics, explains, this sort of bad design is purposeful. “They are not mistakes, they are carefully crafted with a solid understanding of human psychology, and they do not have the user’s interests in mind.”

As social networks and other online products increasingly try to grow their users bases, they must be held accountable for their bad design, especially when that bad design is intentional. Hopefully, this will serve as a warning to other companies that use shady tactics and dark UX patterns to artificially grow their products.

You can read the judgement here.|||

Hopefully, this will be a lesson to other companies who use dark UX patterns to trick their users.