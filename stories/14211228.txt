Motorcycling is life and learning to ride is hard. Cornering, in particular, was the bane of my existence for a long time in the beginning. How do you know if you are leaning too much or too little? Thus… introducing… the Motorcycle Lean Assist, MLA for short! Let’s use data science to solve this common motorcycle challenge. -_-)b

Noooooo. Don’t be. You’re a badass on a motorcycle. If you don’t lean… you might get lucky like this guy.

But chances are you won’t, like this guy.

Noooooo. You’re not ready for MotoGP yet. Now you’re sliding on your butt. You can try these angles later after first being able to at least smoothly throttle through the corner.

Oh, and, a little solidarity for our brothers in tights. We know this feel.

MLA is designed for novice to intermediate riders, targeting between the -45ᵒ and 45ᵒ lean angles you should become comfortable with in order to ride safely. Obviously the MotoGP gods can lean down much more than us, but we are just average peasants and can forget about those angles.

What MLA does is provide you with a way to quantitatively analyze your lean angles so you don’t have to guess. Hopefully it gives you more confidence in your next ride to lean more when you need to and prevents you from going too much when you don’t.

I hear you asking though, “why not just use a gyroscope”?

How MLA works is by feeding a GoPro video stream into a convolutional neural network I trained, applying a temporal smoothing to improve responsiveness and accuracy of the lean angle predictions, and then applying an in-video augmentation to achieve the desired effect.

This was quite a fun project to work on. Instead of using more traditional computer vision techniques I wanted to approach this as an image classification problem for convolutional neural networks. What I wanted it to recognize were the 91ᵒs from -45ᵒ to 45ᵒ. Since there were no readily available datasets, I synthetically generated my own from Google Street View images.

I collected over 1000 images of various mountain roads frequented by motorcyclists and programmed an automation script for Adobe Photoshop to rotate, crop, and overlay the images with an instrument cluster. This was done while holding onto each rotation degree and storing it as my label per image for supervised learning. The beauty of this approach is that I no longer needed to go out and get riding footage. I could use Google Street View to teleport me anywhere in the world and even get different weather conditions into the training set. This greatly helps the generalization of MLA. At the end, I was able to get over 100,000 images for my dataset.

From there, I fed it into CaffeNet, a slightly modified version of AlexNet, to retrain its last three fully-connected layers.

Many model versions were trained after burning $100+ on AWS machines, including trying this as a regression problem, but ultimately, doing this as a classification yielded the best results as seen in the MLA demo reel at the top of this post. All things considered, I feel it is performing quite well for the amount and type of data I trained it on.

For more information and code, please visit my GitHub repo. Further improvements can absolutely be made for this project like using a more accurate dataset for training. The current one is like painting a donkey with stripes and having it learn to detect a zebra. Google Street View has camera angles significantly higher than any motorcycle mounted camera ever would. Hopefully this is good enough as-is to help a few newer riders though. Good luck guys! See you in the canyons.|||

