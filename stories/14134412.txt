Consider the 4 regression below, all of which have the same summary statistics and R2 score:

This is a lesson in that you cannon blindly trust the R2 score or other summary statisitcs as a measure of fit goodness. Particularly, you cannot ignore the assumptions of a regression, which are:

I would like to explore the assumption of residual distribution.

You can look at your residuals (loss) as an indicator of good fit. If your residuals do not follow a normal distribution, this is typically a warning sign that your R2 score is dubious.

There are a few statistical tests for Residual Normality, particularly, the Jaque-Bara test is common and available in scipy.

Jarque-Bera performors a hypothsis tests, where the null stats that your residual sample is from normal distribution. The test p-value reflects the probability of accepting the null hypothesis. If it’s too low then you reject it.

Below is an example of the JB tests on a normal and poisson distribution, see how the p-value of the normal and poisson cause us to accept and reject the null respectivly:

As you can see from the test above, that the p-value for the normal distributions is much larger than 5% which the p value for the arbitrary poisson distrubtion is much lower than the 5% baseline.

Although we can’t run the Jarque-Bera test on Anscombe’s quartet above (because there aren’t enough samples), we can see from the example above it should be a good metric to evaluate our model beyond summary statistics, which the Anscombe exmaple proves can be misleading.|||

