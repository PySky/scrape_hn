As I’ve become more familiar with the history of projects like Sketchpad, Smalltalk, and Self, I’ve been fascinated by the qualitative difference in approach their builders brought to programming system design, compared to most recent languages. These were systems that flowed out of a distinct philosophy and the intent to change the world. If existing language or interaction paradigms were insufficient to realize the goal, new ones had to be invented. If the implementation couldn’t keep up, new implementation techniques had to be created.

Among other advances, we have this approach to thank for the HotSpot compiler, technology originally created to make dynamic programming in Self feasible on 1980s hardware.

By contrast, most programming languages I’ve worked with professionally were born from much less ambitious visions. Usually, the vision amounted to “help programmers serve the computer more easily”, or sometimes “be like $older_language, only a little less painful”. My language of choice for the last ~10 years, Ruby, is very much in this vein. Most of the design decisions that cause me to love it turn out to be difficult to explain to someone who has learned to program in Ruby. Things like “optional semicolons” and “open classes” are less exciting if you haven’t spent the preceding five years coding in Java or C#.

Programming in 2015 feels a bit like Mad Max sometimes. Most of the “new hotness” technologies are cobbled-together bits of older technologies. And where there is innovation, it is often in service to the cold gods of performance or predictability, rather than opening new vistas of computer-mediated creation. Witness the rise of languages like Go (“C with GC and CSP”), Rust (“C++, but less horrible”), Elixir (“Erlang, but less horrible”), and Clojure (“Lisp without the cruft and mutability”).

These are all great languages, with a lot to recommend them. They are languages I use and enjoy. But they are are languages that exist because someone said “I like programming as we know it, I just want to change X and Y”. Or, alternately, “I’m tired of programmers screwing X up. Let’s disallow it completely.”. These are fundamentally derivative ideas.

Building incremental improvements on old things is good and important work. But in the 60s, 70s, and 80s, people like Alan Kay and Ivan Sutherland dreamed bigger, and even their “failures” changed the face of programming and computing. I wish I could point to areas where this kind of transformational, philosophically-driven innovation is being performed today. But if it’s happening, I haven’t come across it.|||

