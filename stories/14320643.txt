Recently everyone seems to be really excited with functional programming and its concepts. However, many people don’t talk about recursion and, especially, about proper tail calls, which is really important when it comes to writing clean and concise code without exploding the stack.

In this post I’ll give you tips to better visualize and think about recursion and explain what are proper tail calls, tail call optimization, syntactic tail calls and how to differentiate them, how they work and talk about their implementation in major JavaScript engines.

I’ll also be talking a lot about the call stack and stack traces, but I’ll not get into too much detail, thus if you want to read more about it take a look at this blog post I’ve made (which, by the way, is the most popular post in this website until now).

Recursion happens when the solution of a problem depends on the applying this same solution to other instances of it.

For example, the of can also be defined as the of multiplied by and so on.

This means the factorial of a number can be defined in terms of itself:

In a nutshell, when a function calls itself we can say we have recursion.

When I’m thinking about recursion I like to imagine multiple branches of execution deriving of a first execution and then bubbling up results back to the root call.

In the previous factorial example, we can see that multiple calls derive from the first one until we reach a definition that already exists by itself (in this case, the factorial of 0, which is one). Then, the result of this definition is returned (bubbles up) so that we can do another operation with it and return a value again, repeating this process all the way back to provide the result to the “root” call.

If we had to represent the calls a function does when it is invoked passing as an argument, it would look like this:

By doing a parallel with compilers’ theory, this looks very much like what happens when we use a context-free grammar to derive sentences until we reach terminal values.

This might seem abstract at first, but let me demonstrate visually how this process of thought works in another way by dissecting a call to a function that calculates the Nth number in the Fibonnacci Sequence.

This is the code for our Fibonacci function:

Basically, each call to the Fibonacci function generates two more calls, which may also call themselves until they reach a number that is smaller than 2 (because the Fibonacci sequence starts with 1 and 1, generating two when they’re summed).

When we reach a number smaller than two we return this result so that we can feed the calls above it, bubbling up results all the way up to the root call.

As the image below clearly demonstrates, when calling , we end up deriving calls from it until we reach a “self-contained” definition (a “base case”) which in this case are the first two numbers in the Fibonacci sequence: 1 (0th) and 1 (1st).

Since each recursive call depends on the result of another two recursive call (unless the value passed is smaller than 2 and therefore a “base case”), we start returning values from the leaves ( ) and then summing them in order to feed the call above.

As you could notice in the examples above, we can have linear recursion (when there is a single branch of recursive calls, such as in the factorial example) and branching recursion (when there is more than one branch of recursive calls, such as in the Fibonacci example).

When thinking about recursion, there are two main things you need to think about:

After you have defined an exit condition it is easy to determine when a function should call itself again and what it should do with the results.

If you want to read more about practical and fun applications of recursion, take a look at how trees and graph-related algorithms work.

Commonly, when using recursion, we end up stacking functions one on top of the other, because they might depend on the result of the previous invocation of itself.

If you want to get a good understanding of how a call stack works or how to read a stack trace, take a look at this post.

In order to demonstrate what the call stack looks like when we have recursion, let’s use a simple recursive function as an example.

This is its code:

Now, let’s call it and check the factorial of .

As you might remember from the previous example, the factorial of consists of getting , and and multiplying them. This means that a simple call to retrieve the factorial of does three more calls to the function.

Each one of these calls pushes a new frame onto the call stack, so it might look like this when all of them are stacked:

Now, let’s add a call to in order to see the current frames in the stack whenever the factorial function is called.

Your code should look like this now:

Now let’s run this code and analyze each one of the printed call stacks.

This is the first one:

As you can see, the first call stack contains only the first call to the function, which is , but now things will start to get interesting:

Here we have another call to the function right on top of the last one. This one is .

Then this is the stack when we call :

As you can see, it added another call on top of the previous ones.

And, finally, the call stack when we reach :

As I’ve said in the beginning of this section, the first call to needed to call , and . This is why we have four entries for the factorial function in our stack.

Now you’re probably seeing the problem we might face when having too much recursion: the call stack gets too big and we end up having a Stack Buffer Overflow. This happens when we try to add another entry to the call stack after it has reached its limit.

If you want to calculate how many frames you can have in your stack depending on which environment you’re running your JavaScript code into, I highly recommend you to try this cool method posted by Dr. Axel Rauschmayer (a guy I’m a big fan of).

Proper tail calls should have been implemented when ES6 came out, but it is not available yet in all major JS engines due to reasons I’ll explain later in this post.

Proper tail calls allow us to avoid blowing the stack when doing recursive calls. However, in order to make proper tail calls, we need to actually have a tail call in the first place.

But what is a tail call?

Tail calls are functions that can be executed without growing the stack. They’re always the last thing to be done and evaluated before the and the return value of this called function is returned by the calling function. The calling function also cannot be a generator function.

If you are into compilers’ theory and this kind of hardcore (a.k.a. awesome) stuff you can read the formal definition in the ECMA spec.

In order to demonstrate how proper tail calls work we need to refactor our old function and make it tail recursive:

Now the last thing this function will do will be returning the result of calling itself and nothing more, which makes it tail recursive.

As you might have noticed we’re now passing two arguments to it: the number we want to calculate the next factorial of ( ) and the accumulated total, which is .

Now we don’t need to necessarily get to the leaves of the derivate calls anymore (as we did in the previous example) since we have all the values we need in order to fulfill the current state (the accumulated value and the next factorial we should calculate).

Let’s analyze how this function is able to do that without stacking multiple recursive calls.

This is what happens when we call :

In a nutshell, this is what happens:

Now, instead of stacking frames, we just need to stack 1, since the subsequent calls don’t depend on the previous ones, which makes our new function have a memory complexity of instead of .

If you add a call to the function above and call in order to see the calls that get stacked, like this:

You will see that it still stacks calls to the function even though we can say this function is tail recursive:

In order to have access to proper tail calls on Node, we must enable by adding to the top of our file and then run it with the flag.

In order for that flag to be able to improve our function, our script should look like this:

When running that code again, these are the stack traces we get back:

As you can see, we’re not stacking more than one call to at a time, because every time we call it, we don’t need the previous frame anymore.

A good tip to create tail recursive functions is to pass all the “state” needed for the next call in order to be able to drop the next frame. Since you can’t always do that inside a single function, you can also think about how viable it is to create a nested function, which can be tail recursive.

You should also keep in mind that proper tail calls do not necessarily make your code run faster. Actually, most of the time, it just makes it slower.

However, besides allowing you to use less memory to store your stack, when using proper tail calls you also get locally allocated objects and end up needing less memory to run your recursive functions too, because since you don’t need any variables inside the current frame for the next recursive call, you allow the garbage collector to collect every object allocated inside the current frame, while in “non-tail-recursive” functions you would need to do allocations each time the recursive function was called, due to the fact that all the frames would be kept into the stack until the last recursive call (the one that is the “base case”) returns.

Differently to what happens with proper tail calls, tail call optimization actually improves the performance of tail recursive functions and makes running them faster.

Tail call optimization is a technique used by the compiler to transform your recursive calls into a loop using .

Since we already know how tail recursive functions work, it becomes really easy to explain how tail call optimization works.

Let’s take the function we have used previously and simulate what would probably happen with it if we had tail call optimization enabled in our JavaScript engines.

This is our starting code:

Given that there is code here that will be repeated until the exit condition (“base case”) is met, we can put it inside a label and jump straight to it instead of trying to call a function again. So our code might become something like this:

This means that tail call optimization is not the same as having proper tail calls!

As you could see in the examples above, having proper tail calls implies in not “saving” the history of all the function calls to our stack, which makes it more difficult to track bugs by reading the stack trace, since we don’t have information about all the calls that lead to the current situation.

This affects both statements and also the property we talked about in this post I’ve mentioned before.

A possible solution to this is having a “Shadow Stack” in development environments.

A Shadow Stack works just like a “second stack”. While the normal stack does not keep frames around when proper tail recursive calls are made, these calls get pushed into our “shadow stack” so that we can use it for debugging purposes and still avoid pushing these frames into the execution stack.

However, as you might imagine, there’s a lack of consolidated and easy-to-use tools for this and it also requires more memory to store all these frames in another place (which might not be a problem in a development environment).

Finally, using a shadow stack still does not solve the problem of the property if we have Tail Call Optimization, because when that happens we start using statements and not adding any frames to the stack trace. This means that when an error is created it might not have the function it was inside in the stack, because we got to that statement by jumping to a label and not by calling that function as we would normally do.

If you’re curious about that, take a loot at this excellent blog post by Michael Saboff about how WebKit handles tail calls.

Syntactic tail calls are a way of indicating to the compiler when proper tail calls and tail call optimization are wanted.

This way we could enable developers to choose whether they want this feature or not. It’s basically just a really explicit opt-in.

This allows us to manage the complexity of the elided stack frames and also allows new possibilities for “less invasive solutions (or no solutions at all)” (as the proposal itself says).

When it comes to the syntax there are some alternatives being studied and you can see them right here.

Right now this is an stage 0 proposal.

If you have any doubts, thoughts or if you disagree with anything I’ve written, please share it with me in the comments below or reach me at @lfernandescosta on twitter. I’d love to hear what you have to say.|||

