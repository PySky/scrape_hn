The purpose of this question is to identify dysfunction. I want to get answers from 2 or 3 engineers. If company leadership says they follow a certain process, but the engineers don’t talk about the process, that’s a sign of dysfunction. If you get different answers from different engineers, that’s another sign of dysfunction.

In a high quality team, I get consistent answers to this question. Every developer knows the process, and the process is light weight enough to be supportive of the engineers rather than oppressive to them.

Example of a good answer (there are many others): “We do N-week sprints wherein each engineer commits to a set of features and bug fixes to deliver. Each day we report progress on our commitments to each other. We have an amazing product manager who interfaces with customers to help us prioritize features and bug fixes.”

Example of a bad answer (there are many others): “I come into the office and see what fires are burning. Most days, I get interrupted with an emergency.”

Notice I don’t mention “Scrum” or any other specific methodology. I’m much less interested in the labels the company uses for their engineering process than the actual day-to-day “how stuff gets done”.

Good tooling is a strong indicator of a good team. If a team is using an ancient revision control system, they are probably using a bunch of other outdated tools. Furthermore, they probably don’t value the efficiency gains that can be achieved by investing in good tooling.

A good follow-up question is to ask about workflows. Do you use branches? Do you prefer rebasing or merging (git terms)? These questions will tell you how expert they are with their chosen tools, which will tell you a lot about their level of proficiency, which will in turn tell you what to expect if you take the job. For example, will you be the “local git expert” or will you be learning from a veritable Linus Torvalds?

This question can start a discussion about tools in general, which will often give you some good insight.

Strong answer: I get a lot of satisfaction from the work I do.

Strong answer: We have a lot of fun at work.

Strong answer: I love working with really smart, friendly co-workers.

Strong answer: Management respects engineering.

The more good answers the better. I don’t have to get all the answers above to give high marks to the company. Keep in mind that some people are not naturally “gushy”, so you may not get stellar responses here, and that might be just fine.

But if I hear the following kinds of answers, and very few from the strong answer list, I get nervous:

Weak answer: It pays the bills.

Weak answer: I don’t have to work very hard.

Weak answer: There is not a lot of pressure to deliver.

Weak answer: It doesn’t matter if I make big mistakes.

Weak answer: (silence)

Don’t think I am making those answers up. I’ve actually heard those in real interviews.

I don’t automatically consider it a bad company if I hear those weak answers, but if those are the only answers, I usually look elsewhere.

Be careful when making conclusions about an engineering team based on their unit testing practices. If a team gets excited when I ask about unit testing, it’s generally a good sign. Though on the other hand, if they can’t explain why they unit test, or the drawbacks of unit testing, this can be an indication of blind sheep dogma. If they provide bad excuses for why they don’t write tests, especially excuses like “we don’t have time”, that is a bad sign for me.

If the engineers tell me they write unit tests, and they are able to tell me metrics about their tests, such as how long they take to run, how many tests they have, and their code coverage, that is pretty attractive to me. It tells me that they have good tools, and they know how to use them. On the other hand, if they believe that 100% code coverage ensures a bug-free code base, I am leery.

I want to know beforehand if I will be working on a large, old, untested codebase at this company. This will help me manage my own expectations and decide if that’s something I want to do.

The best software development teams I know use tools like Jenkins, Travis, and Buildbot. If the team has no continuous integration, I try to gauge whether they are familiar with the concept. If they aren’t, this is a bad sign in my experience. Having a continuous integration system means that the team probably believes in automation, which is usually a very good sign in my experience.

For some teams, this naturally leads to a discussion about continuous delivery, which is a related but different concept from continuous integration. If it’s a web developer position, I expect the team to at least have heard about CD, and strong teams tend to put it in place, at least in part.

This is an open-ended question meant to find out if the team has put effort into measuring their software. For web development teams, the answers tend to focus on performance metrics like server response times, request throughput, number of users, client-side responsiveness, etc. But the discussion can go to things like number of users who speak different languages, browser breakdown, cache hit/miss rates, and myriad other topics. If the team hasn’t taken the time to measure, it can be an indicator that they don’t use real data to inform their decisions. They may be premature optimizers. I value a team that uses real, measured data to make decisions, especially about performance, but it applies to so many other things.

If the interviewer knows answers to many of these questions, it’s a good sign that the team is high quality. If they have no idea why they would even care about any of these measurements, it could be a negative indicator.

Again, the rule about dogma applies here. If the team seems to have latched onto a metric that doesn’t necessarily yield valuable, actionable information, and they can’t explain this to your satisfaction, this may be a warning sign.

A strong team usually has dedicated testers, and the team’s developers focus on quality. A really strong team has impressive test automation. Some teams are too small for dedicated testers or test automation, but that doesn’t necessarily mean they are a bad team. When I ask this question, I’m trying to get a feel for their process. Is their hair always on fire? Do they have a sane process for finding and prioritizing bugs? Do they rely on users to find bugs?

In my experience, high functioning teams use lots of collaboration tools. They often use chat services (Slack, IRC, HipChat, Jabber), code review services (Gerrit, GitHub, GitLab, Review Board), and of course, the venerable-but-showing-its-age Email. I am looking for indicators that each developer knows what the other developers are doing. I’m not looking for insane levels of detail, but more for a general awareness. Also, I like to see integrations with collaboration tools. The simplest example is an automatic email sent any time there’s an automated build failure. Another example for web-dev teams is automated error logging services that notify the team’s chat room when serious errors occur, or when key metrics cross a certain threshold.

My personal preference with frameworks is two fold:

So if a team is building an AIX desktop application in Motif, I am probably not interested. But maybe you are. This is a deeply personal topic, and you should approach it with a solid understanding of your own preferences.

Regardless of your framework preferences, it’s important to understand why the team has chosen their framework(s). Are they hype-driven? Do they change frameworks like their underwear? Is their codebase littered with shrapnel from framework-of-the-month churn? Are they stuck on an ancient version?

On the topic of why, I like to understand how much latitude developers have in choosing technologies. Does management mandate technology choice? Does management defer to developers? To get to the bottom of these questions, I usually ask, “How did you come to use framework X in your project?”. If developers don’t know the answer, that might be a bad sign, or it may mean they are just new enough to the company that they weren’t around for the decision.

I like to see teams make contributions to open source projects they use. This tells me they are not only able to use open source code, but they are proficient enough to contribute to it as well. These are the kinds of developers I like to work with. If the company is willing to pay them to do this, even better. That tells me the company understands what it means to be an open source citizen.

If the team is reinventing the wheel rather than using readily available tools to help them build their product, I get nervous. There are exceptions to this rule. For example, when Facebook was working on their own framework, I wouldn’t have held it against them (or would I).

If you want to get a really clear picture of what it’s like to work with this team, then try actually working with them. I’ve never personally done this, but I have a friend who has (a likely story, right). I think it’s a fantastic idea. If you want to learn almost anything about the team, go work with them for a half day. It might require you to sign an NDA. If the team is even willing to consider this idea, I think it’s a very good sign.

You will probably have to arrange this with someone from management, so this question is more designed to get a reaction from the developers. They may be so appalled by the idea that it’s not worth bringing up with management.

This question is designed to tell you more about the development process the company actually follows. This question, alone, is not very informative, but when you add these questions, things get much more interesting:

High quality teams agree on and commit to deadlines together. Deadlines that are handed down arbitrarily can be a sign of dysfunction, or at least that engineers don’t have a seat at the table when determining schedule.

This question serves to help gauge how much effort the company has put into developer experience. Does it take hours, days, or weeks for new developers to have their computer set up and ready to start coding? Is it automated or manual? This will tell you how proficient the team is at “supporting activities” that aren’t directly related to writing software, but that help support it. Does the team take this seriously?

Some companies pride themselves on having a dev setup process that is so fast that new developers can put code into production on day 1. This shows that the company takes providing a frictionless experience for developers pretty serious.|||

Have you ever been in a job interview, and the interviewer looks across the table and says, “do you have any questions?”, and you just stare back and say, “umm, I don’t think so”. If this has…