Recently we (Alex & Tatiana) were invited to give lectures about machine learning at GradDays — an event that is organized twice a year at the Heidelberg University (Germany’s oldest university).

GradDays are giving courses that broaden the physics knowledge of students and teach specialized useful techniques.

as well as other sweet things.

Even so, our course “Machine learning and applications in Science and Industry” was the most popular. Focus of the course (heavily influenced by time constraints: only 4 days) was to give a wide overview of useful models in Machine Learning and their applications in very different areas, and even contained optional practice!

That’s why we put inside many interactive demonstrations of machine learning techniques!

Also we tried to create a nice bridge between models and their real-life applications. Many of the examples were from particle physics — an area that we’re working in (tracking, tagging, reweighting, uniform boosting, particle identification, simulation refinement, tuning of simulation parameters, etc.). However we also included some notable examples from other data-intensive areas: astronomy, neuroscience, medicine, climatology and biology.

Finally, many other interesting things done with machine learning were discussed: spam detection, search engines, visual recognition, kinect and AlphaGo, recommender systems and news clustering.

Lecture of the first day gives some introduction into problems, applications and notions of machine learning. Several simple models are discussed to get an impression:

In the second day we made focus on tree-based techniques, specially boosting, that aren’t popular in research now, but work very well in practice and are best-performers in many examples with tabular data

On the third day we get back to continuous optimization models, start from revisiting linear and generalized linear models, then more involved models are introduced

Finally, the last day was devoted mostly to deep learning: convolutional and recurrent neural networks, autoencoders, embeddings, GANs and others.

Also, an active learning was demonstrated in couple with gaussian processes.|||

Mini-course about machine learning given at GradDays of Heidelberg University