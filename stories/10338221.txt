The tech visionaries who brought the world search, online shopping and social networks are now shaking up the world of health care and biomedical research with their philanthropy.

The most exciting — and disconcerting — developments in the field may be in predictive analytics, which aims to make an informed guess about the future. Although it’s currently mostly being used in retail to figure out who is more likely to buy, say, a certain sweater, there are also test programs that attempt to figure out who might be more likely to get a certain disease or even commit a crime.

Google, which acquired AI company DeepMind in 2014 for an estimated $400 million, has been secretive about its plans in the field, but the company has said its goal is to “solve intelligence.” One of its first real-world applications could be to help self-driving cars become better aware of their environments. Facebook chief executive Mark Zuckerberg says his social network, which has opened three different AI labs, plans to build machines “that are better than humans at our primary senses: vision, listening, etc.”

All of this may one day be possible. But is it a good idea?

Advances in science often have made people uneasy, even angry, going back to Copernicus, who placed the sun — not the Earth — at the center of the universe. Artificial intelligence is particularly sensitive, because the brain and its ability to reason is what makes us human.

In May 2014, cosmologist Stephen Hawking caused a stir when he warned that intelligent computers could be the downfall of humanity and “potentially our worst mistake in history.” Elon Musk — the billionaire philanthropist who helped found SpaceX, Tesla Motors and PayPal — in October 2014 lamented that a program whose function is to get rid of e-mail spam may determine “the best way of getting rid of spam is getting rid of humans.” He wasn’t joking.

Allen and Etzioni say that they also have thought a lot about how AI might change the world and that they respectfully disagree with the doomsayers. The technology will not exterminate but empower, they say, making humans more inventive and helping solve huge global problems such as climate change.

“There are people who say, ‘I don’t care about the ethics of it all. I’m a technologist.’ We are the opposite of that. We think about the impact of this kind of technology on society all the time,” said Etzioni, who is chief executive of the Allen Institute for Artificial Intelligence, “and what we see is a very positive impact.”

“Runaway machine intelligence is something we need to think about more,” Koch, president and chief science officer of the Allen Institute for Brain Science, said. “Clearly, we can’t say let’s not develop any more AI. That’s never going to happen. But we need to figure out what are the imagined dangers and what are the real ones and how to minimize them.”

Allen’s vision is creating an AI machine that would be like a smart assistant, rather than an independent being, “answering questions and clarifying things for you and so forth.” But he admits he has wondered whether it will one day be possible for that assistant or its descendants to evolve into something more.

“It’s a very deep question,” Allen said. “Nobody really knows what it would take to create something that is self-aware or has a personality. I guess I could imagine a day when perhaps, if we can understand how it works in the human brain, which is unbelievably complicated, it could be possible. But that is a long, long ways away.”|||

Paul Allen’s quest to build an artificial brain is one of the hardest software-engineering endeavors ever attempted