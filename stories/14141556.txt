Training and deploying AI models is often associated with massive data centers or super computers, with good reason. The ability to continually process, create, and improve models from all kinds of information: images, video, text, and voice, at massive scale, is no small computing feat. Deploying these models on mobile devices so they’re fast and lightweight can be equally daunting. Overcoming these challenges requires a robust, flexible, and portable deep learning framework.

Facebook has been working with others in the open source community to build such a framework. Today, we’re open-sourcing the first production-ready release of Caffe2 - a lightweight and modular deep learning framework emphasizing portability while maintaining scalability and performance.

We’re committed to providing the community with high-performance machine learning tools so that everyone can create intelligent apps and services. Caffe2 is shipping with tutorials and examples that demonstrate learning at massive scale which can leverage multiple GPUs in one machine or many machines with one or more GPUs. Learn to train and deploy models for iOS, Android, and Raspberry Pi. Pre-trained models from the Caffe2 Model Zoo can be run with just a few lines of code.

Caffe2 is deployed at Facebook to help developers and researchers train large machine learning models and deliver AI-powered experiences in our mobile apps. Now, developers will have access to many of the same tools, allowing them to run large-scale distributed training scenarios and build machine learning applications for mobile.

We’ve worked closely with NVIDIA, Qualcomm, Intel, Amazon, and Microsoft to optimize Caffe2 for both cloud and mobile environments. These collaborations will allow the machine learning community to rapidly experiment using more complex models and deploy the next generation of AI-enhanced apps and services. to optimize Caffe2 for both cloud and mobile environments. These collaborations will allow the machine learning community to rapidly experiment using more complex models and deploy the next generation of AI-enhanced apps and services.

Check out the Caffe2 documentation & tutorials at caffe2.ai and see the source code on GitHub! If you’re thinking about using Caffe2, we’re interested in hearing about your needs. Please participate in our survey. We will send you information about new releases and special developer events/webinars.|||

Training and deploying AI models is often associated with massive data centers or super computers, with good reason. The ability to continually process, create, and improve models from all kinds of information: images, video, text, and voice, at massive scale, is no small computing feat. Deploying these models on mobile devices so they’re fast and lightweight can be equally daunting. Overcoming these challenges requires a robust, flexible, and portable deep learning framework.